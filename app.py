"""
üåç Dashboard Multilingual - An√°lise Salarial - VERS√ÉO INTEGRADA COM MAIN.PY
Sistema completo integrado com todos os gr√°ficos e an√°lises do pipeline principal
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from pathlib import Path
import logging
import sys
import warnings
import json
from datetime import datetime
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns

# Configura√ß√µes
warnings.filterwarnings('ignore')

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Configurar p√°gina
st.set_page_config(
    page_title="Dashboard Integrado - An√°lise Salarial",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

class SimpleAuth:
    """Sistema de autentica√ß√£o simplificado"""
    
    def __init__(self):
        self.users = {
            'admin': {'password': 'admin123', 'name': 'Administrador', 'role': 'admin'},
            'user': {'password': 'user123', 'name': 'Usu√°rio', 'role': 'user'},
            'demo': {'password': 'demo123', 'name': 'Demo', 'role': 'user'}
        }
    
    def authenticate(self, username, password):
        """Autenticar usu√°rio"""
        if username in self.users and self.users[username]['password'] == password:
            st.session_state.authenticated = True
            st.session_state.user_data = self.users[username]
            st.session_state.username = username
            return True
        return False
    
    def is_authenticated(self):
        """Verificar se usu√°rio est√° autenticado"""
        return st.session_state.get('authenticated', False)
    
    def get_user_data(self):
        """Obter dados do usu√°rio"""
        return st.session_state.get('user_data', {})
    
    def logout(self):
        """Fazer logout"""
        st.session_state.authenticated = False
        st.session_state.user_data = {}
        st.session_state.username = ''

class IntegratedDashboard:
    """Dashboard integrado com pipeline principal (main.py)"""
    
    def __init__(self):
        """Inicializar dashboard integrado"""
        self.auth = SimpleAuth()
        
        # P√°ginas integradas com an√°lises do main.py
        self.pages = {
            'overview': {
                'title': 'Vis√£o Geral',
                'icon': 'üìä',
                'roles': ['admin', 'user'],
                'func': self._show_overview_page
            },
            'exploratory': {
                'title': 'An√°lise Explorat√≥ria',
                'icon': 'üîç',
                'roles': ['admin', 'user'],
                'func': self._show_exploratory_page
            },
            'models': {
                'title': 'Modelos ML',
                'icon': 'ü§ñ',
                'roles': ['admin', 'user'],
                'func': self._show_models_page
            },
            'clustering': {
                'title': 'Clustering (DBSCAN)',
                'icon': 'üéØ',
                'roles': ['admin', 'user'],
                'func': self._show_clustering_page
            },
            'association_rules': {
                'title': 'Regras de Associa√ß√£o',
                'icon': 'üìã',
                'roles': ['admin', 'user'],
                'func': self._show_association_rules_page
            },
            'visualizations': {
                'title': 'Visualiza√ß√µes Geradas',
                'icon': 'üé®',
                'roles': ['admin', 'user'],
                'func': self._show_visualizations_page
            },
            'pipeline_results': {
                'title': 'Resultados Pipeline',
                'icon': '‚öôÔ∏è',
                'roles': ['admin', 'user'],
                'func': self._show_pipeline_results_page
            },
            'prediction': {
                'title': 'Predi√ß√£o',
                'icon': 'üîÆ',
                'roles': ['admin', 'user'],
                'func': self._show_prediction_page
            },
            'admin': {
                'title': 'Administra√ß√£o',
                'icon': '‚öôÔ∏è',
                'roles': ['admin'],
                'func': self._show_admin_page
            }
        }
        
        # Estado inicial
        if 'current_page' not in st.session_state:
            st.session_state.current_page = 'overview'
        
        # Cache de dados
        self.data_cache = None
        
        # Diret√≥rios de an√°lise
        self.output_dirs = {
            'analysis': Path('output/analysis'),
            'images': Path('output/images'),
            'models': Path('models'),
            'output': Path('output')
        }
    
    def run(self):
        """Executar dashboard integrado"""
        # CSS personalizado
        self._apply_css()
        
        # Header
        st.markdown("""
        <div class="main-header">
            üåç Dashboard Integrado - An√°lise Salarial & Pipeline Acad√™mico
        </div>
        """, unsafe_allow_html=True)
        
        # Verificar autentica√ß√£o
        if not self.auth.is_authenticated():
            self._show_login_page()
            return
        
        # Carregar dados uma vez
        if self.data_cache is None:
            self.data_cache = self._load_integrated_data()
        
        # Layout principal
        self._show_sidebar()
        self._execute_current_page()
    
    def _apply_css(self):
        """Aplicar CSS personalizado aprimorado"""
        st.markdown("""
        <style>
        .main-header {
            background: linear-gradient(90deg, #1f4e79, #2c6aa0, #4a90a4);
            color: white;
            padding: 1.5rem;
            text-align: center;
            font-size: 1.8rem;
            font-weight: bold;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .pipeline-status {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            text-align: center;
        }
        
        .algorithm-card {
            background: linear-gradient(135deg, #4ecdc4 0%, #44a08d 100%);
            color: white;
            padding: 1rem;
            border-radius: 10px;
            margin: 0.5rem 0;
            text-align: center;
        }
        
        .results-box {
            background: linear-gradient(135deg, #ffeaa7 0%, #fdcb6e 100%);
            color: #2d3436;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
        }
        
        .nav-button-active {
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%) !important;
            color: white !important;
            border: none !important;
            padding: 0.75rem 1rem !important;
            border-radius: 10px !important;
            width: 100% !important;
            text-align: left !important;
            margin-bottom: 0.5rem !important;
            font-weight: 600 !important;
        }
        
        .nav-button-inactive {
            background: #f8f9fa !important;
            color: #495057 !important;
            border: 1px solid #dee2e6 !important;
            padding: 0.75rem 1rem !important;
            border-radius: 10px !important;
            width: 100% !important;
            text-align: left !important;
            margin-bottom: 0.5rem !important;
        }
        
        .user-section {
            background: linear-gradient(135deg, #6c5ce7 0%, #a29bfe 100%);
            color: white;
            padding: 1rem;
            border-radius: 15px;
            margin-bottom: 1rem;
            text-align: center;
        }
        
        .metric-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1rem;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 1rem;
        }
        
        .image-container {
            border: 2px solid #dee2e6;
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            background: #f8f9fa;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def _load_integrated_data(self):
        """Carregar dados integrados com pipeline principal"""
        try:
            # 1. Carregar dados principais
            data_paths = [
                "bkp/4-Carateristicas_salario.csv",
                "data/raw/4-Carateristicas_salario.csv",
                "4-Carateristicas_salario.csv"
            ]
            
            df = None
            source = None
            
            for path in data_paths:
                if Path(path).exists():
                    df = pd.read_csv(path)
                    source = path
                    break
            
            # 2. Escanear arquivos de an√°lise gerados pelo main.py
            analysis_files = self._scan_pipeline_files()
            
            # 3. Verificar status do pipeline
            pipeline_status = self._check_pipeline_status(analysis_files)
            
            if df is not None:
                # Limpeza b√°sica
                df = df.replace('?', pd.NA)
                
                return {
                    'df': df,
                    'status': f'‚úÖ Dados carregados de {source} ({len(df):,} registros)',
                    'analysis_files': analysis_files,
                    'pipeline_status': pipeline_status,
                    'source': source
                }
            else:
                # Dados de exemplo se n√£o encontrar o CSV
                return self._create_sample_data_with_analysis()
                
        except Exception as e:
            logging.error(f"Erro ao carregar dados integrados: {e}")
            return self._create_sample_data_with_analysis()
    
    def _scan_pipeline_files(self):
        """Escanear arquivos gerados pelo pipeline principal"""
        files = {
            'images': {
                'clustering': [],
                'association': [],
                'models': [],
                'dashboard': [],
                'distributions': []
            },
            'analysis': {
                'csv': [],
                'json': []
            },
            'models': []
        }
        
        # Gr√°ficos principais esperados do main.py
        expected_images = {
            'clustering': [
                'dbscan_analysis.png',
                'clustering_analysis_v2.png'
            ],
            'association': [
                'association_rules_analysis.png'
            ],
            'models': [
                'model_comparison_v2.png',
                'feature_importance_v2.png'
            ],
            'dashboard': [
                'summary_dashboard_v2.png',
                'temporal_analysis_v2.png'
            ],
            'distributions': [
                'numeric_distributions.png',
                'categorical_distributions.png',
                'salary_distribution.png',
                'correlacao.png'
            ]
        }
        
        # Verificar em m√∫ltiplos diret√≥rios
        search_dirs = [
            Path('output/images'),
            Path('output/analysis'),
            Path('output'),
            Path('images'),
            Path('analysis')
        ]
        
        for search_dir in search_dirs:
            if search_dir.exists():
                # Imagens
                for category, image_list in expected_images.items():
                    for image_name in image_list:
                        image_path = search_dir / image_name
                        if image_path.exists():
                            files['images'][category].append(image_path)
                
                # Arquivos adicionais
                files['analysis']['csv'].extend(list(search_dir.glob('*.csv')))
                files['analysis']['json'].extend(list(search_dir.glob('*.json')))
        
        # Modelos
        model_dirs = [Path('models'), Path('data/processed'), Path('output/models')]
        for model_dir in model_dirs:
            if model_dir.exists():
                files['models'].extend(list(model_dir.glob('*.pkl')))
                files['models'].extend(list(model_dir.glob('*.joblib')))
        
        return files
    
    def _check_pipeline_status(self, analysis_files):
        """Verificar status de execu√ß√£o do pipeline"""
        status = {
            'executed': False,
            'algorithms': {
                'dbscan': False,
                'apriori': False,
                'fp_growth': False,
                'eclat': False,
                'ml_models': False
            },
            'visualizations_count': 0,
            'analysis_files_count': 0
        }
        
        # Verificar algoritmos por arquivos
        all_files = []
        for category in analysis_files['images'].values():
            all_files.extend(category)
        all_files.extend(analysis_files['analysis']['csv'])
        
        for file_path in all_files:
            file_name = str(file_path).lower()
            
            if 'dbscan' in file_name:
                status['algorithms']['dbscan'] = True
            elif 'apriori' in file_name:
                status['algorithms']['apriori'] = True
            elif 'fp_growth' in file_name or 'fp-growth' in file_name:
                status['algorithms']['fp_growth'] = True
            elif 'eclat' in file_name:
                status['algorithms']['eclat'] = True
            elif 'model' in file_name:
                status['algorithms']['ml_models'] = True
        
        # Contadores
        status['visualizations_count'] = sum(len(v) for v in analysis_files['images'].values())
        status['analysis_files_count'] = len(analysis_files['analysis']['csv'])
        
        # Pipeline executado se tiver pelo menos 2 algoritmos
        executed_count = sum(1 for executed in status['algorithms'].values() if executed)
        status['executed'] = executed_count >= 2
        
        return status
    
    def _create_sample_data_with_analysis(self):
        """Criar dados de exemplo com status de an√°lise"""
        try:
            np.random.seed(42)
            n_samples = 1000
            
            data = {
                'age': np.random.randint(18, 70, n_samples),
                'workclass': np.random.choice(['Private', 'Self-emp-not-inc', 'Federal-gov'], n_samples),
                'education': np.random.choice(['Bachelors', 'HS-grad', 'Masters'], n_samples),
                'education-num': np.random.randint(1, 17, n_samples),
                'marital-status': np.random.choice(['Married-civ-spouse', 'Divorced', 'Never-married'], n_samples),
                'occupation': np.random.choice(['Tech-support', 'Sales', 'Exec-managerial'], n_samples),
                'relationship': np.random.choice(['Wife', 'Husband', 'Not-in-family'], n_samples),
                'race': np.random.choice(['White', 'Black', 'Asian-Pac-Islander'], n_samples),
                'sex': np.random.choice(['Female', 'Male'], n_samples),
                'capital-gain': np.random.randint(0, 10000, n_samples),
                'capital-loss': np.random.randint(0, 5000, n_samples),
                'hours-per-week': np.random.randint(20, 80, n_samples),
                'native-country': np.random.choice(['United-States', 'Canada'], n_samples),
                'salary': np.random.choice(['<=50K', '>50K'], n_samples)
            }
            
            df = pd.DataFrame(data)
            
            return {
                'df': df,
                'status': '‚ö†Ô∏è Dados de exemplo criados - Execute python main.py para an√°lise completa',
                'analysis_files': {'images': {k: [] for k in ['clustering', 'association', 'models', 'dashboard', 'distributions']}, 'analysis': {'csv': [], 'json': []}, 'models': []},
                'pipeline_status': {'executed': False, 'algorithms': {k: False for k in ['dbscan', 'apriori', 'fp_growth', 'eclat', 'ml_models']}, 'visualizations_count': 0, 'analysis_files_count': 0},
                'source': 'sample_data'
            }
            
        except Exception as e:
            logging.error(f"Erro ao criar dados de exemplo: {e}")
            return None
    
    def _show_login_page(self):
        """P√°gina de login"""
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            st.markdown("### üîê Login - Dashboard Integrado")
            
            with st.form("login_form", clear_on_submit=True):
                username = st.text_input("üë§ Nome de usu√°rio", placeholder="admin, user, demo")
                password = st.text_input("üîë Senha", type="password", placeholder="admin123, user123, demo123")
                
                if st.form_submit_button("üö™ Entrar", use_container_width=True):
                    if username and password:
                        if self.auth.authenticate(username, password):
                            st.success("‚úÖ Login realizado com sucesso!")
                            st.rerun()
                        else:
                            st.error("‚ùå Credenciais inv√°lidas!")
                    else:
                        st.warning("‚ö†Ô∏è Preencha todos os campos!")
            
            # Ajuda
            with st.expander("‚ÑπÔ∏è Credenciais de teste"):
                st.info("""
                **Credenciais dispon√≠veis:**
                - **admin** / **admin123** (Administrador completo)
                - **user** / **user123** (Usu√°rio padr√£o)
                - **demo** / **demo123** (Demonstra√ß√£o)
                
                **üí° Dica:** Execute `python main.py` para gerar todas as an√°lises!
                """)
    
    def _show_sidebar(self):
        """Mostrar sidebar integrada"""
        with st.sidebar:
            # Informa√ß√µes do usu√°rio
            self._show_user_info()
            
            st.markdown("---")
            
            # Status do pipeline
            self._show_pipeline_status()
            
            st.markdown("---")
            
            # Navega√ß√£o
            self._show_navigation()
            
            st.markdown("---")
            
            # Controles
            self._show_controls()
    
    def _show_user_info(self):
        """Mostrar informa√ß√µes do usu√°rio"""
        user_data = self.auth.get_user_data()
        if user_data:
            st.markdown(f"""
            <div class="user-section">
                <h4>üë§ {user_data.get('name', 'N/A')}</h4>
                <p><strong>Papel:</strong> {user_data.get('role', 'user').title()}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button("üö™ Logout", use_container_width=True):
                self.auth.logout()
                st.rerun()
    
    def _show_pipeline_status(self):
        """Mostrar status do pipeline principal"""
        st.markdown("### ‚öôÔ∏è Status Pipeline")
        
        if self.data_cache:
            pipeline_status = self.data_cache.get('pipeline_status', {})
            
            if pipeline_status.get('executed', False):
                st.markdown("""
                <div class="pipeline-status">
                    ‚úÖ Pipeline Executado!
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown("""
                <div class="results-box">
                    ‚ö†Ô∏è Execute: python main.py
                </div>
                """, unsafe_allow_html=True)
            
            # Algoritmos implementados
            algorithms = pipeline_status.get('algorithms', {})
            
            st.markdown("**üß† Algoritmos:**")
            for alg, status in algorithms.items():
                emoji = "‚úÖ" if status else "‚ùå"
                alg_name = alg.upper().replace('_', '-')
                st.markdown(f"  {emoji} {alg_name}")
            
            # Estat√≠sticas
            viz_count = pipeline_status.get('visualizations_count', 0)
            files_count = pipeline_status.get('analysis_files_count', 0)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("üé® Gr√°ficos", viz_count)
            with col2:
                st.metric("üìä An√°lises", files_count)
    
    def _show_navigation(self):
        """Mostrar navega√ß√£o"""
        st.markdown("### üß≠ Navega√ß√£o")
        
        user_data = self.auth.get_user_data()
        user_role = user_data.get('role', 'user')
        
        for page_key, page_info in self.pages.items():
            if user_role in page_info['roles']:
                button_text = f"{page_info['icon']} {page_info['title']}"
                is_current = st.session_state.current_page == page_key
                
                if is_current:
                    st.markdown(f"""
                    <div class="nav-button-active">
                        {button_text}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    if st.button(button_text, key=f"nav_{page_key}", use_container_width=True):
                        st.session_state.current_page = page_key
                        st.rerun()
    
    def _show_controls(self):
        """Mostrar controles"""
        st.markdown("### üîß Controles")
        
        if st.button("üîÑ Recarregar Dados", use_container_width=True):
            self.data_cache = None
            self.data_cache = self._load_integrated_data()
            st.success("‚úÖ Dados recarregados!")
            st.rerun()
        
        if st.button("‚ñ∂Ô∏è Executar Pipeline", use_container_width=True):
            st.info("üí° Execute no terminal: `python main.py`")
    
    def _execute_current_page(self):
        """Executar p√°gina atual"""
        current_page = st.session_state.current_page
        
        if current_page in self.pages:
            try:
                self.pages[current_page]['func']()
            except Exception as e:
                st.error(f"‚ùå Erro ao carregar p√°gina: {e}")
                logging.error(f"Erro na p√°gina {current_page}: {e}")
        else:
            st.error(f"‚ùå P√°gina '{current_page}' n√£o encontrada")
    
    # =========================================================================
    # P√ÅGINAS ESPEC√çFICAS INTEGRADAS COM MAIN.PY
    # =========================================================================
    
    def _show_overview_page(self):
        """P√°gina de vis√£o geral integrada"""
        st.header("üìä Vis√£o Geral - Dashboard Integrado")
        
        df = self.data_cache.get('df') if self.data_cache else None
        pipeline_status = self.data_cache.get('pipeline_status', {}) if self.data_cache else {}
        
        if df is None:
            st.error("‚ùå Dados n√£o dispon√≠veis")
            return
        
        # Status da execu√ß√£o
        if pipeline_status.get('executed', False):
            st.success("‚úÖ Pipeline principal executado com sucesso!")
        else:
            st.warning("‚ö†Ô∏è Pipeline n√£o executado. Execute `python main.py` para an√°lise completa.")
        
        # M√©tricas principais integradas
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <h3>üìã Registros</h3>
                <h2>{len(df):,}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-card">
                <h3>üìä Colunas</h3>
                <h2>{len(df.columns)}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            algorithms_executed = sum(1 for executed in pipeline_status.get('algorithms', {}).values() if executed)
            st.markdown(f"""
            <div class="metric-card">
                <h3>üß† Algoritmos</h3>
                <h2>{algorithms_executed}/5</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            viz_count = pipeline_status.get('visualizations_count', 0)
            st.markdown(f"""
            <div class="metric-card">
                <h3>üé® Gr√°ficos</h3>
                <h2>{viz_count}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        # Status dos algoritmos principais
        st.subheader("üß† Status dos Algoritmos Implementados")
        
        algorithms_info = {
            'dbscan': {'name': 'DBSCAN', 'desc': 'Clustering baseado em densidade'},
            'apriori': {'name': 'APRIORI', 'desc': 'Regras de associa√ß√£o cl√°ssicas'},
            'fp_growth': {'name': 'FP-GROWTH', 'desc': 'Minera√ß√£o eficiente de padr√µes'},
            'eclat': {'name': 'ECLAT', 'desc': 'Algoritmo de intersec√ß√£o'},
            'ml_models': {'name': 'ML MODELS', 'desc': 'Random Forest + Logistic Regression'}
        }
        
        for alg_key, alg_info in algorithms_info.items():
            executed = pipeline_status.get('algorithms', {}).get(alg_key, False)
            status_emoji = "‚úÖ" if executed else "‚ùå"
            status_text = "Executado" if executed else "N√£o executado"
            
            st.markdown(f"""
            <div class="algorithm-card">
                <strong>{status_emoji} {alg_info['name']}</strong> - {alg_info['desc']}<br>
                <small>Status: {status_text}</small>
            </div>
            """, unsafe_allow_html=True)
        
        # Distribui√ß√µes principais se dados dispon√≠veis
        st.subheader("üìà Distribui√ß√µes dos Dados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if 'salary' in df.columns:
                salary_counts = df['salary'].value_counts()
                fig = px.pie(
                    values=salary_counts.values,
                    names=salary_counts.index,
                    title="üí∞ Distribui√ß√£o de Sal√°rio"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            if 'sex' in df.columns:
                sex_counts = df['sex'].value_counts()
                fig = px.bar(
                    x=sex_counts.index,
                    y=sex_counts.values,
                    title="üë• Distribui√ß√£o por Sexo"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # Amostra dos dados
        st.subheader("üìã Amostra dos Dados")
        st.dataframe(df.head(10), use_container_width=True)
    
    def _show_exploratory_page(self):
        """P√°gina de an√°lise explorat√≥ria com gr√°ficos do pipeline"""
        st.header("üîç An√°lise Explorat√≥ria - Integrada com Pipeline")
        
        df = self.data_cache.get('df') if self.data_cache else None
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        
        if df is None:
            st.error("‚ùå Dados n√£o dispon√≠veis")
            return
        
        # Mostrar gr√°ficos de distribui√ß√£o gerados pelo main.py
        st.subheader("üìä Distribui√ß√µes Geradas pelo Pipeline")
        
        distributions_images = analysis_files.get('images', {}).get('distributions', [])
        
        if distributions_images:
            tabs = st.tabs([f"üìä {img.stem}" for img in distributions_images])
            
            for i, (tab, img_path) in enumerate(zip(tabs, distributions_images)):
                with tab:
                    try:
                        image = Image.open(img_path)
                        st.image(image, caption=f"Gerado pelo pipeline: {img_path.name}", use_column_width=True)
                    except Exception as e:
                        st.error(f"Erro ao carregar imagem: {e}")
        else:
            st.warning("‚ö†Ô∏è Nenhuma distribui√ß√£o encontrada. Execute `python main.py` para gerar.")
        
        # An√°lise interativa adicional
        st.subheader("üîç An√°lise Interativa")
        
        # Controles
        col1, col2, col3 = st.columns(3)
        
        with col1:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                x_var = st.selectbox("üìä Vari√°vel X:", numeric_cols)
        
        with col2:
            y_var = st.selectbox("üìä Vari√°vel Y:", ["Nenhuma"] + numeric_cols)
        
        with col3:
            categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
            if categorical_cols:
                color_var = st.selectbox("üé® Cor por:", ["Nenhuma"] + categorical_cols)
            else:
                color_var = "Nenhuma"
        
        # Gr√°ficos baseados na sele√ß√£o
        if 'x_var' in locals():
            if y_var != "Nenhuma":
                # Scatter plot
                fig = px.scatter(
                    df, x=x_var, y=y_var,
                    color=color_var if color_var != "Nenhuma" else None,
                    title=f"üìä {x_var} vs {y_var}"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                # Histograma
                fig = px.histogram(
                    df, x=x_var,
                    color=color_var if color_var != "Nenhuma" else None,
                    title=f"üìä Distribui√ß√£o de {x_var}"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # Correla√ß√µes
        st.subheader("üîó Matriz de Correla√ß√£o")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr()
            fig = px.imshow(
                corr_matrix,
                text_auto=True,
                title="üîó Matriz de Correla√ß√£o"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _show_models_page(self):
        """P√°gina de modelos ML integrada com pipeline"""
        st.header("ü§ñ Modelos ML - Integrados com Pipeline")
        
        df = self.data_cache.get('df') if self.data_cache else None
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        pipeline_status = self.data_cache.get('pipeline_status', {}) if self.data_cache else {}
        
        if df is None:
            st.error("‚ùå Dados n√£o dispon√≠veis")
            return
        
        # Status dos modelos
        ml_executed = pipeline_status.get('algorithms', {}).get('ml_models', False)
        
        if ml_executed:
            st.success("‚úÖ Modelos ML executados pelo pipeline!")
        else:
            st.warning("‚ö†Ô∏è Modelos n√£o executados. Execute `python main.py` para treinar.")
        
        # Gr√°ficos de modelos gerados pelo main.py
        st.subheader("üìä An√°lises dos Modelos Geradas")
        
        model_images = analysis_files.get('images', {}).get('models', [])
        
        if model_images:
            for img_path in model_images:
                st.markdown(f"### üìà {img_path.stem.replace('_', ' ').title()}")
                try:
                    image = Image.open(img_path)
                    st.image(image, caption=f"Gerado pelo pipeline: {img_path.name}", use_column_width=True)
                except Exception as e:
                    st.error(f"Erro ao carregar imagem: {e}")
        else:
            st.info("üí° Nenhum gr√°fico de modelo encontrado. Execute o pipeline para gerar.")
        
        # Informa√ß√µes sobre modelos implementados
        st.subheader("üß† Modelos Implementados no Pipeline")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üå≥ Random Forest</h4>
                <p>‚Ä¢ Ensemble de √°rvores de decis√£o</p>
                <p>‚Ä¢ Reduz overfitting</p>
                <p>‚Ä¢ Boa performance geral</p>
                <p>‚Ä¢ Implementado no main.py</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìà Logistic Regression</h4>
                <p>‚Ä¢ Modelo linear para classifica√ß√£o</p>
                <p>‚Ä¢ Interpret√°vel</p>
                <p>‚Ä¢ R√°pido para treinar</p>
                <p>‚Ä¢ Implementado no main.py</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Target distribution
        if 'salary' in df.columns:
            st.subheader("üéØ Distribui√ß√£o da Vari√°vel Target")
            target_dist = df['salary'].value_counts()
            fig = px.pie(
                values=target_dist.values,
                names=target_dist.index,
                title="üéØ Distribui√ß√£o da Vari√°vel Target (Salary)"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _show_clustering_page(self):
        """P√°gina de clustering integrada com DBSCAN do pipeline"""
        st.header("üéØ Clustering (DBSCAN) - Integrado com Pipeline")
        
        df = self.data_cache.get('df') if self.data_cache else None
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        pipeline_status = self.data_cache.get('pipeline_status', {}) if self.data_cache else {}
        
        if df is None:
            st.error("‚ùå Dados n√£o dispon√≠veis")
            return
        
        # Status do DBSCAN
        dbscan_executed = pipeline_status.get('algorithms', {}).get('dbscan', False)
        
        if dbscan_executed:
            st.success("‚úÖ DBSCAN executado pelo pipeline!")
        else:
            st.warning("‚ö†Ô∏è DBSCAN n√£o executado. Execute `python main.py` para gerar clusters.")
        
        # Gr√°ficos de clustering gerados pelo main.py
        st.subheader("üìä An√°lises de Clustering Geradas")
        
        clustering_images = analysis_files.get('images', {}).get('clustering', [])
        
        if clustering_images:
            for img_path in clustering_images:
                st.markdown(f"### üéØ {img_path.stem.replace('_', ' ').title()}")
                try:
                    image = Image.open(img_path)
                    st.image(image, caption=f"Gerado pelo pipeline: {img_path.name}", use_column_width=True)
                except Exception as e:
                    st.error(f"Erro ao carregar imagem: {e}")
        else:
            st.info("üí° Nenhum gr√°fico de clustering encontrado. Execute o pipeline para gerar.")
        
        # Verificar arquivos CSV de clustering
        st.subheader("üìã Resultados de Clustering")
        
        clustering_csvs = [f for f in analysis_files.get('analysis', {}).get('csv', []) 
                          if 'dbscan' in str(f).lower() or 'cluster' in str(f).lower()]
        
        if clustering_csvs:
            for csv_path in clustering_csvs:
                with st.expander(f"üìÅ {csv_path.name}"):
                    try:
                        df_cluster = pd.read_csv(csv_path)
                        st.dataframe(df_cluster.head(), use_container_width=True)
                        
                        # Visualizar clusters se poss√≠vel
                        if 'cluster' in df_cluster.columns:
                            cluster_counts = df_cluster['cluster'].value_counts()
                            fig = px.bar(
                                x=cluster_counts.index,
                                y=cluster_counts.values,
                                title=f"üéØ Distribui√ß√£o de Clusters - {csv_path.name}"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                    except Exception as e:
                        st.error(f"Erro ao ler arquivo: {e}")
        
        # Informa√ß√µes sobre DBSCAN
        st.subheader("üß† Sobre o Algoritmo DBSCAN")
        
        st.markdown("""
        <div class="algorithm-card">
            <h4>üéØ DBSCAN (Density-Based Spatial Clustering)</h4>
            <p><strong>Caracter√≠sticas:</strong></p>
            <p>‚Ä¢ Baseado em densidade de pontos</p>
            <p>‚Ä¢ Detecta ru√≠do automaticamente</p>
            <p>‚Ä¢ N√£o requer n√∫mero de clusters pr√©-definido</p>
            <p>‚Ä¢ Identifica clusters de formas arbitr√°rias</p>
            <p><strong>Implementa√ß√£o:</strong> Dispon√≠vel no main.py</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Prepara√ß√£o para clustering (dados atuais)
        st.subheader("üìä Prepara√ß√£o para Clustering")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) >= 2:
            st.info(f"‚úÖ {len(numeric_cols)} vari√°veis num√©ricas dispon√≠veis para clustering")
            
            # Visualiza√ß√£o 2D das features
            col1, col2 = st.columns(2)
            
            with col1:
                x_feature = st.selectbox("Feature X:", numeric_cols, key="cluster_x")
            
            with col2:
                y_feature = st.selectbox("Feature Y:", numeric_cols, index=1 if len(numeric_cols) > 1 else 0, key="cluster_y")
            
            if x_feature and y_feature and x_feature != y_feature:
                # Scatter plot das features
                color_by = 'salary' if 'salary' in df.columns else None
                fig = px.scatter(
                    df, x=x_feature, y=y_feature,
                    color=color_by,
                    title=f"üìä {x_feature} vs {y_feature}"
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Poucas vari√°veis num√©ricas para clustering eficaz")
    
    def _show_association_rules_page(self):
        """P√°gina de regras de associa√ß√£o integrada com APRIORI, FP-GROWTH, ECLAT"""
        st.header("üìã Regras de Associa√ß√£o - APRIORI + FP-GROWTH + ECLAT")
        
        df = self.data_cache.get('df') if self.data_cache else None
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        pipeline_status = self.data_cache.get('pipeline_status', {}) if self.data_cache else {}
        
        if df is None:
            st.error("‚ùå Dados n√£o dispon√≠veis")
            return
        
        # Status dos algoritmos
        algorithms_status = {
            'apriori': pipeline_status.get('algorithms', {}).get('apriori', False),
            'fp_growth': pipeline_status.get('algorithms', {}).get('fp_growth', False),
            'eclat': pipeline_status.get('algorithms', {}).get('eclat', False)
        }
        
        # Mostrar status
        col1, col2, col3 = st.columns(3)
        
        with col1:
            status = "‚úÖ" if algorithms_status['apriori'] else "‚ùå"
            st.markdown(f"""
            <div class="algorithm-card">
                <h4>{status} APRIORI</h4>
                <p>Algoritmo cl√°ssico</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            status = "‚úÖ" if algorithms_status['fp_growth'] else "‚ùå"
            st.markdown(f"""
            <div class="algorithm-card">
                <h4>{status} FP-GROWTH</h4>
                <p>Mais eficiente</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            status = "‚úÖ" if algorithms_status['eclat'] else "‚ùå"
            st.markdown(f"""
            <div class="algorithm-card">
                <h4>{status} ECLAT</h4>
                <p>Intersec√ß√£o vertical</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Gr√°ficos de regras de associa√ß√£o gerados pelo main.py
        st.subheader("üìä An√°lises de Regras de Associa√ß√£o Geradas")
        
        association_images = analysis_files.get('images', {}).get('association', [])
        
        if association_images:
            for img_path in association_images:
                st.markdown(f"### üìã {img_path.stem.replace('_', ' ').title()}")
                try:
                    image = Image.open(img_path)
                    st.image(image, caption=f"Gerado pelo pipeline: {img_path.name}", use_column_width=True)
                except Exception as e:
                    st.error(f"Erro ao carregar imagem: {e}")
        else:
            st.info("üí° Nenhum gr√°fico de regras encontrado. Execute o pipeline para gerar.")
        
        # Resultados em CSV
        st.subheader("üìã Resultados das Regras de Associa√ß√£o")
        
        association_csvs = [f for f in analysis_files.get('analysis', {}).get('csv', []) 
                           if any(keyword in str(f).lower() 
                                 for keyword in ['apriori', 'fp_growth', 'eclat', 'association', 'rules'])]
        
        if association_csvs:
            tabs = st.tabs([f"üìã {csv.stem.upper()}" for csv in association_csvs])
            
            for tab, csv_path in zip(tabs, association_csvs):
                with tab:
                    try:
                        df_rules = pd.read_csv(csv_path)
                        
                        # Estat√≠sticas das regras
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("üìä Total de Regras", len(df_rules))
                        
                        with col2:
                            if 'confidence' in df_rules.columns:
                                avg_confidence = df_rules['confidence'].mean()
                                st.metric("üéØ Confian√ßa M√©dia", f"{avg_confidence:.3f}")
                        
                        with col3:
                            if 'lift' in df_rules.columns:
                                avg_lift = df_rules['lift'].mean()
                                st.metric("üìà Lift M√©dio", f"{avg_lift:.3f}")
                        
                        # Mostrar regras
                        st.dataframe(df_rules.head(10), use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Erro ao ler arquivo: {e}")
        else:
            st.warning("‚ö†Ô∏è Nenhum resultado encontrado. Execute `python main.py` para gerar regras.")
        
        # An√°lise de padr√µes nos dados atuais
        st.subheader("üìä An√°lise de Padr√µes nos Dados")
        
        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
        if categorical_cols:
            st.info(f"‚úÖ {len(categorical_cols)} vari√°veis categ√≥ricas dispon√≠veis")
            
            # An√°lise de frequ√™ncia
            selected_col = st.selectbox("Selecione uma vari√°vel para an√°lise:", categorical_cols)
            
            if selected_col:
                value_counts = df[selected_col].value_counts()
                fig = px.bar(
                    x=value_counts.index[:10],  # Top 10
                    y=value_counts.values[:10],
                    title=f"üìä Top 10 valores em {selected_col}"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    def _show_visualizations_page(self):
        """P√°gina dedicada a todas as visualiza√ß√µes geradas pelo pipeline"""
        st.header("üé® Visualiza√ß√µes Geradas pelo Pipeline")
        
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        
        # Organizar visualiza√ß√µes por categoria
        all_images = analysis_files.get('images', {})
        total_images = sum(len(v) for v in all_images.values())
        
        if total_images == 0:
            st.warning("‚ö†Ô∏è Nenhuma visualiza√ß√£o encontrada.")
            st.info("üí° Execute `python main.py` para gerar todas as visualiza√ß√µes.")
            return
        
        st.success(f"‚úÖ {total_images} visualiza√ß√µes encontradas!")
        
        # Tabs por categoria
        categories = [k for k, v in all_images.items() if v]
        
        if categories:
            tabs = st.tabs([f"üé® {cat.replace('_', ' ').title()}" for cat in categories])
            
            for tab, category in zip(tabs, categories):
                with tab:
                    st.subheader(f"üìä {category.replace('_', ' ').title()}")
                    
                    images_in_category = all_images[category]
                    
                    # Mostrar imagens em grid
                    if len(images_in_category) == 1:
                        # Uma imagem - tela cheia
                        img_path = images_in_category[0]
                        try:
                            image = Image.open(img_path)
                            st.image(image, caption=f"{img_path.name}", use_column_width=True)
                        except Exception as e:
                            st.error(f"Erro ao carregar {img_path.name}: {e}")
                    
                    elif len(images_in_category) == 2:
                        # Duas imagens - lado a lado
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            try:
                                image = Image.open(images_in_category[0])
                                st.image(image, caption=f"{images_in_category[0].name}", use_column_width=True)
                            except Exception as e:
                                st.error(f"Erro: {e}")
                        
                        with col2:
                            try:
                                image = Image.open(images_in_category[1])
                                st.image(image, caption=f"{images_in_category[1].name}", use_column_width=True)
                            except Exception as e:
                                st.error(f"Erro: {e}")
                    
                    else:
                        # M√∫ltiplas imagens - uma por vez com sele√ß√£o
                        selected_image = st.selectbox(
                            f"Selecione uma visualiza√ß√£o de {category}:",
                            options=[img.stem for img in images_in_category],
                            key=f"select_{category}"
                        )
                        
                        if selected_image:
                            selected_path = next(img for img in images_in_category if img.stem == selected_image)
                            try:
                                image = Image.open(selected_path)
                                st.image(image, caption=f"{selected_path.name}", use_column_width=True)
                            except Exception as e:
                                st.error(f"Erro ao carregar {selected_path.name}: {e}")
        
        # Informa√ß√µes sobre as visualiza√ß√µes
        st.subheader("‚ÑπÔ∏è Sobre as Visualiza√ß√µes")
        
        st.markdown("""
        **üé® Visualiza√ß√µes Geradas pelo Pipeline:**
        
        - **üìä Dashboard**: Resumo executivo completo
        - **üéØ Clustering**: An√°lises DBSCAN detalhadas
        - **üìã Association**: Regras APRIORI, FP-GROWTH, ECLAT
        - **ü§ñ Models**: Compara√ß√£o e import√¢ncia de features
        - **üìà Distributions**: Histogramas e distribui√ß√µes
        
        **üí° Para gerar novas visualiza√ß√µes:** Execute `python main.py`
        """)
    
    def _show_pipeline_results_page(self):
        """P√°gina dedicada aos resultados completos do pipeline"""
        st.header("‚öôÔ∏è Resultados Completos do Pipeline")
        
        pipeline_status = self.data_cache.get('pipeline_status', {}) if self.data_cache else {}
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        
        # Status geral
        if pipeline_status.get('executed', False):
            st.success("‚úÖ Pipeline executado com sucesso!")
        else:
            st.error("‚ùå Pipeline n√£o foi executado")
            st.info("üí° Execute `python main.py` para processar todas as an√°lises")
            return
        
        # Resumo executivo
        st.subheader("üìä Resumo Executivo")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            algorithms_count = sum(1 for executed in pipeline_status.get('algorithms', {}).values() if executed)
            st.metric("üß† Algoritmos", f"{algorithms_count}/5")
        
        with col2:
            viz_count = pipeline_status.get('visualizations_count', 0)
            st.metric("üé® Visualiza√ß√µes", viz_count)
        
        with col3:
            files_count = pipeline_status.get('analysis_files_count', 0)
            st.metric("üìä Arquivos CSV", files_count)
        
        with col4:
            models_count = len(analysis_files.get('models', []))
            st.metric("ü§ñ Modelos", models_count)
        
        # Status detalhado dos algoritmos
        st.subheader("üß† Status Detalhado dos Algoritmos")
        
        algorithms_detail = {
            'dbscan': {
                'name': 'DBSCAN',
                'description': 'Clustering baseado em densidade',
                'type': 'Clustering',
                'output': 'dbscan_results.csv + dbscan_analysis.png'
            },
            'apriori': {
                'name': 'APRIORI',
                'description': 'Regras de associa√ß√£o cl√°ssicas',
                'type': 'Association Rules',
                'output': 'apriori_rules.csv'
            },
            'fp_growth': {
                'name': 'FP-GROWTH',
                'description': 'Minera√ß√£o eficiente de padr√µes',
                'type': 'Association Rules',
                'output': 'fp_growth_rules.csv'
            },
            'eclat': {
                'name': 'ECLAT',
                'description': 'Algoritmo de intersec√ß√£o vertical',
                'type': 'Association Rules',
                'output': 'eclat_rules.csv'
            },
            'ml_models': {
                'name': 'ML MODELS',
                'description': 'Random Forest + Logistic Regression',
                'type': 'Machine Learning',
                'output': 'model_comparison_v2.png + feature_importance_v2.png'
            }
        }
        
        for alg_key, alg_info in algorithms_detail.items():
            executed = pipeline_status.get('algorithms', {}).get(alg_key, False)
            status_color = "success" if executed else "error"
            status_text = "‚úÖ Executado" if executed else "‚ùå N√£o executado"
            
            with st.container():
                col1, col2, col3, col4 = st.columns([2, 3, 2, 3])
                
                with col1:
                    if executed:
                        st.success(alg_info['name'])
                    else:
                        st.error(alg_info['name'])
                
                with col2:
                    st.write(f"**Tipo:** {alg_info['type']}")
                    st.write(alg_info['description'])
                
                with col3:
                    st.write(f"**Status:**")
                    st.write(status_text)
                
                with col4:
                    st.write(f"**Output:**")
                    st.write(alg_info['output'])
        
        # Arquivos gerados
        st.subheader("üìÅ Arquivos Gerados")
        
        # CSV files
        csv_files = analysis_files.get('analysis', {}).get('csv', [])
        if csv_files:
            st.markdown("**üìä Arquivos CSV de An√°lise:**")
            for csv_file in csv_files:
                st.markdown(f"‚Ä¢ `{csv_file.name}` - {csv_file.stat().st_size / 1024:.1f} KB")
        
        # JSON files
        json_files = analysis_files.get('analysis', {}).get('json', [])
        if json_files:
            st.markdown("**üìã Arquivos JSON:**")
            for json_file in json_files:
                st.markdown(f"‚Ä¢ `{json_file.name}` - {json_file.stat().st_size / 1024:.1f} KB")
        
        # Model files
        model_files = analysis_files.get('models', [])
        if model_files:
            st.markdown("**ü§ñ Modelos Treinados:**")
            for model_file in model_files:
                st.markdown(f"‚Ä¢ `{model_file.name}` - {model_file.stat().st_size / 1024:.1f} KB")
        
        # Verificar se existe summary dashboard gerado
        dashboard_images = analysis_files.get('images', {}).get('dashboard', [])
        summary_dashboard = next((img for img in dashboard_images if 'summary' in img.name.lower()), None)
        
        if summary_dashboard:
            st.subheader("üìä Dashboard de Resumo Gerado")
            try:
                image = Image.open(summary_dashboard)
                st.image(image, caption="Dashboard de resumo gerado pelo pipeline", use_column_width=True)
            except Exception as e:
                st.error(f"Erro ao carregar dashboard: {e}")
        
        # Log de execu√ß√£o se dispon√≠vel
        st.subheader("üìã Informa√ß√µes T√©cnicas")
        
        st.markdown(f"""
        **üîß Configura√ß√µes do Pipeline:**
        - **Algoritmos principais:** 4 (DBSCAN, APRIORI, FP-GROWTH, ECLAT)
        - **Modelos ML:** 2 (Random Forest, Logistic Regression)
        - **Visualiza√ß√µes:** {pipeline_status.get('visualizations_count', 0)} gr√°ficos gerados
        - **Tempo de execu√ß√£o:** Varia de 30s a 2 minutos
        - **Formato de sa√≠da:** CSV, PNG, JSON
        
        **üìä M√©tricas calculadas:**
        - Accuracy, Precision, Recall, F1-Score (ML)
        - Silhouette Score, Inertia (Clustering)
        - Confidence, Lift, Support (Association Rules)
        """)
    
    def _show_prediction_page(self):
        """P√°gina de predi√ß√£o integrada"""
        st.header("üîÆ Interface de Predi√ß√£o")
        
        df = self.data_cache.get('df') if self.data_cache else None
        analysis_files = self.data_cache.get('analysis_files', {}) if self.data_cache else {}
        
        if df is None:
            st.error("‚ùå Dados n√£o dispon√≠veis")
            return
        
        # Verificar modelos dispon√≠veis
        model_files = analysis_files.get('models', [])
        
        if not model_files:
            st.warning("‚ö†Ô∏è Nenhum modelo treinado encontrado")
            st.info("üí° Execute o pipeline principal para treinar modelos: `python main.py`")
            return
        
        st.success(f"‚úÖ {len(model_files)} modelo(s) dispon√≠vel(is)")
        
        # Interface de predi√ß√£o
        st.subheader("üìù Fazer Predi√ß√£o Individual")
        
        with st.form("prediction_form"):
            st.markdown("**Insira os dados para predi√ß√£o:**")
            
            # Campos de entrada baseados nas colunas do dataset
            col1, col2, col3 = st.columns(3)
            
            with col1:
                age = st.number_input("üéÇ Idade", min_value=16, max_value=90, value=30)
                education_num = st.number_input("üìö Anos de Educa√ß√£o", min_value=1, max_value=16, value=10)
                hours_per_week = st.number_input("‚è∞ Horas/Semana", min_value=1, max_value=99, value=40)
            
            with col2:
                workclass = st.selectbox("üíº Classe de Trabalho", 
                                       ['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'])
                education = st.selectbox("üéì Educa√ß√£o", 
                                       ['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'])
                marital_status = st.selectbox("üíë Estado Civil", 
                                            ['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'])
            
            with col3:
                occupation = st.selectbox("üë®‚Äçüíº Ocupa√ß√£o", 
                                        ['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces'])
                relationship = st.selectbox("üë• Relacionamento", 
                                          ['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'])
                sex = st.selectbox("‚öß Sexo", ['Female', 'Male'])
            
            col4, col5 = st.columns(2)
            
            with col4:
                race = st.selectbox("üåç Ra√ßa", 
                                  ['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'])
                capital_gain = st.number_input("üí∞ Ganho de Capital", min_value=0, max_value=99999, value=0)
            
            with col5:
                native_country = st.selectbox("üè≥Ô∏è Pa√≠s de Origem", 
                                            ['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal', 'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands'])
                capital_loss = st.number_input("üìâ Perda de Capital", min_value=0, max_value=4356, value=0)
            
            # Bot√£o de predi√ß√£o
            if st.form_submit_button("üîÆ Fazer Predi√ß√£o", use_container_width=True):
                # Simular predi√ß√£o (aqui voc√™ carregaria o modelo real)
                st.success("üéØ Predi√ß√£o realizada!")
                
                # Resultado simulado
                probability = np.random.rand()
                prediction = ">50K" if probability > 0.5 else "<=50K"
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("üìä Predi√ß√£o", prediction)
                
                with col2:
                    st.metric("üéØ Confian√ßa", f"{probability:.1%}")
                
                st.info("üí° Esta √© uma predi√ß√£o simulada. Execute o pipeline para usar modelos reais.")
        
        # Predi√ß√£o em lote
        st.subheader("üìä Predi√ß√£o em Lote")
        
        uploaded_file = st.file_uploader("üìÅ Fa√ßa upload de um CSV para predi√ß√£o em lote", type=['csv'])
        
        if uploaded_file is not None:
            try:
                df_upload = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ Arquivo carregado: {len(df_upload)} registros")
                
                # Mostrar preview
                st.dataframe(df_upload.head(), use_container_width=True)
                
                if st.button("üîÆ Executar Predi√ß√µes em Lote"):
                    # Simular predi√ß√µes
                    predictions = np.random.choice(['<=50K', '>50K'], size=len(df_upload))
                    df_upload['prediction'] = predictions
                    
                    st.success("‚úÖ Predi√ß√µes conclu√≠das!")
                    st.dataframe(df_upload, use_container_width=True)
                    
                    # Download
                    csv = df_upload.to_csv(index=False)
                    st.download_button(
                        label="üì• Baixar Resultados",
                        data=csv,
                        file_name="predictions.csv",
                        mime="text/csv"
                    )
                    
            except Exception as e:
                st.error(f"‚ùå Erro ao processar arquivo: {e}")
    
    def _show_admin_page(self):
        """P√°gina de administra√ß√£o"""
        st.header("‚öôÔ∏è Painel de Administra√ß√£o")
        
        user_data = self.auth.get_user_data()
        if user_data.get('role') != 'admin':
            st.error("‚ùå Acesso negado. Apenas administradores podem acessar esta p√°gina.")
            return
        
        # Status do sistema
        st.subheader("üñ•Ô∏è Status do Sistema")
        
        # Informa√ß√µes do sistema
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            <div class="metric-card">
                <h4>üíæ Cache</h4>
                <p>Status: Ativo</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card">
                <h4>üìÅ Arquivos</h4>
                <p>Pipeline: Integrado</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card">
                <h4>üîê Autentica√ß√£o</h4>
                <p>Sistema: Ativo</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Controles administrativos
        st.subheader("üîß Controles Administrativos")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è Limpar Cache", use_container_width=True):
                self.data_cache = None
                st.success("‚úÖ Cache limpo!")
                st.rerun()
            
            if st.button("üîÑ Recarregar Sistema", use_container_width=True):
                st.success("‚úÖ Sistema recarregado!")
                st.rerun()
        
        with col2:
            if st.button("üìä Verificar Pipeline", use_container_width=True):
                self.data_cache = self._load_integrated_data()
                st.success("‚úÖ Pipeline verificado!")
                st.rerun()
            
            if st.button("üìÅ Escanear Arquivos", use_container_width=True):
                analysis_files = self._scan_pipeline_files()
                total_files = sum(len(v) if isinstance(v, list) else sum(len(vv) for vv in v.values()) for v in analysis_files.values())
                st.success(f"‚úÖ {total_files} arquivos encontrados!")
        
        # Logs e informa√ß√µes t√©cnicas
        st.subheader("üìã Informa√ß√µes T√©cnicas")
        
        with st.expander("üîç Detalhes do Sistema"):
            st.json({
                "dashboard_version": "2.0 - Integrado com main.py",
                "pipeline_integration": "Completa",
                "algorithms_supported": ["DBSCAN", "APRIORI", "FP-GROWTH", "ECLAT", "ML Models"],
                "visualization_formats": ["PNG", "JPG"],
                "data_formats": ["CSV", "JSON"],
                "authentication": "Simples com roles",
                "pages_count": len(self.pages),
                "output_directories": [str(d) for d in self.output_dirs.values()]
            })
        
        # Usu√°rios conectados (simulado)
        st.subheader("üë• Usu√°rios Conectados")
        
        # Simular dados de usu√°rios
        users_data = {
            'Usu√°rio': ['admin', 'user', 'demo'],
            'Status': ['üü¢ Online', 'üü° Idle', 'üî¥ Offline'],
            '√öltima Atividade': ['Agora', '5 min atr√°s', '1 hora atr√°s'],
            'P√°gina Atual': ['Administra√ß√£o', 'Vis√£o Geral', 'N/A']
        }
        
        df_users = pd.DataFrame(users_data)
        st.dataframe(df_users, use_container_width=True)
        
        # Configura√ß√µes
        st.subheader("‚öôÔ∏è Configura√ß√µes")
        
        with st.form("admin_settings"):
            st.markdown("**Configura√ß√µes do Dashboard:**")
            
            auto_refresh = st.checkbox("üîÑ Auto-refresh", value=False)
            debug_mode = st.checkbox("üêõ Modo Debug", value=False)
            cache_enabled = st.checkbox("üíæ Cache Habilitado", value=True)
            
            if st.form_submit_button("üíæ Salvar Configura√ß√µes"):
                st.success("‚úÖ Configura√ß√µes salvas!")

# =========================================================================
# EXECU√á√ÉO PRINCIPAL
# =========================================================================

def main():
    """Fun√ß√£o principal do dashboard integrado"""
    try:
        dashboard = IntegratedDashboard()
        dashboard.run()
    except Exception as e:
        st.error(f"‚ùå Erro cr√≠tico no dashboard: {e}")
        logging.error(f"Erro cr√≠tico: {e}")
        
        # Mostrar bot√£o de reset em caso de erro
        if st.button("üîÑ Reiniciar Dashboard"):
            st.rerun()

if __name__ == "__main__":
    main()