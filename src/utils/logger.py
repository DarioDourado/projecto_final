#!/usr/bin/env python3
"""
üîß Sistema de Logging Avan√ßado para Pipeline de An√°lise Salarial
Suporte completo para DBSCAN, APRIORI, FP-GROWTH, ECLAT
"""

import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any
import json

class ColoredFormatter(logging.Formatter):
    """Formatter colorido para melhor visualiza√ß√£o no terminal"""
    
    # C√≥digos de cores ANSI
    COLORS = {
        'DEBUG': '\033[36m',    
        'INFO': '\033[32m',     
        'WARNING': '\033[33m',  
        'ERROR': '\033[31m',   
        'CRITICAL': '\033[35m',
        'RESET': '\033[0m'
    }
    
    def format(self, record):
        # Aplicar cor baseada no n√≠vel
        color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        reset = self.COLORS['RESET']
        
        # Formata√ß√£o colorida
        record.levelname = f"{color}{record.levelname:8s}{reset}"
        
        return super().format(record)

class PipelineLogger:
    """Logger especializado para pipeline de an√°lise salarial"""
    
    def __init__(self, name: str = "SalaryAnalysis"):
        self.name = name
        self.logger = None
        self.log_file = None
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def setup(self, 
              log_level: str = "INFO",
              log_file: Optional[str] = None,
              enable_colors: bool = True,
              enable_file_rotation: bool = True) -> logging.Logger:
        """
        Configurar sistema de logging avan√ßado
        
        Args:
            log_level: N√≠vel de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)
            log_file: Caminho do arquivo de log (opcional)
            enable_colors: Habilitar cores no console
            enable_file_rotation: Habilitar rota√ß√£o de arquivos de log
        
        Returns:
            Logger configurado
        """
        # Criar diret√≥rio de logs
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # Configurar logger principal
        self.logger = logging.getLogger(self.name)
        self.logger.setLevel(getattr(logging, log_level.upper(), logging.INFO))
        
        # Limpar handlers existentes
        self._clear_handlers()
        
        # Configurar formatters
        console_formatter = ColoredFormatter(
            '%(asctime)s | %(levelname)s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        ) if enable_colors else logging.Formatter(
            '%(asctime)s | %(levelname)8s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        file_formatter = logging.Formatter(
            '%(asctime)s | %(levelname)8s | %(name)s | %(funcName)s:%(lineno)d | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # Handler para console
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(console_formatter)
        console_handler.setLevel(logging.INFO)
        self.logger.addHandler(console_handler)
        
        # Handler para arquivo
        if log_file:
            self.log_file = log_file
        else:
            self.log_file = log_dir / f"pipeline_{self.session_id}.log"
        
        if enable_file_rotation:
            from logging.handlers import RotatingFileHandler
            file_handler = RotatingFileHandler(
                self.log_file,
                maxBytes=10*1024*1024,  # 10MB
                backupCount=5,
                encoding='utf-8'
            )
        else:
            file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG)
        self.logger.addHandler(file_handler)
        
        # Log inicial
        self.logger.info(f"üöÄ Logger inicializado para {self.name}")
        self.logger.info(f"üìÅ Logs salvos em: {self.log_file}")
        self.logger.info(f"üîç N√≠vel de log: {log_level}")
        self.logger.info(f"üÜî Session ID: {self.session_id}")
        
        return self.logger
    
    def _clear_handlers(self):
        """Limpar handlers existentes para evitar duplica√ß√£o"""
        for handler in self.logger.handlers[:]:
            handler.close()
            self.logger.removeHandler(handler)
    
    def log_algorithm_start(self, algorithm: str, params: Dict[str, Any] = None):
        """Log espec√≠fico para in√≠cio de algoritmo"""
        self.logger.info(f"üéØ INICIANDO {algorithm.upper()}")
        self.logger.info("=" * 60)
        if params:
            self.logger.info(f"üìã Par√¢metros: {json.dumps(params, indent=2, ensure_ascii=False)}")
    
    def log_algorithm_end(self, algorithm: str, results: Dict[str, Any]):
        """Log espec√≠fico para fim de algoritmo"""
        self.logger.info(f"‚úÖ {algorithm.upper()} CONCLU√çDO")
        if 'execution_time' in results:
            self.logger.info(f"‚è±Ô∏è Tempo de execu√ß√£o: {results['execution_time']:.2f}s")
        if 'results_count' in results:
            self.logger.info(f"üìä Resultados gerados: {results['results_count']}")
        self.logger.info("=" * 60)
    
    def log_data_info(self, df, source: str = "Unknown"):
        """Log informa√ß√µes sobre os dados carregados"""
        if df is not None:
            self.logger.info(f"üìä DADOS CARREGADOS ({source})")
            self.logger.info(f"   ‚Ä¢ Registros: {len(df):,}")
            self.logger.info(f"   ‚Ä¢ Colunas: {len(df.columns)}")
            self.logger.info(f"   ‚Ä¢ Fonte: {source}")
            self.logger.info(f"   ‚Ä¢ Mem√≥ria: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
            
            # Tipos de dados
            numeric_cols = len(df.select_dtypes(include=['number']).columns)
            categorical_cols = len(df.select_dtypes(include=['object']).columns)
            self.logger.info(f"   ‚Ä¢ Num√©ricas: {numeric_cols} | Categ√≥ricas: {categorical_cols}")
        else:
            self.logger.error("‚ùå Dados n√£o carregados")
    
    def log_error_with_context(self, error: Exception, context: str = ""):
        """Log de erro com contexto adicional"""
        self.logger.error(f"‚ùå ERRO: {context}")
        self.logger.error(f"   ‚Ä¢ Tipo: {type(error).__name__}")
        self.logger.error(f"   ‚Ä¢ Mensagem: {str(error)}")
        
        # Stack trace detalhado no arquivo de log
        import traceback
        self.logger.debug("üìã STACK TRACE COMPLETO:")
        self.logger.debug(traceback.format_exc())
    
    def log_performance_metrics(self, metrics: Dict[str, Any]):
        """Log de m√©tricas de performance"""
        self.logger.info("üìà M√âTRICAS DE PERFORMANCE:")
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                if 'time' in key.lower():
                    self.logger.info(f"   ‚Ä¢ {key}: {value:.2f}s")
                elif 'memory' in key.lower():
                    self.logger.info(f"   ‚Ä¢ {key}: {value:.1f} MB")
                else:
                    self.logger.info(f"   ‚Ä¢ {key}: {value}")
            else:
                self.logger.info(f"   ‚Ä¢ {key}: {value}")
    
    def create_algorithm_logger(self, algorithm: str) -> logging.Logger:
        """Criar logger espec√≠fico para um algoritmo"""
        algo_logger = logging.getLogger(f"{self.name}.{algorithm}")
        algo_logger.setLevel(self.logger.level)
        
        # Herdar handlers do logger principal
        for handler in self.logger.handlers:
            algo_logger.addHandler(handler)
        
        # Evitar propaga√ß√£o dupla
        algo_logger.propagate = False
        
        return algo_logger

# Fun√ß√£o de compatibilidade com c√≥digo existente
def setup_logging(log_level: str = "INFO", 
                 log_file: Optional[str] = None,
                 enable_colors: bool = True) -> logging.Logger:
    """
    Fun√ß√£o de compatibilidade para manter c√≥digo existente funcionando
    
    Args:
        log_level: N√≠vel de log
        log_file: Arquivo de log (opcional)
        enable_colors: Habilitar cores
    
    Returns:
        Logger configurado
    """
    pipeline_logger = PipelineLogger("SalaryAnalysis")
    return pipeline_logger.setup(
        log_level=log_level,
        log_file=log_file,
        enable_colors=enable_colors
    )

# Logger global para uso r√°pido
_global_logger = None

def get_logger(name: str = "SalaryAnalysis") -> logging.Logger:
    """Obter logger global configurado"""
    global _global_logger
    if _global_logger is None:
        _global_logger = setup_logging()
    return _global_logger

def log_algorithm_execution(algorithm: str):
    """Decorator para log autom√°tico de execu√ß√£o de algoritmos"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger = get_logger()
            start_time = datetime.now()
            
            logger.info(f"üéØ Executando {algorithm}...")
            
            try:
                result = func(*args, **kwargs)
                
                end_time = datetime.now()
                execution_time = (end_time - start_time).total_seconds()
                
                logger.info(f"‚úÖ {algorithm} conclu√≠do em {execution_time:.2f}s")
                return result
                
            except Exception as e:
                end_time = datetime.now()
                execution_time = (end_time - start_time).total_seconds()
                
                logger.error(f"‚ùå {algorithm} falhou ap√≥s {execution_time:.2f}s: {e}")
                raise
                
        return wrapper
    return decorator

# Configura√ß√£o padr√£o para o projeto
def setup_project_logging():
    """Configurar logging padr√£o para todo o projeto"""
    pipeline_logger = PipelineLogger("SalaryAnalysisPipeline")
    logger = pipeline_logger.setup(
        log_level="INFO",
        enable_colors=True,
        enable_file_rotation=True
    )
    
    # Configurar loggers espec√≠ficos para cada m√≥dulo
    modules = ['clustering', 'association_rules', 'ml_pipeline', 'database']
    
    for module in modules:
        module_logger = pipeline_logger.create_algorithm_logger(module)
        module_logger.info(f"üîß Logger configurado para m√≥dulo {module}")
    
    return logger

if __name__ == "__main__":
    logger = setup_project_logging()
    
    logger.info("üß™ Testando sistema de logging...")
    logger.debug("Debug message")
    logger.warning("Warning message")
    logger.error("Error message")
    
    # Teste de decorator
    @log_algorithm_execution("TESTE_ALGORITHM")
    def test_function():
        import time
        time.sleep(1)
        return "Resultado teste"
    
    result = test_function()
    logger.info(f"Resultado: {result}")