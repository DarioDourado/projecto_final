"""
UtilitÃ¡rios para mostrar melhorias de legibilidade no processamento de dados
Preparado para futuro suporte multilingual
Mensagens em PortuguÃªs de Portugal
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
import logging

class ReadabilityInsights:
    """Classe para gerar insights sobre as melhorias de legibilidade"""
    
    def __init__(self):
        self.enhancement_report = None
        self.load_enhancement_report()
    
    def load_enhancement_report(self):
        """Carregar relatÃ³rio de melhorias"""
        report_path = Path("data/processed/enhancement_report.json")
        
        if report_path.exists():
            try:
                with open(report_path, 'r', encoding='utf-8') as f:
                    self.enhancement_report = json.load(f)
                logging.info("âœ… RelatÃ³rio de melhorias carregado")
            except Exception as e:
                logging.warning(f"âš ï¸ Erro ao carregar relatÃ³rio: {e}")
                self.enhancement_report = None
    
    def show_enhancement_summary(self):
        """Mostrar resumo das melhorias aplicadas"""
        if not self.enhancement_report:
            print("âš ï¸ RelatÃ³rio de melhorias nÃ£o encontrado. Execute o processamento primeiro.")
            return
        
        print("="*60)
        print("ğŸ“Š RESUMO DAS MELHORIAS DE LEGIBILIDADE")
        print("="*60)
        
        # Verificar estrutura do relatÃ³rio
        summary = self.enhancement_report.get('summary', {})
        column_enhancements = self.enhancement_report.get('column_enhancements', {})
        
        # EstatÃ­sticas gerais
        total_columns = summary.get('total_columns_enhanced', len(column_enhancements))
        avg_mapping_rate = summary.get('average_mapping_rate', 0.0)
        
        print(f"ğŸ”„ Colunas melhoradas: {total_columns}")
        print(f"ğŸ“ˆ Taxa mÃ©dia de mapeamento: {avg_mapping_rate:.1%}")
        
        if column_enhancements:
            print("\nğŸ“ Colunas Processadas:")
            for col_name, col_data in column_enhancements.items():
                mapped_values = col_data.get('mapped_values', 0)
                total_values = col_data.get('total_values', 0)
                mapping_rate = col_data.get('mapping_rate', 0.0)
                
                print(f"  â€¢ {col_name}: {mapped_values}/{total_values} valores mapeados ({mapping_rate:.1%})")
        
        # Mostrar exemplos de melhorias se disponÃ­veis
        print("\nğŸ“ Exemplos de Melhorias:")
        examples_shown = 0
        for column, col_data in column_enhancements.items():
            if examples_shown >= 3:  # Limitar a 3 colunas
                break
            
            mappings_applied = col_data.get('mappings_applied', {})
            if mappings_applied:
                print(f"\n  ğŸ“‚ {column.upper()}:")
                for original, enhanced in list(mappings_applied.items())[:3]:  # Top 3 por coluna
                    print(f"    {original} â†’ {enhanced}")
                examples_shown += 1
        
        if not column_enhancements:
            print("  ğŸ“ Nenhuma melhoria especÃ­fica registrada")
    
    def compare_readability(self, original_df, processed_df):
        """Comparar legibilidade antes e depois do processamento"""
        print("\n" + "="*60)
        print("ğŸ“Š COMPARAÃ‡ÃƒO DE LEGIBILIDADE")
        print("="*60)
        
        # Comparar nÃºmero de colunas
        print(f"ğŸ“Š Colunas originais: {len(original_df.columns)}")
        print(f"ğŸ“Š Colunas melhoradas: {len(processed_df.columns)}")
        
        new_columns = len(processed_df.columns) - len(original_df.columns)
        if new_columns > 0:
            print(f"â• Novas colunas interpretÃ¡veis: {new_columns}")
        
        # Mostrar exemplos de colunas melhoradas
        enhanced_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship']
        
        for col in enhanced_columns:
            if col in original_df.columns and col in processed_df.columns:
                print(f"\nğŸ”„ COLUNA: {col.upper()}")
                
                try:
                    # Valores Ãºnicos originais vs melhorados
                    original_unique = set(original_df[col].dropna().astype(str).unique())
                    enhanced_unique = set(processed_df[col].dropna().astype(str).unique())
                    
                    print(f"  ğŸ“ˆ Valores Ãºnicos originais: {len(original_unique)}")
                    print(f"  ğŸ“ˆ Valores Ãºnicos melhorados: {len(enhanced_unique)}")
                    
                    # Mostrar algumas melhorias
                    print(f"  ğŸ“ Exemplos de melhorias:")
                    sample_original = list(original_unique)[:3]
                    for orig_val in sample_original:
                        # Encontrar valor melhorado correspondente
                        mask = original_df[col].astype(str) == orig_val
                        if mask.any():
                            try:
                                enhanced_val = processed_df.loc[mask, col].iloc[0]
                                if str(orig_val) != str(enhanced_val):
                                    print(f"    {orig_val} â†’ {enhanced_val}")
                            except:
                                continue
                except Exception as e:
                    print(f"  âš ï¸ Erro ao processar coluna {col}: {e}")
                    continue
    
    def show_new_features_distribution(self, df):
        """Mostrar distribuiÃ§Ã£o das novas features interpretÃ¡veis"""
        print("\n" + "="*60)
        print("ğŸ“Š DISTRIBUIÃ‡ÃƒO DAS NOVAS FEATURES INTERPRETÃVEIS")
        print("="*60)
        
        # Procurar colunas que parecem ser novas features
        new_feature_patterns = ['age_group', 'work_schedule', 'education_level', 'investment_profile']
        
        found_features = [col for col in df.columns if any(pattern in col for pattern in new_feature_patterns)]
        
        if not found_features:
            print("ğŸ“ Nenhuma nova feature interpretÃ¡vel encontrada")
            return
        
        for col in found_features:
            print(f"\nğŸ“ˆ {col.upper().replace('_', ' ')}:")
            try:
                value_counts = df[col].value_counts()
                total = len(df)
                
                for value, count in value_counts.head(5).items():
                    percentage = (count / total) * 100
                    print(f"  â€¢ {value}: {count:,} ({percentage:.1f}%)")
                
                if len(value_counts) > 5:
                    others = len(value_counts) - 5
                    print(f"  â€¢ ... e mais {others} categorias")
            except Exception as e:
                print(f"  âš ï¸ Erro ao processar {col}: {e}")
    
    def show_multilingual_readiness(self):
        """Mostrar como os dados estÃ£o preparados para suporte multilingual"""
        print("\n" + "="*60)
        print("ğŸŒ PREPARAÃ‡ÃƒO PARA MULTILINGUAL")
        print("="*60)
        
        print("âœ… Estrutura de dados otimizada para traduÃ§Ã£o:")
        print("  â€¢ Categorias claras e descritivas em inglÃªs")
        print("  â€¢ ConvenÃ§Ãµes de nomenclatura consistentes")
        print("  â€¢ NÃ­veis educacionais hierÃ¡rquicos")
        print("  â€¢ Grupos etÃ¡rios padronizados")
        print("  â€¢ Categorias de horas de trabalho interpretÃ¡veis")
        print("  â€¢ ClassificaÃ§Ãµes de perfis de investimento")
        
        print("\nğŸ”„ Pronto para implementaÃ§Ã£o futura:")
        print("  â€¢ Tabelas de mapeamento de traduÃ§Ãµes")
        print("  â€¢ SeleÃ§Ã£o de idioma no dashboard")
        print("  â€¢ ApresentaÃ§Ã£o de categorias localizadas")
        print("  â€¢ RelatÃ³rios multi-idioma")
        
        print("\nğŸ’¡ BenefÃ­cios atuais:")
        print("  â€¢ Nomes de categorias mais intuitivos")
        print("  â€¢ Melhor compreensÃ£o do utilizador")
        print("  â€¢ Insights de dados mais claros")
        print("  â€¢ ApresentaÃ§Ã£o profissional")
    
    def generate_readability_report(self, original_df, processed_df):
        """Gerar relatÃ³rio completo de melhorias de legibilidade"""
        print("\n" + "="*80)
        print("ğŸ“ RELATÃ“RIO COMPLETO DE MELHORIAS DE LEGIBILIDADE")
        print("="*80)
        
        # Resumo das melhorias
        self.show_enhancement_summary()
        
        # ComparaÃ§Ã£o antes/depois
        self.compare_readability(original_df, processed_df)
        
        # DistribuiÃ§Ã£o das novas features
        self.show_new_features_distribution(processed_df)
        
        # PreparaÃ§Ã£o multilingual
        self.show_multilingual_readiness()
        
        # Insights adicionais
        print("\n" + "="*60)
        print("ğŸ’¡ INSIGHTS ADICIONAIS")
        print("="*60)
        
        # AnÃ¡lise de completude
        try:
            original_missing = original_df.isnull().sum().sum()
            processed_missing = processed_df.isnull().sum().sum()
            
            print(f"ğŸ“Š Valores em falta originais: {original_missing:,}")
            print(f"ğŸ“Š Valores em falta processados: {processed_missing:,}")
            
            if original_missing >= processed_missing:
                improvement = original_missing - processed_missing
                print(f"âœ… Melhoria nos valores em falta: {improvement:,}")
            else:
                print("ğŸ“ Estrutura de dados mantida")
        except Exception as e:
            print(f"âš ï¸ Erro ao calcular completude: {e}")
        
        # AnÃ¡lise da variÃ¡vel target
        if 'salary' in processed_df.columns:
            try:
                target_dist = processed_df['salary'].value_counts()
                print(f"\nğŸ¯ DISTRIBUIÃ‡ÃƒO DA VARIÃVEL ALVO:")
                for value, count in target_dist.items():
                    percentage = (count / len(processed_df)) * 100
                    print(f"  â€¢ {value}: {count:,} ({percentage:.1f}%)")
            except Exception as e:
                print(f"âš ï¸ Erro ao analisar variÃ¡vel alvo: {e}")
        
        print("\nğŸ‰ Os dados estÃ£o agora mais legÃ­veis e amigÃ¡veis ao utilizador!")
        print("ğŸ’¡ As categorias sÃ£o descritivas e profissionais.")
        print("ğŸ“Š Novas features interpretÃ¡veis melhoram as capacidades de anÃ¡lise.")
        print("ğŸŒ A estrutura estÃ¡ pronta para futuro suporte multilingual.")

def show_readability_insights():
    """FunÃ§Ã£o principal para mostrar melhorias de legibilidade"""
    try:
        # Carregar dados originais e processados
        original_path = Path("data/raw/4-Carateristicas_salario.csv")
        processed_path = Path("data/processed/data_processed.csv")
        
        if not original_path.exists():
            print("âŒ Dados originais nÃ£o encontrados!")
            return
        
        if not processed_path.exists():
            print("âŒ Dados processados nÃ£o encontrados! Execute o pipeline primeiro.")
            return
        
        # Carregar dados de forma segura
        try:
            original_df = pd.read_csv(original_path)
            processed_df = pd.read_csv(processed_path)
            
            print(f"âœ… Dados carregados: {len(original_df)} â†’ {len(processed_df)} registros")
            
        except Exception as e:
            print(f"âŒ Erro ao carregar dados: {e}")
            return
        
        # Gerar insights
        insights = ReadabilityInsights()
        insights.generate_readability_report(original_df, processed_df)
        
    except Exception as e:
        print(f"âŒ Erro ao gerar insights: {e}")
        logging.error(f"Erro em readability insights: {e}")

if __name__ == "__main__":
    show_readability_insights()