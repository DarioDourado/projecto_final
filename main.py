"""
Pipeline Principal SQL-Only - Sistema Exclusivo de Banco de Dados
Vers√£o sem depend√™ncia de CSV - CORRIGIDA
"""

import sys
import logging
import os
from pathlib import Path
import argparse

# Carregar vari√°veis de ambiente PRIMEIRO
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # Se python-dotenv n√£o estiver instalado, carregar manualmente
    env_file = Path('.env')
    if env_file.exists():
        with open(env_file) as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

# Imports b√°sicos
from src.utils.logger import setup_logging
from src.visualization.styles import setup_matplotlib_style

# Imports com fallback para MySQL
try:
    import mysql.connector
    MYSQL_AVAILABLE = True
except ImportError:
    try:
        import pymysql
        pymysql.install_as_MySQLdb()
        MYSQL_AVAILABLE = True
        print("‚ö†Ô∏è  Usando PyMySQL como fallback")
    except ImportError:
        MYSQL_AVAILABLE = False
        print("‚ùå Nenhum driver MySQL dispon√≠vel")

# Verificar antes de inicializar pipeline
if not MYSQL_AVAILABLE:
    print("‚ùå Driver MySQL n√£o encontrado")
    print("üí° Instale: pip install mysql-connector-python")
    sys.exit(1)

class MasterPipelineSQL:
    """Pipeline principal exclusivo para banco de dados"""
    
    def __init__(self, force_migration: bool = False):
        # Configurar logging PRIMEIRO
        self.logger = setup_logging()
        self.force_migration = force_migration
        
        # Verificar configura√ß√£o de banco OBRIGAT√ìRIA
        if not self._check_database_config():
            raise ValueError("‚ùå Configura√ß√£o de banco de dados obrigat√≥ria!")
        
        # Inicializar pipelines com tratamento de erro
        self._initialize_pipelines()
        
        # Resultados
        self.df = None
        self.models = {}
        self.results = {}
        self.best_k = None
        self.rules = []
    
    def _initialize_pipelines(self):
        """Inicializar pipelines com tratamento de erro"""
        try:
            from src.pipelines.data_pipeline import DataPipelineSQL
            from src.pipelines.ml_pipeline import MLPipeline
            from src.pipelines.analysis_pipeline import AnalysisPipeline
            from src.pipelines.performance_pipeline import PerformancePipeline
            
            self.data_pipeline = DataPipelineSQL(force_migration=self.force_migration)
            self.ml_pipeline = MLPipeline()
            self.analysis_pipeline = AnalysisPipeline()
            self.performance_pipeline = PerformancePipeline()
            
            self.logger.info("‚úÖ Pipelines inicializados com sucesso")
            
        except ImportError as e:
            self.logger.error(f"‚ùå Erro ao importar pipelines: {e}")
            self.logger.error("üí° Verifique se todos os m√≥dulos est√£o implementados")
            raise
        except Exception as e:
            self.logger.error(f"‚ùå Erro na inicializa√ß√£o dos pipelines: {e}")
            raise
    
    def _check_database_config(self) -> bool:
        """Verificar configura√ß√£o obrigat√≥ria do banco"""
        required_vars = ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            if hasattr(self, 'logger'):
                self.logger.error(f"‚ùå Vari√°veis de ambiente ausentes: {missing_vars}")
            else:
                print(f"‚ùå Vari√°veis de ambiente ausentes: {missing_vars}")
            
            print("üí° Configure as vari√°veis de ambiente:")
            print("   export DB_HOST=localhost")
            print("   export DB_NAME=salary_analysis")
            print("   export DB_USER=salary_user")
            print("   export DB_PASSWORD=senha_forte")
            print("üîß Ou crie arquivo .env com essas vari√°veis")
            return False
        
        if hasattr(self, 'logger'):
            self.logger.info("‚úÖ Configura√ß√£o de banco de dados encontrada")
        return True
    
    def run(self):
        """Executar pipeline completo SQL-only com tratamento robusto de erros"""
        self.logger.info("üöÄ Sistema de An√°lise Salarial - VERS√ÉO SQL EXCLUSIVA")
        self.logger.info("üóÑÔ∏è Fonte de dados: BANCO DE DADOS MySQL")
        self.logger.info("="*60)
        
        try:
            # 0. Configura√ß√µes iniciais
            self._setup()
            
            # 1. Pipeline de dados SQL
            self.logger.info("\nüìä PIPELINE DE DADOS SQL")
            self.logger.info("-" * 40)
            self.df = self.data_pipeline.run()
            
            if self.df is None or len(self.df) == 0:
                raise ValueError("‚ùå Nenhum dado carregado do banco")
            
            self.logger.info(f"‚úÖ Dados carregados: {len(self.df)} registros")
            
            # 2. Pipeline de ML com tratamento de erro
            self.logger.info("\nü§ñ PIPELINE DE ML")
            self.logger.info("-" * 40)
            try:
                self.models, self.results = self.ml_pipeline.run(self.df)
                
                if not self.models:
                    self.logger.warning("‚ö†Ô∏è Nenhum modelo foi treinado com sucesso")
                else:
                    self.logger.info(f"‚úÖ {len(self.models)} modelos treinados")
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erro no pipeline ML: {e}")
                self.logger.warning("‚ö†Ô∏è Continuando sem modelos ML...")
                self.models = {}
                self.results = {}
            
            # 3. Pipeline de performance (apenas se houver modelos)
            if self.models:
                self.logger.info("\nüìà PIPELINE DE PERFORMANCE")
                self.logger.info("-" * 40)
                try:
                    self.performance_pipeline.run(self.models, self.results, self.df)
                except Exception as e:
                    self.logger.error(f"‚ùå Erro no pipeline de performance: {e}")
            else:
                self.logger.info("\n‚ö†Ô∏è Pulando pipeline de performance (sem modelos)")
            
            # 4. Pipelines de an√°lise
            self.logger.info("\nüéØ PIPELINE DE AN√ÅLISES")
            self.logger.info("-" * 40)
            
            # Clustering
            try:
                self.best_k = self.analysis_pipeline.run_clustering(self.df)
                if self.best_k:
                    self.logger.info(f"‚úÖ Clustering: {self.best_k} clusters identificados")
            except Exception as e:
                self.logger.error(f"‚ùå Erro no clustering: {e}")
                self.best_k = None
            
            # Regras de associa√ß√£o
            try:
                self.rules = self.analysis_pipeline.run_association_rules(self.df)
                if self.rules:
                    self.logger.info(f"‚úÖ {len(self.rules)} regras de associa√ß√£o encontradas")
            except Exception as e:
                self.logger.error(f"‚ùå Erro nas regras de associa√ß√£o: {e}")
                self.rules = []
            
            # M√©tricas avan√ßadas
            try:
                self.analysis_pipeline.run_advanced_metrics(self.df, self.results)
                self.logger.info("‚úÖ M√©tricas avan√ßadas calculadas")
            except Exception as e:
                self.logger.error(f"‚ùå Erro nas m√©tricas avan√ßadas: {e}")
            
            # 5. Criar views SQL de an√°lise
            self.logger.info("\nüóÑÔ∏è CRIANDO VIEWS DE AN√ÅLISE")
            self.logger.info("-" * 40)
            try:
                self.data_pipeline.create_analysis_views()
                self.logger.info("‚úÖ Views SQL de an√°lise criadas")
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao criar views SQL: {e}")
            
            # 6. Relat√≥rio final
            self._generate_final_report()
            
            self.logger.info("\nüéâ Pipeline SQL conclu√≠do com sucesso!")
            self.logger.info("üìä Para visualizar: streamlit run app.py")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro cr√≠tico durante execu√ß√£o: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            
            # Relat√≥rio de emerg√™ncia
            self._emergency_report()
            raise
    
    def _setup(self):
        """Configura√ß√µes iniciais SQL-only"""
        try:
            # Configurar estilo de visualiza√ß√£o
            setup_matplotlib_style()
            
            # Testar conex√£o com banco
            self._test_database_connection()
            
            self.logger.info("‚úÖ Configura√ß√µes SQL iniciais conclu√≠das")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na configura√ß√£o: {e}")
            raise
    
    def _test_database_connection(self):
        """Testar conex√£o com banco de dados"""
        try:
            from src.database.connection import DatabaseConnection
            
            with DatabaseConnection() as db:
                result = db.execute_query("SELECT 1 as test")
                if result:
                    self.logger.info("‚úÖ Conex√£o com banco de dados funcionando")
                else:
                    raise ValueError("Teste de conex√£o falhou")
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erro na conex√£o com banco: {e}")
            self.logger.error("üí° Verifique se MySQL est√° rodando e credenciais est√£o corretas")
            raise
    
    def _generate_final_report(self):
        """Gerar relat√≥rio final SQL"""
        self.logger.info("\n" + "="*60)
        self.logger.info("üìä RELAT√ìRIO FINAL DO PIPELINE SQL")
        self.logger.info("="*60)
        
        # Estat√≠sticas do banco
        try:
            if hasattr(self.data_pipeline, 'get_statistics_from_sql'):
                stats = self.data_pipeline.get_statistics_from_sql()
                total_records = stats.get('total_records', 0)
                self.logger.info(f"üìã Registros no banco: {total_records:,}")
                
                if 'salary_stats' in stats:
                    self.logger.info("üí∞ Distribui√ß√£o salarial:")
                    for salary_stat in stats['salary_stats']:
                        salary_range = salary_stat.get('salary_range', 'N/A')
                        count = salary_stat.get('count', 0)
                        avg_age = salary_stat.get('avg_age', 0)
                        self.logger.info(f"   ‚Ä¢ {salary_range}: {count:,} pessoas (idade m√©dia: {avg_age:.1f})")
        
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erro nas estat√≠sticas SQL: {e}")
        
        # Dados processados
        if self.df is not None:
            self.logger.info(f"üìä Dataset ML: {len(self.df)} registros processados")
            self.logger.info(f"üìã Colunas: {list(self.df.columns)}")
        
        # Modelos treinados
        if self.results:
            self.logger.info("ü§ñ Modelos treinados:")
            for name, result in self.results.items():
                accuracy = result.get('accuracy', 0)
                self.logger.info(f"   ‚Ä¢ {name}: Acur√°cia = {accuracy:.4f}")
        else:
            self.logger.info("ü§ñ Nenhum modelo ML foi treinado")
        
        # Clustering
        if self.best_k:
            self.logger.info(f"üéØ Clustering: {self.best_k} clusters identificados")
        else:
            self.logger.info("üéØ Clustering: N√£o executado")
        
        # Regras de associa√ß√£o
        rules_count = len(self.rules) if self.rules else 0
        self.logger.info(f"üìã Regras de associa√ß√£o: {rules_count} encontradas")
        
        # Arquivos gerados
        self._show_generated_files()
        
        # Instru√ß√µes finais
        self.logger.info("\nüí° Pr√≥ximos passos:")
        self.logger.info("   ‚Ä¢ Dashboard: streamlit run app.py")
        self.logger.info("   ‚Ä¢ An√°lises SQL: Use views criadas no banco")
        self.logger.info("   ‚Ä¢ Modelos salvos em: data/processed/")
        self.logger.info("   ‚Ä¢ Visualiza√ß√µes em: output/images/")
    
    def _show_generated_files(self):
        """Mostrar arquivos gerados"""
        # Verificar diret√≥rio de output
        output_dir = Path("output")
        if output_dir.exists():
            # Imagens
            images_dir = output_dir / "images"
            if images_dir.exists():
                image_files = list(images_dir.glob("*.png"))
                self.logger.info(f"üé® {len(image_files)} visualiza√ß√µes em output/images/")
            
            # An√°lises
            analysis_dir = output_dir / "analysis"
            if analysis_dir.exists():
                analysis_files = list(analysis_dir.glob("*"))
                self.logger.info(f"üìä {len(analysis_files)} an√°lises em output/analysis/")
        
        # Modelos salvos
        processed_dir = Path("data/processed")
        if processed_dir.exists():
            model_files = list(processed_dir.glob("*.joblib"))
            self.logger.info(f"ü§ñ {len(model_files)} modelos salvos em data/processed/")
    
    def _emergency_report(self):
        """Relat√≥rio de emerg√™ncia quando pipeline falha"""
        self.logger.info("\nüö® RELAT√ìRIO DE EMERG√äNCIA")
        self.logger.info("="*40)
        
        if self.df is not None:
            self.logger.info(f"üìä Dados carregados: {len(self.df)} registros")
        else:
            self.logger.info("‚ùå Nenhum dado foi carregado")
        
        self.logger.info(f"ü§ñ Modelos criados: {len(self.models)}")
        self.logger.info(f"üìä Resultados: {len(self.results)}")
        
        self.logger.info("\nüí° Para diagn√≥stico:")
        self.logger.info("   ‚Ä¢ Verificar logs detalhados acima")
        self.logger.info("   ‚Ä¢ Testar conex√£o: mysql -u salary_user -p salary_analysis")
        self.logger.info("   ‚Ä¢ Verificar estrutura: python main.py --setup-db")

def main():
    """Fun√ß√£o principal SQL-only"""
    parser = argparse.ArgumentParser(description="Sistema de An√°lise Salarial SQL-Only")
    parser.add_argument('--migrate', action='store_true', 
                       help='For√ßar migra√ß√£o CSV‚ÜíSQL (se CSV dispon√≠vel)')
    parser.add_argument('--setup-db', action='store_true',
                       help='Apenas configurar estrutura do banco')
    
    args = parser.parse_args()
    
    # Verificar vari√°veis de ambiente primeiro
    required_vars = ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print("‚ùå ERRO: Configura√ß√£o de banco de dados obrigat√≥ria!")
        print(f"‚ùå Vari√°veis ausentes: {missing_vars}")
        print("\nüí° Configure as vari√°veis de ambiente:")
        print("export DB_HOST=localhost")
        print("export DB_NAME=salary_analysis")
        print("export DB_USER=salary_user")
        print("export DB_PASSWORD=senha_forte")
        print("\nüîß Ou crie arquivo .env com essas vari√°veis")
        print("\nüìã Exemplo de .env:")
        print("DB_HOST=localhost")
        print("DB_NAME=salary_analysis")
        print("DB_USER=salary_user")
        print("DB_PASSWORD=senha_forte")
        return
    
    # Setup apenas da estrutura do banco
    if args.setup_db:
        try:
            print("üîß Configurando estrutura do banco de dados...")
            from src.database.migration import DatabaseMigrator
            
            migrator = DatabaseMigrator()
            if migrator.create_database_structure():
                print("‚úÖ Estrutura do banco criada com sucesso!")
                print("üí° Agora execute: python main.py")
            else:
                print("‚ùå Erro ao criar estrutura do banco")
                
        except ImportError as e:
            print(f"‚ùå Erro ao importar DatabaseMigrator: {e}")
            print("üí° Verifique se o m√≥dulo src.database.migration existe")
        except Exception as e:
            print(f"‚ùå Erro: {e}")
        return
    
    # Executar pipeline principal
    try:
        print("üöÄ Iniciando Sistema de An√°lise Salarial...")
        pipeline = MasterPipelineSQL(force_migration=args.migrate)
        pipeline.run()
        
        print("\nüéâ Pipeline executado com sucesso!")
        print("üìä Para visualizar resultados: streamlit run app.py")
        
    except ValueError as e:
        print(f"\n‚ùå ERRO DE CONFIGURA√á√ÉO: {e}")
        print("\nüí° Solu√ß√µes:")
        print("  1. Verificar vari√°veis de ambiente")
        print("  2. Criar estrutura: python main.py --setup-db")
        print("  3. Testar conex√£o: mysql -u salary_user -p salary_analysis")
        
    except ImportError as e:
        print(f"\n‚ùå ERRO DE IMPORTA√á√ÉO: {e}")
        print("\nüí° Solu√ß√µes:")
        print("  1. Verificar se todos os m√≥dulos existem em src/")
        print("  2. Verificar depend√™ncias: pip install -r requirements.txt")
        
    except Exception as e:
        print(f"\n‚ùå ERRO CR√çTICO: {e}")
        print("\nüí° Solu√ß√µes poss√≠veis:")
        print("  1. Verificar conex√£o: mysql -u salary_user -p salary_analysis")
        print("  2. Recriar estrutura: python main.py --setup-db")
        print("  3. Migrar dados: python main.py --migrate")
        print("  4. Verificar logs detalhados nos arquivos de log")

if __name__ == "__main__":
    main()