"""
Pipeline Principal SQL-Only - Sistema Exclusivo de Banco de Dados
VersÃ£o sem dependÃªncia de CSV - CORRIGIDA
"""

import sys
import logging
import os
from pathlib import Path
import argparse

# Carregar variÃ¡veis de ambiente PRIMEIRO
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # Se python-dotenv nÃ£o estiver instalado, carregar manualmente
    env_file = Path('.env')
    if env_file.exists():
        with open(env_file) as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

# Imports bÃ¡sicos
from src.utils.logger import setup_logging
from src.visualization.styles import setup_matplotlib_style

# Imports com fallback para MySQL
try:
    import mysql.connector
    MYSQL_AVAILABLE = True
except ImportError:
    try:
        import pymysql
        pymysql.install_as_MySQLdb()
        MYSQL_AVAILABLE = True
        print("âš ï¸  Usando PyMySQL como fallback")
    except ImportError:
        MYSQL_AVAILABLE = False
        print("âŒ Nenhum driver MySQL disponÃ­vel")

# Verificar antes de inicializar pipeline
if not MYSQL_AVAILABLE:
    print("âŒ Driver MySQL nÃ£o encontrado")
    print("ğŸ’¡ Instale: pip install mysql-connector-python")
    sys.exit(1)

class MasterPipelineSQL:
    """Pipeline principal exclusivo para banco de dados"""
    
    def __init__(self, force_migration: bool = False):
        # Configurar logging PRIMEIRO
        self.logger = setup_logging()
        self.force_migration = force_migration
        
        # Verificar configuraÃ§Ã£o de banco OBRIGATÃ“RIA
        if not self._check_database_config():
            raise ValueError("âŒ ConfiguraÃ§Ã£o de banco de dados obrigatÃ³ria!")
        
        # Inicializar pipelines com tratamento de erro
        self._initialize_pipelines()
        
        # Resultados
        self.df = None
        self.models = {}
        self.results = {}
        self.best_k = None
        self.rules = []
    
    def _initialize_pipelines(self):
        """Inicializar pipelines com tratamento de erro"""
        try:
            from src.pipelines.data_pipeline import DataPipelineSQL
            from src.pipelines.ml_pipeline import MLPipeline
            from src.pipelines.analysis_pipeline import AnalysisPipeline
            from src.pipelines.performance_pipeline import PerformancePipeline
            
            self.data_pipeline = DataPipelineSQL(force_migration=self.force_migration)
            self.ml_pipeline = MLPipeline()
            self.analysis_pipeline = AnalysisPipeline()
            self.performance_pipeline = PerformancePipeline()
            
            self.logger.info("âœ… Pipelines inicializados com sucesso")
            
        except ImportError as e:
            self.logger.error(f"âŒ Erro ao importar pipelines: {e}")
            self.logger.error("ğŸ’¡ Verifique se todos os mÃ³dulos estÃ£o implementados")
            raise
        except Exception as e:
            self.logger.error(f"âŒ Erro na inicializaÃ§Ã£o dos pipelines: {e}")
            raise
    
    def _check_database_config(self) -> bool:
        """Verificar configuraÃ§Ã£o obrigatÃ³ria do banco"""
        required_vars = ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ VariÃ¡veis de ambiente ausentes: {missing_vars}")
            else:
                print(f"âŒ VariÃ¡veis de ambiente ausentes: {missing_vars}")
            
            print("ğŸ’¡ Configure as variÃ¡veis de ambiente:")
            print("   export DB_HOST=localhost")
            print("   export DB_NAME=salary_analysis")
            print("   export DB_USER=salary_user")
            print("   export DB_PASSWORD=senha_forte")
            print("ğŸ”§ Ou crie arquivo .env com essas variÃ¡veis")
            return False
        
        if hasattr(self, 'logger'):
            self.logger.info("âœ… ConfiguraÃ§Ã£o de banco de dados encontrada")
        return True
    
    def run(self):
        """Executar pipeline completo SQL-only com tratamento robusto de erros"""
        self.logger.info("ğŸš€ Sistema de AnÃ¡lise Salarial - VERSÃƒO SQL EXCLUSIVA")
        self.logger.info("ğŸ—„ï¸ Fonte de dados: BANCO DE DADOS MySQL")
        self.logger.info("="*60)
        
        try:
            # 0. ConfiguraÃ§Ãµes iniciais
            self._setup()
            
            # 1. Pipeline de dados SQL
            self.logger.info("\nğŸ“Š PIPELINE DE DADOS SQL")
            self.logger.info("-" * 40)
            self.df = self.data_pipeline.run()
            
            if self.df is None or len(self.df) == 0:
                raise ValueError("âŒ Nenhum dado carregado do banco")
            
            self.logger.info(f"âœ… Dados carregados: {len(self.df)} registros")
            
            # 2. Pipeline de ML com tratamento de erro
            self.logger.info("\nğŸ¤– PIPELINE DE ML")
            self.logger.info("-" * 40)
            try:
                self.models, self.results = self.ml_pipeline.run(self.df)
                
                if not self.models:
                    self.logger.warning("âš ï¸ Nenhum modelo foi treinado com sucesso")
                else:
                    self.logger.info(f"âœ… {len(self.models)} modelos treinados")
                    
            except Exception as e:
                self.logger.error(f"âŒ Erro no pipeline ML: {e}")
                self.logger.warning("âš ï¸ Continuando sem modelos ML...")
                self.models = {}
                self.results = {}
            
            # 3. Pipeline de performance (apenas se houver modelos)
            if self.models:
                self.logger.info("\nğŸ“ˆ PIPELINE DE PERFORMANCE")
                self.logger.info("-" * 40)
                try:
                    self.performance_pipeline.run(self.models, self.results, self.df)
                except Exception as e:
                    self.logger.error(f"âŒ Erro no pipeline de performance: {e}")
            else:
                self.logger.info("\nâš ï¸ Pulando pipeline de performance (sem modelos)")
            
            # 4. Pipelines de anÃ¡lise
            self.logger.info("\nğŸ¯ PIPELINE DE ANÃLISES")
            self.logger.info("-" * 40)
            
            # Clustering
            try:
                self.best_k = self.analysis_pipeline.run_clustering(self.df)
                if self.best_k:
                    self.logger.info(f"âœ… Clustering: {self.best_k} clusters identificados")
            except Exception as e:
                self.logger.error(f"âŒ Erro no clustering: {e}")
                self.best_k = None
            
            # Regras de associaÃ§Ã£o
            try:
                self.rules = self.analysis_pipeline.run_association_rules(self.df)
                if self.rules:
                    self.logger.info(f"âœ… {len(self.rules)} regras de associaÃ§Ã£o encontradas")
            except Exception as e:
                self.logger.error(f"âŒ Erro nas regras de associaÃ§Ã£o: {e}")
                self.rules = []
            
            # MÃ©tricas avanÃ§adas
            try:
                self.analysis_pipeline.run_advanced_metrics(self.df, self.results)
                self.logger.info("âœ… MÃ©tricas avanÃ§adas calculadas")
            except Exception as e:
                self.logger.error(f"âŒ Erro nas mÃ©tricas avanÃ§adas: {e}")
            
            # 5. Criar views SQL de anÃ¡lise
            self.logger.info("\nğŸ—„ï¸ CRIANDO VIEWS DE ANÃLISE")
            self.logger.info("-" * 40)
            try:
                self.data_pipeline.create_analysis_views()
                self.logger.info("âœ… Views SQL de anÃ¡lise criadas")
            except Exception as e:
                self.logger.error(f"âŒ Erro ao criar views SQL: {e}")
            
            # 6. RelatÃ³rio final
            self._generate_final_report()
            
            self.logger.info("\nğŸ‰ Pipeline SQL concluÃ­do com sucesso!")
            self.logger.info("ğŸ“Š Para visualizar: streamlit run app.py")
            
        except Exception as e:
            self.logger.error(f"âŒ Erro crÃ­tico durante execuÃ§Ã£o: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            
            # RelatÃ³rio de emergÃªncia
            self._emergency_report()
            raise
    
    def _setup(self):
        """ConfiguraÃ§Ãµes iniciais SQL-only"""
        try:
            # Configurar estilo de visualizaÃ§Ã£o
            setup_matplotlib_style()
            
            # Testar conexÃ£o com banco
            self._test_database_connection()
            
            self.logger.info("âœ… ConfiguraÃ§Ãµes SQL iniciais concluÃ­das")
            
        except Exception as e:
            self.logger.error(f"âŒ Erro na configuraÃ§Ã£o: {e}")
            raise
    
    def _test_database_connection(self):
        """Testar conexÃ£o com banco de dados"""
        try:
            from src.database.connection import DatabaseConnection
            
            with DatabaseConnection() as db:
                result = db.execute_query("SELECT 1 as test")
                if result:
                    self.logger.info("âœ… ConexÃ£o com banco de dados funcionando")
                else:
                    raise ValueError("Teste de conexÃ£o falhou")
                    
        except Exception as e:
            self.logger.error(f"âŒ Erro na conexÃ£o com banco: {e}")
            self.logger.error("ğŸ’¡ Verifique se MySQL estÃ¡ rodando e credenciais estÃ£o corretas")
            raise
    
    def _generate_final_report(self):
        """Gerar relatÃ³rio final SQL"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“Š RELATÃ“RIO FINAL DO PIPELINE SQL")
        self.logger.info("="*60)
        
        # EstatÃ­sticas do banco
        try:
            if hasattr(self.data_pipeline, 'get_statistics_from_sql'):
                stats = self.data_pipeline.get_statistics_from_sql()
                total_records = stats.get('total_records', 0)
                self.logger.info(f"ğŸ“‹ Registros no banco: {total_records:,}")
                
                if 'salary_stats' in stats:
                    self.logger.info("ğŸ’° DistribuiÃ§Ã£o salarial:")
                    for salary_stat in stats['salary_stats']:
                        salary_range = salary_stat.get('salary_range', 'N/A')
                        count = salary_stat.get('count', 0)
                        avg_age = salary_stat.get('avg_age', 0)
                        self.logger.info(f"   â€¢ {salary_range}: {count:,} pessoas (idade mÃ©dia: {avg_age:.1f})")
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ Erro nas estatÃ­sticas SQL: {e}")
        
        # Dados processados
        if self.df is not None:
            self.logger.info(f"ğŸ“Š Dataset ML: {len(self.df)} registros processados")
            self.logger.info(f"ğŸ“‹ Colunas: {list(self.df.columns)}")
        
        # Modelos treinados
        if self.results:
            self.logger.info("ğŸ¤– Modelos treinados:")
            for name, result in self.results.items():
                accuracy = result.get('accuracy', 0)
                self.logger.info(f"   â€¢ {name}: AcurÃ¡cia = {accuracy:.4f}")
        else:
            self.logger.info("ğŸ¤– Nenhum modelo ML foi treinado")
        
        # Clustering
        if self.best_k:
            self.logger.info(f"ğŸ¯ Clustering: {self.best_k} clusters identificados")
        else:
            self.logger.info("ğŸ¯ Clustering: NÃ£o executado")
        
        # Regras de associaÃ§Ã£o
        rules_count = len(self.rules) if self.rules else 0
        self.logger.info(f"ğŸ“‹ Regras de associaÃ§Ã£o: {rules_count} encontradas")
        
        # Arquivos gerados
        self._show_generated_files()
        
        # InstruÃ§Ãµes finais
        self.logger.info("\nğŸ’¡ PrÃ³ximos passos:")
        self.logger.info("   â€¢ Dashboard: streamlit run app.py")
        self.logger.info("   â€¢ AnÃ¡lises SQL: Use views criadas no banco")
        self.logger.info("   â€¢ Modelos salvos em: data/processed/")
        self.logger.info("   â€¢ VisualizaÃ§Ãµes em: output/images/")
    
    def _show_generated_files(self):
        """Mostrar arquivos gerados"""
        # Verificar diretÃ³rio de output
        output_dir = Path("output")
        if output_dir.exists():
            # Imagens
            images_dir = output_dir / "images"
            if images_dir.exists():
                image_files = list(images_dir.glob("*.png"))
                self.logger.info(f"ğŸ¨ {len(image_files)} visualizaÃ§Ãµes em output/images/")
            
            # AnÃ¡lises
            analysis_dir = output_dir / "analysis"
            if analysis_dir.exists():
                analysis_files = list(analysis_dir.glob("*"))
                self.logger.info(f"ğŸ“Š {len(analysis_files)} anÃ¡lises em output/analysis/")
        
        # Modelos salvos
        processed_dir = Path("data/processed")
        if processed_dir.exists():
            model_files = list(processed_dir.glob("*.joblib"))
            self.logger.info(f"ğŸ¤– {len(model_files)} modelos salvos em data/processed/")
    
    def _emergency_report(self):
        """RelatÃ³rio de emergÃªncia quando pipeline falha"""
        self.logger.info("\nğŸš¨ RELATÃ“RIO DE EMERGÃŠNCIA")
        self.logger.info("="*40)
        
        if self.df is not None:
            self.logger.info(f"ğŸ“Š Dados carregados: {len(self.df)} registros")
        else:
            self.logger.info("âŒ Nenhum dado foi carregado")
        
        self.logger.info(f"ğŸ¤– Modelos criados: {len(self.models)}")
        self.logger.info(f"ğŸ“Š Resultados: {len(self.results)}")
        
        self.logger.info("\nğŸ’¡ Para diagnÃ³stico:")
        self.logger.info("   â€¢ Verificar logs detalhados acima")
        self.logger.info("   â€¢ Testar conexÃ£o: mysql -u salary_user -p salary_analysis")
        self.logger.info("   â€¢ Verificar estrutura: python main.py --setup-db")

def main():
    """FunÃ§Ã£o principal SQL-only"""
    parser = argparse.ArgumentParser(description="Sistema de AnÃ¡lise Salarial SQL-Only")
    parser.add_argument('--migrate', action='store_true', 
                       help='ForÃ§ar migraÃ§Ã£o CSVâ†’SQL (se CSV disponÃ­vel)')
    parser.add_argument('--setup-db', action='store_true',
                       help='Apenas configurar estrutura do banco')
    
    args = parser.parse_args()
    
    # Verificar variÃ¡veis de ambiente primeiro
    required_vars = ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print("âŒ ERRO: ConfiguraÃ§Ã£o de banco de dados obrigatÃ³ria!")
        print(f"âŒ VariÃ¡veis ausentes: {missing_vars}")
        print("\nğŸ’¡ Configure as variÃ¡veis de ambiente:")
        print("export DB_HOST=localhost")
        print("export DB_NAME=salary_analysis")
        print("export DB_USER=salary_user")
        print("export DB_PASSWORD=senha_forte")
        print("\nğŸ”§ Ou crie arquivo .env com essas variÃ¡veis")
        print("\nğŸ“‹ Exemplo de .env:")
        print("DB_HOST=localhost")
        print("DB_NAME=salary_analysis")
        print("DB_USER=salary_user")
        print("DB_PASSWORD=senha_forte")
        return
    
    # Setup apenas da estrutura do banco
    if args.setup_db:
        try:
            print("ğŸ”§ Configurando estrutura do banco de dados...")
            from src.database.migration import DatabaseMigrator
            
            migrator = DatabaseMigrator()
            if migrator.create_database_structure():
                print("âœ… Estrutura do banco criada com sucesso!")
                print("ğŸ’¡ Agora execute: python main.py")
            else:
                print("âŒ Erro ao criar estrutura do banco")
                
        except ImportError as e:
            print(f"âŒ Erro ao importar DatabaseMigrator: {e}")
            print("ğŸ’¡ Verifique se o mÃ³dulo src.database.migration existe")
        except Exception as e:
            print(f"âŒ Erro: {e}")
        return
    
    # Executar pipeline principal
    try:
        print("ğŸš€ Iniciando Sistema de AnÃ¡lise Salarial...")
        pipeline = MasterPipelineSQL(force_migration=args.migrate)
        pipeline.run()
        
        print("\nğŸ‰ Pipeline executado com sucesso!")
        print("ğŸ“Š Para visualizar resultados: streamlit run app.py")
        
    except ValueError as e:
        print(f"\nâŒ ERRO DE CONFIGURAÃ‡ÃƒO: {e}")
        print("\nğŸ’¡ SoluÃ§Ãµes:")
        print("  1. Verificar variÃ¡veis de ambiente")
        print("  2. Criar estrutura: python main.py --setup-db")
        print("  3. Testar conexÃ£o: mysql -u salary_user -p salary_analysis")
        
    except ImportError as e:
        print(f"\nâŒ ERRO DE IMPORTAÃ‡ÃƒO: {e}")
        print("\nğŸ’¡ SoluÃ§Ãµes:")
        print("  1. Verificar se todos os mÃ³dulos existem em src/")
        print("  2. Verificar dependÃªncias: pip install -r requirements.txt")
        
    except Exception as e:
        print(f"\nâŒ ERRO CRÃTICO: {e}")
        print("\nğŸ’¡ SoluÃ§Ãµes possÃ­veis:")
        print("  1. Verificar conexÃ£o: mysql -u salary_user -p salary_analysis")
        print("  2. Recriar estrutura: python main.py --setup-db")
        print("  3. Migrar dados: python main.py --migrate")
        print("  4. Verificar logs detalhados nos arquivos de log")

if __name__ == "__main__":
    main()