#!/usr/bin/env python3
"""
üöÄ Pipeline Principal - Sistema H√≠brido SQL‚ÜíCSV
Resultados completos no terminal (como no app.py)
"""

import os
import sys
import logging
import argparse
import traceback
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Tuple, Optional
import pandas as pd
import numpy as np

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

def setup_logging():
    """Configurar sistema de logging otimizado"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"pipeline_{timestamp}.log"
    
    log_format = '%(asctime)s | %(levelname)-8s | %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        datefmt=date_format,
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    logger = logging.getLogger("HybridPipeline")
    logger.info("üöÄ PIPELINE H√çBRIDO SQL‚ÜíCSV INICIADO")
    logger.info(f"üìù Log salvo em: {log_file}")
    return logger

class HybridPipelineSQL:
    """Pipeline H√≠brido com Relat√≥rios Completos no Terminal"""
    
    def __init__(self, force_csv=False, log_level="INFO", show_results=True):
        """Inicializar pipeline h√≠brido"""
        self.logger = setup_logging()
        self.logger.setLevel(getattr(logging, log_level.upper()))
        
        self.force_csv = force_csv
        self.show_results = show_results
        self.data_source = None
        self.results = {}
        self.models = {}
        self.df = None
        self.start_time = datetime.now()
        
        # M√©tricas de performance
        self.performance_metrics = {
            'start_time': self.start_time,
            'data_source': None,
            'data_load_time': None,
            'ml_training_time': None,
            'total_time': None,
            'records_processed': 0
        }
        
        self.logger.info(f"üîß Pipeline h√≠brido inicializado:")
        self.logger.info(f"   ‚Ä¢ For√ßar CSV: {force_csv}")
        self.logger.info(f"   ‚Ä¢ N√≠vel de log: {log_level}")
        self.logger.info(f"   ‚Ä¢ Mostrar resultados: {show_results}")
        
        self._initialize_components()

    def _initialize_components(self):
        """Inicializar componentes com fallback"""
        try:
            # 1. Tentar pipeline SQL primeiro (se n√£o for√ßar CSV)
            if not self.force_csv:
                try:
                    from src.pipelines.data_pipeline import DataPipelineSQL
                    self.sql_pipeline = DataPipelineSQL(force_migration=False)
                    self.logger.info("‚úÖ Pipeline SQL dispon√≠vel")
                except ImportError as e:
                    self.logger.warning(f"‚ö†Ô∏è Pipeline SQL indispon√≠vel: {e}")
                    self.sql_pipeline = None
            else:
                self.sql_pipeline = None
                self.logger.info("üìã Modo CSV for√ßado")
            
            # 2. Pipeline ML (sempre dispon√≠vel)
            try:
                from src.pipelines.ml_pipeline import MLPipeline
                self.ml_pipeline = MLPipeline()
                self.logger.info("‚úÖ Pipeline ML inicializado")
            except ImportError as e:
                self.logger.error(f"‚ùå Pipeline ML n√£o dispon√≠vel: {e}")
                self.ml_pipeline = None
            
            # 3. Pipelines opcionais
            self._initialize_optional_pipelines()
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na inicializa√ß√£o: {e}")

    def _initialize_optional_pipelines(self):
        """Inicializar pipelines opcionais"""
        # Clustering
        try:
            from src.pipelines.clustering_pipeline import ClusteringPipeline
            self.clustering_pipeline = ClusteringPipeline()
            self.logger.info("‚úÖ Pipeline Clustering dispon√≠vel")
        except ImportError:
            self.clustering_pipeline = None
            self.logger.info("‚ÑπÔ∏è Pipeline Clustering n√£o dispon√≠vel")
        
        # Association Rules
        try:
            from src.pipelines.association_pipeline import AssociationPipeline
            self.association_pipeline = AssociationPipeline()
            self.logger.info("‚úÖ Pipeline Association dispon√≠vel")
        except ImportError:
            self.association_pipeline = None
            self.logger.info("‚ÑπÔ∏è Pipeline Association n√£o dispon√≠vel")

    def run(self) -> Dict[str, Any]:
        """Executar pipeline completo com relat√≥rios no terminal"""
        try:
            self.logger.info("üöÄ INICIANDO PIPELINE H√çBRIDO")
            self.logger.info("=" * 60)
            
            # 1. Carregar dados (SQL ‚Üí CSV fallback)
            self._run_data_pipeline()
            
            if self.df is None or len(self.df) == 0:
                raise ValueError("‚ùå Nenhum dado foi carregado")
            
            # 2. Machine Learning
            self._run_ml_pipeline()
            
            # 3. An√°lises opcionais
            self._run_optional_analysis()
            
            # 4. Finalizar
            self._finalize_pipeline()
            
            # 5. üéØ EXIBIR RESULTADOS COMPLETOS (como app.py)
            if self.show_results:
                self._display_complete_results()
            
            return self._prepare_results()
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro cr√≠tico no pipeline: {e}")
            self.logger.error(traceback.format_exc())
            return {'error': str(e), 'data_source': self.data_source}

    def _run_data_pipeline(self):
        """Executar carregamento de dados com fallback SQL‚ÜíCSV"""
        self.logger.info("üìä CARREGAMENTO DE DADOS")
        self.logger.info("-" * 40)
        
        data_start = datetime.now()
        
        # Tentar SQL primeiro (se dispon√≠vel)
        if self.sql_pipeline and not self.force_csv:
            self.logger.info("üóÑÔ∏è Tentando carregar dados do SQL...")
            try:
                self.df = self.sql_pipeline.run()
                if self.df is not None and len(self.df) > 0:
                    self.data_source = 'sql'
                    self.logger.info(f"‚úÖ Dados carregados do SQL: {len(self.df):,} registros")
                    self._log_data_details()
                else:
                    self.logger.warning("‚ö†Ô∏è SQL retornou dados vazios, tentando CSV...")
                    self._load_from_csv()
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erro no SQL: {e}")
                self.logger.info("üîÑ Fazendo fallback para CSV...")
                self._load_from_csv()
        else:
            # Carregar diretamente do CSV
            self._load_from_csv()
        
        # Calcular tempo de carregamento
        data_time = datetime.now() - data_start
        self.performance_metrics['data_load_time'] = data_time.total_seconds()
        self.performance_metrics['data_source'] = self.data_source
        self.performance_metrics['records_processed'] = len(self.df) if self.df is not None else 0
        
        self.logger.info(f"‚è±Ô∏è Tempo de carregamento: {data_time.total_seconds():.2f}s")

    def _load_from_csv(self):
        """Carregar dados do arquivo CSV"""
        csv_paths = [
            "data/raw/4-Carateristicas_salario.csv",
            "4-Carateristicas_salario.csv",
            "bkp/4-Carateristicas_salario.csv",
            "data/4-Carateristicas_salario.csv"
        ]
        
        for csv_path in csv_paths:
            if Path(csv_path).exists():
                try:
                    self.logger.info(f"üìã Carregando CSV: {csv_path}")
                    self.df = pd.read_csv(csv_path)
                    
                    if len(self.df) > 0:
                        self.data_source = 'csv'
                        self.logger.info(f"‚úÖ CSV carregado: {len(self.df):,} registros, {len(self.df.columns)} colunas")
                        
                        # Limpeza b√°sica
                        self._basic_cleaning()
                        self._log_data_details()
                        return
                    
                except Exception as e:
                    self.logger.error(f"‚ùå Erro ao carregar {csv_path}: {e}")
        
        # Se chegou aqui, n√£o encontrou nenhum CSV
        self.logger.error("‚ùå Nenhum arquivo CSV encontrado!")
        self.logger.info("üí° Locais procurados:")
        for path in csv_paths:
            self.logger.info(f"   ‚Ä¢ {path}")

    def _basic_cleaning(self):
        """Limpeza b√°sica dos dados CSV"""
        if self.df is None:
            return
        
        initial_size = len(self.df)
        
        # Remover espa√ßos e caracteres especiais
        for col in self.df.select_dtypes(include=['object']).columns:
            self.df[col] = self.df[col].astype(str).str.strip()
        
        # Substituir '?' por NaN
        self.df = self.df.replace('?', np.nan)
        
        # Remover linhas completamente vazias
        self.df = self.df.dropna(how='all')
        
        final_size = len(self.df)
        if final_size != initial_size:
            self.logger.info(f"üßπ Limpeza: {initial_size:,} ‚Üí {final_size:,} registros")

    def _log_data_details(self):
        """Log detalhado dos dados carregados"""
        if self.df is None:
            return
        
        self.logger.info("üìà DETALHES DOS DADOS:")
        self.logger.info(f"   üìã Registros: {len(self.df):,}")
        self.logger.info(f"   üìä Colunas: {len(self.df.columns)}")
        self.logger.info(f"   üíæ Mem√≥ria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # Colunas por tipo
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        
        self.logger.info(f"   üî¢ Num√©ricas: {len(numeric_cols)}")
        self.logger.info(f"   üìù Categ√≥ricas: {len(categorical_cols)}")
        
        # Dados ausentes
        missing_data = self.df.isnull().sum()
        if missing_data.sum() > 0:
            self.logger.warning("‚ö†Ô∏è DADOS AUSENTES:")
            for col, missing_count in missing_data[missing_data > 0].items():
                percentage = (missing_count / len(self.df)) * 100
                self.logger.warning(f"   ‚Ä¢ {col}: {missing_count} ({percentage:.1f}%)")
        else:
            self.logger.info("‚úÖ Sem dados ausentes")
        
        # Duplicatas
        duplicates = self.df.duplicated().sum()
        if duplicates > 0:
            self.logger.warning(f"‚ö†Ô∏è {duplicates} duplicatas ({duplicates/len(self.df)*100:.1f}%)")
        else:
            self.logger.info("‚úÖ Sem duplicatas")
        
        # Distribui√ß√£o target (se existir)
        if 'salary' in self.df.columns:
            target_dist = self.df['salary'].value_counts()
            self.logger.info("üéØ DISTRIBUI√á√ÉO TARGET:")
            for value, count in target_dist.items():
                percentage = (count / len(self.df)) * 100
                self.logger.info(f"   ‚Ä¢ {value}: {count:,} ({percentage:.1f}%)")

    def _run_ml_pipeline(self):
        """Executar pipeline de ML"""
        if not self.ml_pipeline:
            self.logger.warning("‚ö†Ô∏è Pipeline ML n√£o dispon√≠vel")
            return
        
        self.logger.info("ü§ñ MACHINE LEARNING")
        self.logger.info("-" * 40)
        
        ml_start = datetime.now()
        
        try:
            self.models, ml_results = self.ml_pipeline.run(self.df)
            
            if self.models:
                self.logger.info(f"‚úÖ {len(self.models)} modelos treinados")
                
                # Log performance de cada modelo
                for name, model_info in self.models.items():
                    if isinstance(model_info, dict) and 'accuracy' in model_info:
                        accuracy = model_info['accuracy']
                        self.logger.info(f"   ‚Ä¢ {name}: {accuracy:.4f}")
                        
                        # Classifica√ß√£o de performance
                        if accuracy > 0.90:
                            self.logger.info(f"     üèÜ EXCELENTE")
                        elif accuracy > 0.85:
                            self.logger.info(f"     ‚úÖ MUITO BOA")
                        elif accuracy > 0.80:
                            self.logger.info(f"     ‚ö†Ô∏è BOA")
                        else:
                            self.logger.warning(f"     ‚ùå REGULAR")
                
                # Identificar melhor modelo
                best_model, best_score = self._find_best_model()
                if best_model:
                    self.logger.info(f"üèÜ MELHOR MODELO: {best_model} ({best_score:.4f})")
                
                self.results['ml_results'] = ml_results
            else:
                self.logger.warning("‚ö†Ô∏è Nenhum modelo foi treinado")
        
        except Exception as e:
            self.logger.error(f"‚ùå Erro no ML: {e}")
            self.logger.error(traceback.format_exc())
        
        ml_time = datetime.now() - ml_start
        self.performance_metrics['ml_training_time'] = ml_time.total_seconds()
        self.logger.info(f"‚è±Ô∏è Tempo ML: {ml_time.total_seconds():.2f}s")

    def _find_best_model(self) -> Tuple[Optional[str], float]:
        """Encontrar melhor modelo"""
        best_model = None
        best_score = 0.0
        
        for model_name, model_info in self.models.items():
            if isinstance(model_info, dict) and 'accuracy' in model_info:
                accuracy = model_info['accuracy']
                if accuracy > best_score:
                    best_score = accuracy
                    best_model = model_name
        
        return best_model, best_score

    def _run_optional_analysis(self):
        """Executar an√°lises opcionais"""
        self.logger.info("üìä AN√ÅLISES OPCIONAIS")
        self.logger.info("-" * 40)
        
        # Clustering
        if self.clustering_pipeline:
            try:
                self.logger.info("üéØ Executando clustering...")
                clustering_results = self.clustering_pipeline.run(self.df)
                if clustering_results:
                    self.results['clustering'] = clustering_results
                    self.logger.info("‚úÖ Clustering conclu√≠do")
                    
                    # Log resultados de clustering
                    for algorithm, result in clustering_results.items():
                        if isinstance(result, dict):
                            if 'n_clusters' in result:
                                self.logger.info(f"   ‚Ä¢ {algorithm}: {result['n_clusters']} clusters")
                            if 'silhouette_score' in result:
                                score = result['silhouette_score']
                                self.logger.info(f"     Silhouette: {score:.4f}")
                else:
                    self.logger.warning("‚ö†Ô∏è Clustering n√£o retornou resultados")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erro no clustering: {e}")
        else:
            self.logger.info("‚ÑπÔ∏è Clustering n√£o dispon√≠vel")
        
        # Association Rules
        if self.association_pipeline:
            try:
                self.logger.info("üìã Executando regras de associa√ß√£o...")
                association_results = self.association_pipeline.run(self.df)
                if association_results:
                    self.results['association_rules'] = association_results
                    self.logger.info("‚úÖ Regras de associa√ß√£o conclu√≠das")
                    
                    # Log resultados
                    if 'rules' in association_results:
                        rules_count = len(association_results['rules'])
                        self.logger.info(f"   ‚Ä¢ {rules_count} regras encontradas")
                else:
                    self.logger.warning("‚ö†Ô∏è Regras de associa√ß√£o n√£o retornaram resultados")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erro nas regras de associa√ß√£o: {e}")
        else:
            self.logger.info("‚ÑπÔ∏è Regras de associa√ß√£o n√£o dispon√≠veis")

    def _finalize_pipeline(self):
        """Finalizar pipeline"""
        total_time = datetime.now() - self.start_time
        self.performance_metrics['total_time'] = total_time.total_seconds()
        
        self.logger.info("üéâ PIPELINE CONCLU√çDO")
        self.logger.info("=" * 60)
        self.logger.info(f"‚è±Ô∏è Tempo total: {total_time.total_seconds():.2f}s")
        self.logger.info(f"üìä Fonte dos dados: {self.data_source.upper()}")
        self.logger.info(f"üìã Registros processados: {self.performance_metrics['records_processed']:,}")
        
        if self.models:
            self.logger.info(f"ü§ñ Modelos treinados: {len(self.models)}")
            best_model, best_score = self._find_best_model()
            if best_model:
                self.logger.info(f"üèÜ Melhor performance: {best_model} ({best_score:.4f})")
        
        # Salvar resultados
        self._save_results()

    def _display_complete_results(self):
        """üéØ EXIBIR RESULTADOS COMPLETOS NO TERMINAL - Como app.py"""
        print("\n" + "üéØ" * 80)
        print("üéØ RELAT√ìRIO COMPLETO DE RESULTADOS - AN√ÅLISE DE SAL√ÅRIOS")
        print("üéØ" * 80)
        
        # 1. OVERVIEW DOS DADOS
        self._display_data_overview()
        
        # 2. AN√ÅLISE EXPLORAT√ìRIA
        self._display_eda_results()
        
        # 3. MACHINE LEARNING
        self._display_ml_results()
        
        # 4. M√âTRICAS DE PERFORMANCE
        self._display_performance_metrics()
        
        # 5. INSIGHTS E CONCLUS√ïES
        self._display_insights()
        
        print("\n" + "üéØ" * 80)
        print("‚úÖ RELAT√ìRIO COMPLETO EXIBIDO COM SUCESSO!")
        print("üéØ" * 80)

    def _display_data_overview(self):
        """Exibir overview dos dados"""
        print(f"\nüìä 1. OVERVIEW DOS DADOS")
        print("-" * 50)
        
        if self.df is not None:
            print(f"üìã Total de Registros: {len(self.df):,}")
            print(f"üìä Total de Colunas: {len(self.df.columns)}")
            print(f"üíæ Tamanho em Mem√≥ria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
            print(f"üóÑÔ∏è Fonte dos Dados: {self.data_source.upper()}")
            
            # Tipos de dados
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns
            categorical_cols = self.df.select_dtypes(include=['object']).columns
            
            print(f"\nüìà TIPOS DE VARI√ÅVEIS:")
            print(f"   üî¢ Num√©ricas: {len(numeric_cols)} ({', '.join(numeric_cols[:3])}{'...' if len(numeric_cols) > 3 else ''})")
            print(f"   üìù Categ√≥ricas: {len(categorical_cols)} ({', '.join(categorical_cols[:3])}{'...' if len(categorical_cols) > 3 else ''})")
            
            # Qualidade dos dados
            missing_data = self.df.isnull().sum()
            duplicates = self.df.duplicated().sum()
            
            print(f"\nüßπ QUALIDADE DOS DADOS:")
            if missing_data.sum() > 0:
                cols_with_missing = missing_data[missing_data > 0]
                print(f"   ‚ö†Ô∏è Dados Ausentes: {missing_data.sum():,} valores em {len(cols_with_missing)} colunas")
                for col, count in cols_with_missing.head(3).items():
                    percentage = (count / len(self.df)) * 100
                    print(f"      ‚Ä¢ {col}: {count:,} ({percentage:.1f}%)")
            else:
                print(f"   ‚úÖ Dados Ausentes: Nenhum")
            
            if duplicates > 0:
                print(f"   ‚ö†Ô∏è Duplicatas: {duplicates:,} ({duplicates/len(self.df)*100:.1f}%)")
            else:
                print(f"   ‚úÖ Duplicatas: Nenhuma")

    def _display_eda_results(self):
        """Exibir resultados da an√°lise explorat√≥ria"""
        print(f"\nüîç 2. AN√ÅLISE EXPLORAT√ìRIA")
        print("-" * 50)
        
        if self.df is not None and 'salary' in self.df.columns:
            # Distribui√ß√£o da vari√°vel target
            target_dist = self.df['salary'].value_counts()
            target_dist_pct = self.df['salary'].value_counts(normalize=True)
            
            print(f"üéØ DISTRIBUI√á√ÉO DA VARI√ÅVEL TARGET (salary):")
            for value, count in target_dist.items():
                percentage = target_dist_pct[value] * 100
                bar_length = int(percentage / 2)  # Escala para visualiza√ß√£o
                bar = "‚ñà" * bar_length + "‚ñë" * (50 - bar_length)
                print(f"   {value:<8}: {count:>8,} ({percentage:>5.1f}%) {bar}")
            
            # Estat√≠sticas das vari√°veis num√©ricas
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                print(f"\nüìä ESTAT√çSTICAS DAS VARI√ÅVEIS NUM√âRICAS:")
                stats = self.df[numeric_cols].describe()
                
                for col in numeric_cols[:4]:  # Mostrar apenas as primeiras 4
                    if col in stats.columns:
                        mean_val = stats.loc['mean', col]
                        std_val = stats.loc['std', col]
                        min_val = stats.loc['min', col]
                        max_val = stats.loc['max', col]
                        
                        print(f"   {col:<15}: M√©dia={mean_val:>8.1f} | Desvio={std_val:>8.1f} | Min={min_val:>8.0f} | Max={max_val:>8.0f}")
            
            # Top categorias das vari√°veis categ√≥ricas
            categorical_cols = self.df.select_dtypes(include=['object']).columns
            important_cats = ['workclass', 'education', 'occupation', 'sex']
            
            print(f"\nüìù TOP CATEGORIAS DAS PRINCIPAIS VARI√ÅVEIS:")
            for col in important_cats:
                if col in categorical_cols and col in self.df.columns:
                    top_values = self.df[col].value_counts().head(3)
                    print(f"   {col:<12}: {dict(top_values)}")

    def _display_ml_results(self):
        """Exibir resultados de Machine Learning"""
        print(f"\nü§ñ 3. RESULTADOS DE MACHINE LEARNING")
        print("-" * 50)
        
        if self.models and len(self.models) > 0:
            print(f"‚úÖ Modelos Treinados: {len(self.models)}")
            
            # Extrair m√©tricas dos modelos
            model_metrics = {}
            for name, model_info in self.models.items():
                if isinstance(model_info, dict):
                    model_metrics[name] = model_info
                else:
                    # Se for o objeto do modelo diretamente, pegar dos resultados
                    if name in self.results.get('ml_results', {}):
                        model_metrics[name] = self.results['ml_results'][name]
            
            # Exibir performance de cada modelo
            print(f"\nüìà PERFORMANCE DOS MODELOS:")
            sorted_models = []
            
            for name, metrics in model_metrics.items():
                if 'accuracy' in metrics:
                    accuracy = metrics['accuracy']
                    sorted_models.append((name, accuracy, metrics))
            
            # Ordenar por accuracy
            sorted_models.sort(key=lambda x: x[1], reverse=True)
            
            for i, (name, accuracy, metrics) in enumerate(sorted_models, 1):
                # Barra de progresso visual
                bar_length = int(accuracy * 50)
                bar = "‚ñà" * bar_length + "‚ñë" * (50 - bar_length)
                
                # Classifica√ß√£o de performance
                if accuracy > 0.90:
                    grade = "üèÜ EXCELENTE"
                elif accuracy > 0.85:
                    grade = "‚úÖ MUITO BOM"
                elif accuracy > 0.80:
                    grade = "‚ö†Ô∏è BOM"
                else:
                    grade = "‚ùì REGULAR"
                
                print(f"   {i}. {name:<20}: {accuracy:.4f} ({accuracy*100:5.1f}%) {bar} {grade}")
                
                # M√©tricas adicionais se dispon√≠veis
                additional_metrics = []
                for metric in ['precision', 'recall', 'f1_score', 'roc_auc']:
                    if metric in metrics:
                        additional_metrics.append(f"{metric}={metrics[metric]:.3f}")
                
                if additional_metrics:
                    print(f"      üìä {' | '.join(additional_metrics)}")
            
            # Melhor modelo
            if sorted_models:
                best_name, best_accuracy, _ = sorted_models[0]
                print(f"\nüèÜ MELHOR MODELO: {best_name}")
                print(f"üéØ ACCURACY: {best_accuracy:.4f} ({best_accuracy*100:.1f}%)")
        else:
            print("‚ùå Nenhum modelo foi treinado com sucesso")

    def _display_performance_metrics(self):
        """Exibir m√©tricas de performance do pipeline"""
        print(f"\n‚è±Ô∏è 4. M√âTRICAS DE PERFORMANCE DO PIPELINE")
        print("-" * 50)
        
        metrics = self.performance_metrics
        
        print(f"üìä TEMPOS DE EXECU√á√ÉO:")
        print(f"   ‚è±Ô∏è Carregamento de dados: {metrics.get('data_load_time', 0):.2f}s")
        print(f"   ü§ñ Treinamento ML: {metrics.get('ml_training_time', 0):.2f}s")
        print(f"   üèÅ Tempo total: {metrics.get('total_time', 0):.2f}s")
        
        print(f"\nüìà PROCESSAMENTO:")
        print(f"   üìã Registros processados: {metrics.get('records_processed', 0):,}")
        print(f"   üóÑÔ∏è Fonte de dados: {metrics.get('data_source', 'N/A').upper()}")
        
        # Taxa de processamento
        if metrics.get('total_time', 0) > 0 and metrics.get('records_processed', 0) > 0:
            rate = metrics['records_processed'] / metrics['total_time']
            print(f"   üöÄ Taxa de processamento: {rate:,.0f} registros/segundo")
        
        # Efici√™ncia de mem√≥ria
        if self.df is not None:
            memory_mb = self.df.memory_usage(deep=True).sum() / 1024**2
            print(f"   üíæ Uso de mem√≥ria: {memory_mb:.2f} MB")

    def _display_insights(self):
        """Exibir insights e conclus√µes"""
        print(f"\nüí° 5. INSIGHTS E CONCLUS√ïES")
        print("-" * 50)
        
        insights = []
        
        # Insights sobre os dados
        if self.df is not None:
            total_records = len(self.df)
            
            if 'salary' in self.df.columns:
                high_salary_pct = (self.df['salary'] == '>50K').mean() * 100
                
                if high_salary_pct < 30:
                    insights.append(f"üìä Apenas {high_salary_pct:.1f}% ganham mais de $50K - dataset desbalanceado")
                
                # Insights por idade
                if 'age' in self.df.columns:
                    avg_age = self.df['age'].mean()
                    insights.append(f"üë• Idade m√©dia: {avg_age:.1f} anos")
                
                # Insights por educa√ß√£o
                if 'education-num' in self.df.columns:
                    high_earners_edu = self.df[self.df['salary'] == '>50K']['education-num'].mean()
                    low_earners_edu = self.df[self.df['salary'] == '<=50K']['education-num'].mean()
                    
                    if high_earners_edu > low_earners_edu:
                        diff = high_earners_edu - low_earners_edu
                        insights.append(f"üéì Quem ganha mais tem {diff:.1f} anos a mais de educa√ß√£o em m√©dia")
                
                # Insights por horas trabalhadas
                if 'hours-per-week' in self.df.columns:
                    high_earners_hours = self.df[self.df['salary'] == '>50K']['hours-per-week'].mean()
                    low_earners_hours = self.df[self.df['salary'] == '<=50K']['hours-per-week'].mean()
                    
                    if high_earners_hours > low_earners_hours:
                        diff = high_earners_hours - low_earners_hours
                        insights.append(f"‚è∞ Quem ganha mais trabalha {diff:.1f} horas/semana a mais")
        
        # Insights sobre modelos
        if self.models and len(self.models) > 0:
            best_model, best_score = self._find_best_model()
            if best_model and best_score > 0.80:
                insights.append(f"ü§ñ {best_model} alcan√ßou {best_score:.1%} de accuracy - bom desempenho")
            elif best_model:
                insights.append(f"ü§ñ {best_model} alcan√ßou {best_score:.1%} de accuracy - necessita melhorias")
        
        # Insights sobre performance
        if self.performance_metrics.get('total_time', 0) < 5:
            insights.append(f"‚ö° Pipeline executou em {self.performance_metrics['total_time']:.1f}s - muito eficiente")
        
        # Exibir insights
        if insights:
            for i, insight in enumerate(insights, 1):
                print(f"   {i}. {insight}")
        else:
            print("   ‚ÑπÔ∏è An√°lise conclu√≠da - execute com mais dados para insights detalhados")
        
        # Recomenda√ß√µes
        print(f"\nüéØ PR√ìXIMOS PASSOS RECOMENDADOS:")
        recommendations = [
            "üìä Execute o dashboard: streamlit run app.py",
            "üîç Analise os gr√°ficos interativos no Streamlit",
            "ü§ñ Teste diferentes algoritmos de ML",
            "üìà Colete mais dados para melhorar os modelos"
        ]
        
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")

    def _save_results(self):
        """Salvar resultados do pipeline"""
        try:
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            
            # Salvar estado do pipeline
            pipeline_state = {
                'data_source': self.data_source,
                'models_count': len(self.models),
                'performance_metrics': self.performance_metrics,
                'results_summary': {
                    'has_ml': len(self.models) > 0,
                    'has_clustering': 'clustering' in self.results,
                    'has_association': 'association_rules' in self.results
                },
                'timestamp': datetime.now().isoformat()
            }
            
            # Salvar em JSON
            state_file = output_dir / "pipeline_state.json"
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(pipeline_state, f, indent=2, default=str, ensure_ascii=False)
            
            self.logger.info(f"üíæ Estado salvo: {state_file}")
            
            # Salvar modelos se existirem
            if self.models:
                models_file = output_dir / "models_summary.json"
                models_summary = {}
                
                for name, model_info in self.models.items():
                    if isinstance(model_info, dict):
                        models_summary[name] = {
                            k: v for k, v in model_info.items() 
                            if isinstance(v, (int, float, str, bool))
                        }
                
                with open(models_file, 'w', encoding='utf-8') as f:
                    json.dump(models_summary, f, indent=2, default=str, ensure_ascii=False)
                
                self.logger.info(f"üíæ Modelos salvos: {models_file}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao salvar resultados: {e}")

    def _prepare_results(self) -> Dict[str, Any]:
        """Preparar resultados finais"""
        return {
            'df': self.df,
            'models': self.models,
            'results': self.results,
            'data_source': self.data_source,
            'performance_metrics': self.performance_metrics,
            'status': self._generate_status_message()
        }

    def _generate_status_message(self) -> str:
        """Gerar mensagem de status final"""
        if self.df is not None and len(self.df) > 0:
            if self.models and len(self.models) > 0:
                best_model, best_score = self._find_best_model()
                return f"‚úÖ Pipeline conclu√≠do - Fonte: {self.data_source.upper()} | Melhor modelo: {best_model} ({best_score:.4f})"
            else:
                return f"‚ö†Ô∏è Dados carregados via {self.data_source.upper()}, mas problemas no ML"
        else:
            return "‚ùå Falha no carregamento de dados"

def setup_database():
    """Configurar banco de dados (placeholder)"""
    print("üóÑÔ∏è Configura√ß√£o de Banco de Dados")
    print("=" * 40)
    
    try:
        # Tentar importar e usar setup real
        from src.database.connection import create_connection
        from src.database.migration import run_migration
        
        print("üìã Testando conex√£o...")
        conn = create_connection()
        if conn:
            print("‚úÖ Conex√£o com banco OK")
            
            print("üîÑ Executando migra√ß√£o...")
            success = run_migration()
            if success:
                print("‚úÖ Migra√ß√£o conclu√≠da com sucesso")
            else:
                print("‚ö†Ô∏è Problemas na migra√ß√£o")
            
            conn.close()
        else:
            print("‚ùå Erro na conex√£o com banco")
            
    except ImportError:
        print("‚ö†Ô∏è M√≥dulos de banco n√£o encontrados")
        print("üí° Sistema funcionar√° em modo CSV")
    except Exception as e:
        print(f"‚ùå Erro na configura√ß√£o: {e}")
        print("üí° Sistema funcionar√° em modo CSV")

def main():
    """Fun√ß√£o principal com argumentos otimizados"""
    parser = argparse.ArgumentParser(description='Pipeline H√≠brido SQL‚ÜíCSV')
    parser.add_argument('--csv-only', action='store_true', help='For√ßar uso apenas de CSV')
    parser.add_argument('--log-level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    parser.add_argument('--setup-db', action='store_true', help='Configurar banco de dados')
    parser.add_argument('--no-results', action='store_true', help='N√£o exibir relat√≥rio completo')
    
    args = parser.parse_args()
    
    try:
        if args.setup_db:
            setup_database()
            return
        
        # Executar pipeline principal
        pipeline = HybridPipelineSQL(
            force_csv=args.csv_only,
            log_level=args.log_level,
            show_results=not args.no_results
        )
        
        results = pipeline.run()
        
        if 'error' not in results:
            print(f"\nüéâ PIPELINE CONCLU√çDO COM SUCESSO!")
            print(f"üìä Fonte: {results['data_source'].upper()}")
            print(f"üìã Registros: {len(results['df']):,}")
            print(f"ü§ñ Modelos: {len(results['models'])}")
            print(f"‚è±Ô∏è Tempo: {results['performance_metrics']['total_time']:.2f}s")
            print(f"\nüí° Pr√≥ximo passo: streamlit run app.py")
        else:
            print(f"\n‚ùå ERRO NO PIPELINE: {results['error']}")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Pipeline interrompido pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro cr√≠tico: {e}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()