"""Pipeline principal reorganizado - mantendo funcionalidades do projeto_salario.py"""

import sys
import os
from pathlib import Path

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

# Imports absolutos para evitar problemas
from src.utils.logger import setup_logging
from src.data.processor import DataProcessor
from src.visualization.styles import setup_matplotlib_style
from src.visualization.plots import VisualizationGenerator
from src.models.trainer import ModelTrainer
import logging

def check_data_structure():
    """Verificar se a estrutura de dados estÃ¡ correta"""
    project_root = Path(__file__).parent
    data_file = project_root / "data" / "raw" / "4-Carateristicas_salario.csv"
    
    if not data_file.exists():
        logging.warning("âš ï¸ Estrutura de dados nÃ£o configurada corretamente!")
        logging.info("ğŸ”§ Execute primeiro: python setup_data_structure.py")
        
        # Tentar configurar automaticamente
        try:
            import setup_data_structure
            setup_data_structure.setup_data_structure()
            if data_file.exists():
                logging.info("âœ… Estrutura configurada automaticamente!")
            else:
                raise FileNotFoundError("NÃ£o foi possÃ­vel configurar a estrutura automaticamente")
        except Exception as e:
            logging.error(f"âŒ Erro ao configurar estrutura: {e}")
            logging.error("Manual: Coloque '4-Carateristicas_salario.csv' em 'data/raw/'")
            raise

def main():
    """Pipeline principal mantendo todas as funcionalidades"""
    # Configurar logging
    logger = setup_logging()
    logging.info("ğŸš€ Iniciando Sistema de AnÃ¡lise Salarial v2.0")
    logging.info("="*60)
    
    try:
        # 0. Verificar estrutura de dados
        check_data_structure()
        
        # 1. Configurar estilo de visualizaÃ§Ã£o
        setup_matplotlib_style()
        logging.info("âœ… Estilo de visualizaÃ§Ã£o configurado")
        
        # 2. Processar dados (de data/raw/ para data/processed/)
        processor = DataProcessor()
        df = processor.process_complete_pipeline()
        
        # 3. Gerar visualizaÃ§Ãµes (em output/images/)
        viz_generator = VisualizationGenerator()
        viz_generator.generate_all_plots(df)
        
        # 4. Treinar modelos (salvar em models/ e output/models/)
        trainer = ModelTrainer()
        models, results = trainer.train_complete_pipeline(df)
        
        # 5. RelatÃ³rio final
        logging.info("\n" + "="*60)
        logging.info("RELATÃ“RIO FINAL")
        logging.info("="*60)
        
        logging.info(f"ğŸ“Š Dataset final: {len(df)} registros")
        logging.info("ğŸ¤– Modelos treinados:")
        for name, result in results.items():
            logging.info(f"  â€¢ {name}: {result['accuracy']:.4f}")
        
        logging.info("ğŸ“‚ Estrutura de saÃ­das:")
        logging.info("  ğŸ“ˆ VisualizaÃ§Ãµes: output/images/")
        logging.info("  ğŸ¤– Modelos: models/trained/ e output/models/")
        logging.info("  ğŸ“Š Dados processados: data/processed/")
        logging.info("  ğŸ’¾ Compatibilidade dashboard: arquivos .joblib na raiz")
        logging.info("\nğŸ‰ Pipeline concluÃ­do com sucesso!")
        
    except Exception as e:
        logging.error(f"âŒ Erro durante execuÃ§Ã£o: {e}")
        raise

if __name__ == "__main__":
    main()