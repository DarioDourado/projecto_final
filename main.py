"""
Pipeline Principal SQL-Only - Sistema Exclusivo de Banco de Dados
VersÃ£o sem dependÃªncia de CSV
"""

import sys
import logging
import os
from pathlib import Path
import argparse

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

# Imports bÃ¡sicos
from src.utils.logger import setup_logging
from src.visualization.styles import setup_matplotlib_style

class MasterPipelineSQL:
    """Pipeline principal exclusivo para banco de dados"""
    
    def __init__(self, force_migration: bool = False):
        self.logger = setup_logging()
        self.force_migration = force_migration
        
        # Verificar configuraÃ§Ã£o de banco OBRIGATÃ“RIA
        if not self._check_database_config():
            raise ValueError("âŒ ConfiguraÃ§Ã£o de banco de dados obrigatÃ³ria!")
        
        # Import dos pipelines SQL com tratamento de erro
        try:
            from src.pipelines.data_pipeline import DataPipelineSQL
            from src.pipelines.ml_pipeline import MLPipeline
            from src.pipelines.analysis_pipeline import AnalysisPipeline
            from src.pipelines.performance_pipeline import PerformancePipeline
            
            self.data_pipeline = DataPipelineSQL(force_migration=force_migration)
            self.ml_pipeline = MLPipeline()
            self.analysis_pipeline = AnalysisPipeline()
            self.performance_pipeline = PerformancePipeline()
        except ImportError as e:
            self.logger.error(f"âŒ Erro ao importar pipelines: {e}")
            raise
        
        # Resultados
        self.df = None
        self.models = {}
        self.results = {}
        self.best_k = None
        self.rules = []
    
    def _check_database_config(self) -> bool:
        """Verificar configuraÃ§Ã£o obrigatÃ³ria do banco"""
        required_vars = ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            logging.error(f"âŒ VariÃ¡veis de ambiente obrigatÃ³rias ausentes: {missing_vars}")
            logging.info("ğŸ’¡ Configure as variÃ¡veis de ambiente:")
            logging.info("   export DB_HOST=localhost")
            logging.info("   export DB_NAME=salary_analysis")
            logging.info("   export DB_USER=salary_user")
            logging.info("   export DB_PASSWORD=sua_senha")
            return False
        
        logging.info("âœ… ConfiguraÃ§Ã£o de banco de dados encontrada")
        return True
    
    def run(self):
        """Executar pipeline completo SQL-only com tratamento de erros"""
        logging.info("ğŸš€ Sistema de AnÃ¡lise Salarial - VERSÃƒO SQL EXCLUSIVA")
        logging.info("ğŸ—„ï¸ Fonte de dados: BANCO DE DADOS MySQL")
        logging.info("="*60)
        
        try:
            # 0. ConfiguraÃ§Ãµes iniciais
            self._setup()
            
            # 1. Pipeline de dados SQL
            logging.info("\nğŸ“Š PIPELINE DE DADOS SQL")
            logging.info("-" * 40)
            self.df = self.data_pipeline.run()
            
            if self.df is None or len(self.df) == 0:
                raise ValueError("âŒ Nenhum dado carregado do banco")
            
            logging.info(f"âœ… Dados carregados: {len(self.df)} registros")
            
            # 2. Pipeline de ML com tratamento de erro
            logging.info("\nğŸ¤– PIPELINE DE ML")
            logging.info("-" * 40)
            
            try:
                self.models, self.results = self.ml_pipeline.run(self.df)
                
                if not self.models:
                    logging.warning("âš ï¸ Nenhum modelo foi treinado com sucesso")
                else:
                    logging.info(f"âœ… {len(self.models)} modelos treinados")
                    
            except Exception as e:
                logging.error(f"âŒ Erro no pipeline ML: {e}")
                logging.warning("âš ï¸ Continuando sem modelos ML...")
                self.models = {}
                self.results = {}
            
            # 3. Pipeline de performance (apenas se houver modelos)
            if self.models:
                logging.info("\nğŸ“ˆ PIPELINE DE PERFORMANCE")
                logging.info("-" * 40)
                try:
                    self.performance_pipeline.run(self.models, self.results, self.df)
                except Exception as e:
                    logging.error(f"âŒ Erro no pipeline de performance: {e}")
            
            # 4. Pipelines de anÃ¡lise
            logging.info("\nğŸ¯ PIPELINE DE ANÃLISES")
            logging.info("-" * 40)
            
            try:
                self.best_k = self.analysis_pipeline.run_clustering(self.df)
            except Exception as e:
                logging.error(f"âŒ Erro no clustering: {e}")
                self.best_k = None
            
            try:
                self.rules = self.analysis_pipeline.run_association_rules(self.df)
            except Exception as e:
                logging.error(f"âŒ Erro nas regras de associaÃ§Ã£o: {e}")
                self.rules = []
            
            try:
                self.analysis_pipeline.run_advanced_metrics(self.df, self.results)
            except Exception as e:
                logging.error(f"âŒ Erro nas mÃ©tricas avanÃ§adas: {e}")
            
            # 5. Criar views SQL de anÃ¡lise
            logging.info("\nğŸ—„ï¸ CRIANDO VIEWS DE ANÃLISE")
            logging.info("-" * 40)
            try:
                self.data_pipeline.create_analysis_views()
            except Exception as e:
                logging.error(f"âŒ Erro ao criar views SQL: {e}")
            
            # 6. RelatÃ³rio final
            self._generate_final_report()
            
            logging.info("ğŸ‰ Pipeline SQL concluÃ­do!")
            logging.info("ğŸ“Š Dashboard: streamlit run app.py")
            
        except Exception as e:
            logging.error(f"âŒ Erro crÃ­tico durante execuÃ§Ã£o: {e}")
            import traceback
            logging.error(traceback.format_exc())
            
            # Tentar relatÃ³rio de emergÃªncia
            try:
                self._emergency_report()
            except:
                pass
            
            raise
    
    def _setup(self):
        """ConfiguraÃ§Ãµes iniciais SQL-only"""
        try:
            setup_matplotlib_style()
            
            # Testar conexÃ£o com banco
            self._test_database_connection()
            
            logging.info("âœ… ConfiguraÃ§Ãµes SQL iniciais concluÃ­das")
        except Exception as e:
            logging.error(f"âŒ Erro na configuraÃ§Ã£o: {e}")
            raise
    
    def _test_database_connection(self):
        """Testar conexÃ£o com banco de dados"""
        try:
            from src.database.connection import DatabaseConnection
            
            with DatabaseConnection() as db:
                result = db.execute_query("SELECT 1 as test")
                if result:
                    logging.info("âœ… ConexÃ£o com banco de dados funcionando")
                else:
                    raise ValueError("ConexÃ£o falhou")
                    
        except Exception as e:
            logging.error(f"âŒ Erro na conexÃ£o com banco: {e}")
            raise
    
    def _generate_final_report(self):
        """Gerar relatÃ³rio final SQL"""
        logging.info("\n" + "="*60)
        logging.info("ğŸ“Š RELATÃ“RIO FINAL SQL")
        logging.info("="*60)
        
        # EstatÃ­sticas do banco
        try:
            stats = self.data_pipeline.get_statistics_from_sql()
            total_records = stats.get('total_records', 0)
            logging.info(f"ğŸ“‹ Registros no banco: {total_records:,}")
            
            if 'salary_stats' in stats:
                for salary_stat in stats['salary_stats']:
                    salary_range = salary_stat['salary_range']
                    count = salary_stat['count']
                    avg_age = salary_stat['avg_age']
                    logging.info(f"  ğŸ’° {salary_range}: {count:,} pessoas (idade mÃ©dia: {avg_age:.1f})")
        
        except Exception as e:
            logging.warning(f"âš ï¸ Erro nas estatÃ­sticas SQL: {e}")
        
        # Dados processados
        if self.df is not None:
            logging.info(f"ğŸ“Š Dataset ML: {len(self.df)} registros processados")
        
        # Modelos treinados
        logging.info("ğŸ¤– Modelos treinados:")
        for name, result in self.results.items():
            accuracy = result.get('accuracy', 0)
            logging.info(f"  â€¢ {name}: {accuracy:.4f}")
        
        # Clustering
        if self.best_k:
            logging.info(f"ğŸ¯ Clustering: {self.best_k} clusters identificados")
        
        # Regras de associaÃ§Ã£o
        rules_count = len(self.rules) if hasattr(self.rules, '__len__') else 0
        logging.info(f"ğŸ“‹ Regras de associaÃ§Ã£o: {rules_count}")
        
        # Arquivos gerados
        self._show_generated_files()
        
        # InstruÃ§Ãµes SQL
        logging.info("\nğŸ’¡ Para anÃ¡lises SQL diretas:")
        logging.info("   â€¢ Use as views criadas: high_earners_view, education_analysis_view")
        logging.info("   â€¢ Execute queries customizadas via dashboard")
        logging.info("   â€¢ Acesse anÃ¡lises em tempo real via SQL")
    
    def _show_generated_files(self):
        """Mostrar arquivos gerados"""
        output_dir = Path("output")
        
        if output_dir.exists():
            images_dir = output_dir / "images"
            analysis_dir = output_dir / "analysis"
            
            if images_dir.exists():
                image_files = list(images_dir.glob("*.png"))
                logging.info(f"\nğŸ¨ {len(image_files)} visualizaÃ§Ãµes em output/images/")
                for img in image_files[:3]:
                    logging.info(f"  â€¢ {img.name}")
                if len(image_files) > 3:
                    logging.info(f"  â€¢ ... e mais {len(image_files) - 3}")
            
            if analysis_dir.exists():
                analysis_files = list(analysis_dir.glob("*"))
                logging.info(f"\nğŸ“Š {len(analysis_files)} anÃ¡lises em output/analysis/")
                for file in analysis_files:
                    logging.info(f"  â€¢ {file.name}")
        
        processed_dir = Path("data/processed")
        if processed_dir.exists():
            joblib_files = list(processed_dir.glob("*.joblib"))
            logging.info(f"\nğŸ“ {len(joblib_files)} modelos em data/processed/")

    def _emergency_report(self):
        """RelatÃ³rio de emergÃªncia quando pipeline falha"""
        logging.info("\nğŸš¨ RELATÃ“RIO DE EMERGÃŠNCIA")
        logging.info("="*40)
        
        if self.df is not None:
            logging.info(f"ğŸ“Š Dados carregados: {len(self.df)} registros")
            logging.info(f"ğŸ“‹ Colunas: {list(self.df.columns)}")
        else:
            logging.info("âŒ Nenhum dado foi carregado")
        
        logging.info(f"ğŸ¤– Modelos criados: {len(self.models)}")
        logging.info(f"ğŸ“Š Resultados: {len(self.results)}")
        
        logging.info("\nğŸ’¡ Para diagnÃ³stico:")
        logging.info("   â€¢ Verificar logs detalhados")
        logging.info("   â€¢ Testar conexÃ£o: python setup_sql_only.py")
        logging.info("   â€¢ Verificar dados: SELECT COUNT(*) FROM person;")

def main():
    """FunÃ§Ã£o principal SQL-only"""
    parser = argparse.ArgumentParser(description="Sistema de AnÃ¡lise Salarial SQL-Only")
    parser.add_argument('--migrate', action='store_true', 
                       help='ForÃ§ar migraÃ§Ã£o CSVâ†’SQL (se CSV disponÃ­vel)')
    parser.add_argument('--setup-db', action='store_true',
                       help='Apenas configurar estrutura do banco')
    
    args = parser.parse_args()
    
    # Verificar variÃ¡veis de ambiente
    if not all(os.getenv(var) for var in ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']):
        print("âŒ ERRO: ConfiguraÃ§Ã£o de banco de dados obrigatÃ³ria!")
        print("\nğŸ’¡ Configure as variÃ¡veis de ambiente:")
        print("export DB_HOST=localhost")
        print("export DB_NAME=salary_analysis")
        print("export DB_USER=salary_user")
        print("export DB_PASSWORD=sua_senha")
        print("\nğŸ”§ Ou crie arquivo .env com essas variÃ¡veis")
        return
    
    # Setup apenas da estrutura
    if args.setup_db:
        try:
            from src.database.migration import DatabaseMigrator
            migrator = DatabaseMigrator()
            if migrator.create_database_structure():
                print("âœ… Estrutura do banco criada com sucesso!")
            else:
                print("âŒ Erro ao criar estrutura do banco")
        except Exception as e:
            print(f"âŒ Erro: {e}")
        return
    
    try:
        pipeline = MasterPipelineSQL(force_migration=args.migrate)
        pipeline.run()
    except Exception as e:
        logging.error(f"âŒ Erro crÃ­tico: {e}")
        print(f"\nâŒ ERRO: {e}")
        print("\nğŸ’¡ SoluÃ§Ãµes possÃ­veis:")
        print("  1. Verificar conexÃ£o com banco: mysql -u salary_user -p salary_analysis")
        print("  2. Criar estrutura: python main.py --setup-db")
        print("  3. Migrar dados: python main.py --migrate")
        print("  4. Verificar variÃ¡veis de ambiente")

if __name__ == "__main__":
    main()