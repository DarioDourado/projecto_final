"""
Pipeline Principal SQL-Only - Sistema Exclusivo de Banco de Dados
Vers√£o sem depend√™ncia de CSV
"""

import sys
import logging
import os
from pathlib import Path
import argparse

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / "src"))

# Imports b√°sicos
from src.utils.logger import setup_logging
from src.visualization.styles import setup_matplotlib_style

class MasterPipelineSQL:
    """Pipeline principal exclusivo para banco de dados"""
    
    def __init__(self, force_migration: bool = False):
        self.logger = setup_logging()
        self.force_migration = force_migration
        
        # Verificar configura√ß√£o de banco OBRIGAT√ìRIA
        if not self._check_database_config():
            raise ValueError("‚ùå Configura√ß√£o de banco de dados obrigat√≥ria!")
        
        # Import dos pipelines SQL com tratamento de erro
        try:
            from src.pipelines.data_pipeline import DataPipelineSQL
            from src.pipelines.ml_pipeline import MLPipeline
            from src.pipelines.analysis_pipeline import AnalysisPipeline
            from src.pipelines.performance_pipeline import PerformancePipeline
            
            self.data_pipeline = DataPipelineSQL(force_migration=force_migration)
            self.ml_pipeline = MLPipeline()
            self.analysis_pipeline = AnalysisPipeline()
            self.performance_pipeline = PerformancePipeline()
        except ImportError as e:
            self.logger.error(f"‚ùå Erro ao importar pipelines: {e}")
            raise
        
        # Resultados
        self.df = None
        self.models = {}
        self.results = {}
        self.best_k = None
        self.rules = []
    
    def _check_database_config(self) -> bool:
        """Verificar configura√ß√£o obrigat√≥ria do banco"""
        required_vars = ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            logging.error(f"‚ùå Vari√°veis de ambiente obrigat√≥rias ausentes: {missing_vars}")
            logging.info("üí° Configure as vari√°veis de ambiente:")
            logging.info("   export DB_HOST=localhost")
            logging.info("   export DB_NAME=salary_analysis")
            logging.info("   export DB_USER=salary_user")
            logging.info("   export DB_PASSWORD=sua_senha")
            return False
        
        logging.info("‚úÖ Configura√ß√£o de banco de dados encontrada")
        return True
    
    def run(self):
        """Executar pipeline completo SQL-only com tratamento de erros"""
        logging.info("üöÄ Sistema de An√°lise Salarial - VERS√ÉO SQL EXCLUSIVA")
        logging.info("üóÑÔ∏è Fonte de dados: BANCO DE DADOS MySQL")
        logging.info("="*60)
        
        try:
            # 0. Configura√ß√µes iniciais
            self._setup()
            
            # 1. Pipeline de dados SQL
            logging.info("\nüìä PIPELINE DE DADOS SQL")
            logging.info("-" * 40)
            self.df = self.data_pipeline.run()
            
            if self.df is None or len(self.df) == 0:
                raise ValueError("‚ùå Nenhum dado carregado do banco")
            
            logging.info(f"‚úÖ Dados carregados: {len(self.df)} registros")
            
            # 2. Pipeline de ML com tratamento de erro
            logging.info("\nü§ñ PIPELINE DE ML")
            logging.info("-" * 40)
            
            try:
                self.models, self.results = self.ml_pipeline.run(self.df)
                
                if not self.models:
                    logging.warning("‚ö†Ô∏è Nenhum modelo foi treinado com sucesso")
                else:
                    logging.info(f"‚úÖ {len(self.models)} modelos treinados")
                    
            except Exception as e:
                logging.error(f"‚ùå Erro no pipeline ML: {e}")
                logging.warning("‚ö†Ô∏è Continuando sem modelos ML...")
                self.models = {}
                self.results = {}
            
            # 3. Pipeline de performance (apenas se houver modelos)
            if self.models:
                logging.info("\nüìà PIPELINE DE PERFORMANCE")
                logging.info("-" * 40)
                try:
                    self.performance_pipeline.run(self.models, self.results, self.df)
                except Exception as e:
                    logging.error(f"‚ùå Erro no pipeline de performance: {e}")
            
            # 4. Pipelines de an√°lise
            logging.info("\nüéØ PIPELINE DE AN√ÅLISES")
            logging.info("-" * 40)
            
            try:
                self.best_k = self.analysis_pipeline.run_clustering(self.df)
            except Exception as e:
                logging.error(f"‚ùå Erro no clustering: {e}")
                self.best_k = None
            
            try:
                self.rules = self.analysis_pipeline.run_association_rules(self.df)
            except Exception as e:
                logging.error(f"‚ùå Erro nas regras de associa√ß√£o: {e}")
                self.rules = []
            
            try:
                self.analysis_pipeline.run_advanced_metrics(self.df, self.results)
            except Exception as e:
                logging.error(f"‚ùå Erro nas m√©tricas avan√ßadas: {e}")
            
            # 5. Criar views SQL de an√°lise
            logging.info("\nüóÑÔ∏è CRIANDO VIEWS DE AN√ÅLISE")
            logging.info("-" * 40)
            try:
                self.data_pipeline.create_analysis_views()
            except Exception as e:
                logging.error(f"‚ùå Erro ao criar views SQL: {e}")
            
            # 6. Relat√≥rio final
            self._generate_final_report()
            
            logging.info("üéâ Pipeline SQL conclu√≠do!")
            logging.info("üìä Dashboard: streamlit run app.py")
            
        except Exception as e:
            logging.error(f"‚ùå Erro cr√≠tico durante execu√ß√£o: {e}")
            import traceback
            logging.error(traceback.format_exc())
            
            # Tentar relat√≥rio de emerg√™ncia
            try:
                self._emergency_report()
            except:
                pass
            
            raise
    
    def _setup(self):
        """Configura√ß√µes iniciais SQL-only"""
        try:
            setup_matplotlib_style()
            
            # Testar conex√£o com banco
            self._test_database_connection()
            
            logging.info("‚úÖ Configura√ß√µes SQL iniciais conclu√≠das")
        except Exception as e:
            logging.error(f"‚ùå Erro na configura√ß√£o: {e}")
            raise
    
    def _test_database_connection(self):
        """Testar conex√£o com banco de dados"""
        try:
            from src.database.connection import DatabaseConnection
            
            with DatabaseConnection() as db:
                result = db.execute_query("SELECT 1 as test")
                if result:
                    logging.info("‚úÖ Conex√£o com banco de dados funcionando")
                else:
                    raise ValueError("Conex√£o falhou")
                    
        except Exception as e:
            logging.error(f"‚ùå Erro na conex√£o com banco: {e}")
            raise
    
    def _generate_final_report(self):
        """Gerar relat√≥rio final SQL"""
        logging.info("\n" + "="*60)
        logging.info("üìä RELAT√ìRIO FINAL SQL")
        logging.info("="*60)
        
        # Estat√≠sticas do banco
        try:
            stats = self.data_pipeline.get_statistics_from_sql()
            total_records = stats.get('total_records', 0)
            logging.info(f"üìã Registros no banco: {total_records:,}")
            
            if 'salary_stats' in stats:
                for salary_stat in stats['salary_stats']:
                    salary_range = salary_stat['salary_range']
                    count = salary_stat['count']
                    avg_age = salary_stat['avg_age']
                    logging.info(f"  üí∞ {salary_range}: {count:,} pessoas (idade m√©dia: {avg_age:.1f})")
        
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Erro nas estat√≠sticas SQL: {e}")
        
        # Dados processados
        if self.df is not None:
            logging.info(f"üìä Dataset ML: {len(self.df)} registros processados")
        
        # Modelos treinados
        logging.info("ü§ñ Modelos treinados:")
        for name, result in self.results.items():
            accuracy = result.get('accuracy', 0)
            logging.info(f"  ‚Ä¢ {name}: {accuracy:.4f}")
        
        # Clustering
        if self.best_k:
            logging.info(f"üéØ Clustering: {self.best_k} clusters identificados")
        
        # Regras de associa√ß√£o
        rules_count = len(self.rules) if hasattr(self.rules, '__len__') else 0
        logging.info(f"üìã Regras de associa√ß√£o: {rules_count}")
        
        # Arquivos gerados
        self._show_generated_files()
        
        # Instru√ß√µes SQL
        logging.info("\nüí° Para an√°lises SQL diretas:")
        logging.info("   ‚Ä¢ Use as views criadas: high_earners_view, education_analysis_view")
        logging.info("   ‚Ä¢ Execute queries customizadas via dashboard")
        logging.info("   ‚Ä¢ Acesse an√°lises em tempo real via SQL")
    
    def _show_generated_files(self):
        """Mostrar arquivos gerados"""
        output_dir = Path("output")
        
        if output_dir.exists():
            images_dir = output_dir / "images"
            analysis_dir = output_dir / "analysis"
            
            if images_dir.exists():
                image_files = list(images_dir.glob("*.png"))
                logging.info(f"\nüé® {len(image_files)} visualiza√ß√µes em output/images/")
                for img in image_files[:3]:
                    logging.info(f"  ‚Ä¢ {img.name}")
                if len(image_files) > 3:
                    logging.info(f"  ‚Ä¢ ... e mais {len(image_files) - 3}")
            
            if analysis_dir.exists():
                analysis_files = list(analysis_dir.glob("*"))
                logging.info(f"\nüìä {len(analysis_files)} an√°lises em output/analysis/")
                for file in analysis_files:
                    logging.info(f"  ‚Ä¢ {file.name}")
        
        processed_dir = Path("data/processed")
        if processed_dir.exists():
            joblib_files = list(processed_dir.glob("*.joblib"))
            logging.info(f"\nüìÅ {len(joblib_files)} modelos em data/processed/")

    def _emergency_report(self):
        """Relat√≥rio de emerg√™ncia quando pipeline falha"""
        logging.info("\nüö® RELAT√ìRIO DE EMERG√äNCIA")
        logging.info("="*40)
        
        if self.df is not None:
            logging.info(f"üìä Dados carregados: {len(self.df)} registros")
            logging.info(f"üìã Colunas: {list(self.df.columns)}")
        else:
            logging.info("‚ùå Nenhum dado foi carregado")
        
        logging.info(f"ü§ñ Modelos criados: {len(self.models)}")
        logging.info(f"üìä Resultados: {len(self.results)}")
        
        logging.info("\nüí° Para diagn√≥stico:")
        logging.info("   ‚Ä¢ Verificar logs detalhados")
        logging.info("   ‚Ä¢ Testar conex√£o: python setup_sql_only.py")
        logging.info("   ‚Ä¢ Verificar dados: SELECT COUNT(*) FROM person;")

def main():
    """Fun√ß√£o principal SQL-only"""
    parser = argparse.ArgumentParser(description="Sistema de An√°lise Salarial SQL-Only")
    parser.add_argument('--migrate', action='store_true', 
                       help='For√ßar migra√ß√£o CSV‚ÜíSQL (se CSV dispon√≠vel)')
    parser.add_argument('--setup-db', action='store_true',
                       help='Apenas configurar estrutura do banco')
    
    args = parser.parse_args()
    
    # Verificar vari√°veis de ambiente
    if not all(os.getenv(var) for var in ['DB_HOST', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']):
        print("‚ùå ERRO: Configura√ß√£o de banco de dados obrigat√≥ria!")
        print("\nüí° Configure as vari√°veis de ambiente:")
        print("export DB_HOST=localhost")
        print("export DB_NAME=salary_analysis")
        print("export DB_USER=salary_user")
        print("export DB_PASSWORD=sua_senha")
        print("\nüîß Ou crie arquivo .env com essas vari√°veis")
        return
    
    # Setup apenas da estrutura
    if args.setup_db:
        try:
            from src.database.migration import DatabaseMigrator
            migrator = DatabaseMigrator()
            if migrator.create_database_structure():
                print("‚úÖ Estrutura do banco criada com sucesso!")
            else:
                print("‚ùå Erro ao criar estrutura do banco")
        except Exception as e:
            print(f"‚ùå Erro: {e}")
        return
    
    try:
        pipeline = MasterPipelineSQL(force_migration=args.migrate)
        pipeline.run()
    except Exception as e:
        logging.error(f"‚ùå Erro cr√≠tico: {e}")
        print(f"\n‚ùå ERRO: {e}")
        print("\nüí° Solu√ß√µes poss√≠veis:")
        print("  1. Verificar conex√£o com banco: mysql -u salary_user -p salary_analysis")
        print("  2. Criar estrutura: python main.py --setup-db")
        print("  3. Migrar dados: python main.py --migrate")
        print("  4. Verificar vari√°veis de ambiente")

if __name__ == "__main__":
    main()