"""
üéì Dashboard Cient√≠fico Acad√™mico - An√°lise Salarial
Sistema Totalmente Integrado com main.py e Relat√≥rio Acad√™mico
Vers√£o: 3.0 - Completamente Refatorado e Corrigido
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib
from pathlib import Path
import json
import logging
from datetime import datetime
import sys
import subprocess
import time
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√µes da p√°gina
st.set_page_config(
    page_title="üéì Dashboard Cient√≠fico - An√°lise Salarial Acad√™mica",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============================================================================
# SISTEMA DE DADOS CORRIGIDO
# =============================================================================

class ScientificDataLoader:
    """Carregador de dados cient√≠fico com paths corretos"""
    
    def __init__(self):
        # ‚úÖ PATHS CORRETOS baseados no workspace real
        self.data_paths = {
            'main_dataset': [
                'bkp/4-Carateristicas_salario.csv',  # ‚úÖ Confirmado no workspace
                'data/raw/4-Carateristicas_salario.csv',
                '4-Carateristicas_salario.csv'
            ],
            'outputs': {
                'dbscan_results': 'output/analysis/dbscan_results.csv',
                'apriori_rules': 'output/analysis/apriori_rules.csv',
                'fp_growth_rules': 'output/analysis/fp_growth_rules.csv',
                'eclat_rules': 'output/analysis/eclat_rules.csv',
                'academic_report': 'output/analysis/relatorio_academico_v2.md',
                'pipeline_summary': 'output/resumo_algoritmos.txt'
            },
            'models': {
                'random_forest': 'data/processed/random_forest_model_v2.joblib',
                'logistic_regression': 'data/processed/logistic_regression_model_v2.joblib',
                'preprocessor': 'data/processed/preprocessor_v2.joblib'
            }
        }
        
        self.logger = logging.getLogger(__name__)
    
    def load_main_dataset(self):
        """Carregar dataset principal com paths corretos"""
        for path in self.data_paths['main_dataset']:
            if Path(path).exists():
                try:
                    df = pd.read_csv(path)
                    self.logger.info(f"‚úÖ Dataset carregado: {path} ({len(df):,} registros)")
                    return df, f"‚úÖ Dataset: {len(df):,} registros de {path}"
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erro ao carregar {path}: {e}")
                    continue
        
        # Fallback para dados sint√©ticos
        return self._create_sample_data(), "‚ö†Ô∏è Usando dados de demonstra√ß√£o (arquivo n√£o encontrado)"
    
    def check_pipeline_execution(self):
        """Verificar se o pipeline main.py foi executado"""
        results = {
            'executed': False,
            'algorithms': {},
            'models': {},
            'files_found': [],
            'summary': None
        }
        
        # Verificar arquivos de output
        for algo, path in self.data_paths['outputs'].items():
            if Path(path).exists():
                results['algorithms'][algo] = True
                results['files_found'].append(path)
                
                # Carregar dados se poss√≠vel
                if path.endswith('.csv'):
                    try:
                        df = pd.read_csv(path)
                        results['algorithms'][f"{algo}_records"] = len(df)
                    except:
                        pass
            else:
                results['algorithms'][algo] = False
        
        # Verificar modelos
        for model, path in self.data_paths['models'].items():
            results['models'][model] = Path(path).exists()
        
        # Verificar resumo do pipeline
        summary_path = self.data_paths['outputs']['pipeline_summary']
        if Path(summary_path).exists():
            try:
                with open(summary_path, 'r', encoding='utf-8') as f:
                    results['summary'] = f.read()
                results['executed'] = True
            except:
                pass
        
        # Status geral
        algorithms_ok = sum(1 for v in results['algorithms'].values() if isinstance(v, bool) and v)
        models_ok = sum(results['models'].values())
        
        results['execution_score'] = (algorithms_ok + models_ok) / (len(self.data_paths['outputs']) + len(self.data_paths['models']))
        results['executed'] = results['execution_score'] > 0.5
        
        return results
    
    def load_algorithm_results(self, algorithm):
        """Carregar resultados de algoritmo espec√≠fico"""
        if algorithm in self.data_paths['outputs']:
            path = self.data_paths['outputs'][algorithm]
            if Path(path).exists():
                try:
                    if path.endswith('.csv'):
                        return pd.read_csv(path)
                    elif path.endswith('.md'):
                        with open(path, 'r', encoding='utf-8') as f:
                            return f.read()
                    elif path.endswith('.txt'):
                        with open(path, 'r', encoding='utf-8') as f:
                            return f.read()
                except Exception as e:
                    self.logger.error(f"Erro ao carregar {algorithm}: {e}")
        return None
    
    def _create_sample_data(self):
        """Criar dados de amostra baseados no dataset original"""
        np.random.seed(42)
        n_samples = 1000
        
        # Dados baseados nas caracter√≠sticas do dataset real
        ages = np.random.normal(39, 13, n_samples).astype(int)
        ages = np.clip(ages, 17, 90)
        
        education_nums = np.random.randint(1, 17, n_samples)
        hours_per_week = np.random.normal(40, 12, n_samples).astype(int)
        hours_per_week = np.clip(hours_per_week, 1, 99)
        
        return pd.DataFrame({
            'age': ages,
            'workclass': np.random.choice(['Private', 'Self-emp-not-inc', 'Local-gov', 'State-gov'], n_samples),
            'fnlwgt': np.random.randint(12285, 1484705, n_samples),
            'education': np.random.choice(['Bachelors', 'HS-grad', 'Some-college', 'Masters'], n_samples),
            'education-num': education_nums,
            'marital-status': np.random.choice(['Married-civ-spouse', 'Never-married', 'Divorced'], n_samples),
            'occupation': np.random.choice(['Prof-specialty', 'Craft-repair', 'Exec-managerial'], n_samples),
            'relationship': np.random.choice(['Husband', 'Not-in-family', 'Wife'], n_samples),
            'race': np.random.choice(['White', 'Black', 'Asian-Pac-Islander'], n_samples),
            'sex': np.random.choice(['Male', 'Female'], n_samples),
            'capital-gain': np.random.exponential(1077, n_samples).astype(int),
            'capital-loss': np.random.exponential(87, n_samples).astype(int),
            'hours-per-week': hours_per_week,
            'native-country': np.random.choice(['United-States', 'Mexico', 'Philippines'], n_samples),
            'salary': np.random.choice(['<=50K', '>50K'], n_samples, p=[0.76, 0.24])
        })

# =============================================================================
# SISTEMA DE AUTENTICA√á√ÉO ACAD√äMICA
# =============================================================================

class AcademicAuthSystem:
    """Sistema de autentica√ß√£o para ambiente acad√™mico"""
    
    def __init__(self):
        self.users = {
            "professor": {"password": "academic2025", "role": "admin", "name": "Professor", "access": "full"},
            "aluno": {"password": "student2025", "role": "student", "name": "Estudante", "access": "read"},
            "revisor": {"password": "reviewer2025", "role": "reviewer", "name": "Revisor Cient√≠fico", "access": "analysis"},
            "demo": {"password": "demo", "role": "guest", "name": "Demonstra√ß√£o", "access": "limited"}
        }
    
    def authenticate(self, username, password):
        if username in self.users and self.users[username]["password"] == password:
            return True, self.users[username]
        return False, None
    
    def show_login_page(self):
        """Interface de login acad√™mica"""
        st.markdown("""
        <div style="text-align: center; padding: 3rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    border-radius: 15px; color: white; margin-bottom: 2rem;">
            <h1>üéì Sistema Acad√™mico de An√°lise Salarial</h1>
            <h3>Dashboard Cient√≠fico Integrado</h3>
            <p><i>Implementa√ß√£o Completa: DBSCAN ‚Ä¢ APRIORI ‚Ä¢ FP-GROWTH ‚Ä¢ ECLAT</i></p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            st.markdown("### üîê Acesso Acad√™mico")
            
            username = st.selectbox(
                "üë§ Perfil de Usu√°rio:",
                ["", "professor", "aluno", "revisor", "demo"],
                help="Selecione seu perfil acad√™mico"
            )
            
            password = st.text_input("üîë Senha:", type="password")
            
            if st.button("üöÄ Entrar no Sistema", use_container_width=True, type="primary"):
                if username and password:
                    success, user_data = self.authenticate(username, password)
                    if success:
                        st.session_state.authenticated = True
                        st.session_state.user = user_data
                        st.session_state.username = username
                        st.success(f"‚úÖ Bem-vindo(a), {user_data['name']}!")
                        st.balloons()
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("‚ùå Credenciais inv√°lidas!")
                else:
                    st.warning("‚ö†Ô∏è Preencha todos os campos!")
            
            # Credenciais de demonstra√ß√£o
            with st.expander("‚ÑπÔ∏è Credenciais de Demonstra√ß√£o"):
                st.markdown("""
                | Usu√°rio | Senha | Acesso |
                |---------|--------|---------|
                | **professor** | academic2024 | Completo |
                | **aluno** | student2024 | Leitura |
                | **revisor** | reviewer2024 | An√°lise |
                | **demo** | demo | Limitado |
                """)

# =============================================================================
# P√ÅGINAS DO DASHBOARD CIENT√çFICO
# =============================================================================

class ScientificDashboardPages:
    """P√°ginas do dashboard cient√≠fico"""
    
    def __init__(self, data_loader):
        self.data_loader = data_loader
    
    def show_overview_page(self, df, pipeline_status):
        """P√°gina de vis√£o geral cient√≠fica"""
        st.title("üìä Vis√£o Geral - An√°lise Cient√≠fica Salarial")
        st.markdown("---")
        
        # Header com informa√ß√µes do projeto
        st.markdown("""
        <div style="background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%); 
                    padding: 2rem; border-radius: 15px; color: white; margin-bottom: 2rem;">
            <h2>üéì Projeto Acad√™mico - An√°lise Salarial</h2>
            <p><strong>Algoritmos Implementados:</strong> DBSCAN, APRIORI, FP-GROWTH, ECLAT, Random Forest, Logistic Regression</p>
            <p><strong>Dataset:</strong> Adult Income Dataset (32.561 registros originais)</p>
            <p><strong>Objetivo:</strong> An√°lise preditiva e descritiva de fatores salariais</p>
        </div>
        """, unsafe_allow_html=True)
        
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "üìä Registros Dataset",
                f"{len(df):,}",
                help="Total de registros carregados"
            )
        
        with col2:
            algorithms_completed = sum(1 for k, v in pipeline_status['algorithms'].items() 
                                     if isinstance(v, bool) and v)
            total_algorithms = len([k for k, v in pipeline_status['algorithms'].items() 
                                  if isinstance(v, bool)])
            st.metric(
                "ü§ñ Algoritmos",
                f"{algorithms_completed}/{total_algorithms}",
                help="Algoritmos executados com sucesso"
            )
        
        with col3:
            models_ready = sum(pipeline_status['models'].values())
            st.metric(
                "üéØ Modelos ML",
                f"{models_ready}/3",
                help="Modelos treinados e dispon√≠veis"
            )
        
        with col4:
            if 'salary' in df.columns:
                high_salary_rate = (df['salary'] == '>50K').mean()
                st.metric(
                    "üí∞ Taxa >50K",
                    f"{high_salary_rate:.1%}",
                    help="Percentual de sal√°rios altos"
                )
        
        # Status detalhado do pipeline
        st.subheader("üî¨ Status dos Algoritmos Cient√≠ficos")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üéØ Clustering & An√°lise N√£o-Supervisionada")
            
            dbscan_status = "‚úÖ Completo" if pipeline_status['algorithms'].get('dbscan_results', False) else "‚ùå Pendente"
            dbscan_records = pipeline_status['algorithms'].get('dbscan_results_records', 0)
            
            st.markdown(f"""
            **DBSCAN Clustering:**
            - Status: {dbscan_status}
            - Registros: {dbscan_records:,} pontos analisados
            - Objetivo: Identificar grupos baseados em densidade
            """)
            
            st.markdown("#### ü§ñ Modelos Supervisionados")
            models = pipeline_status['models']
            
            rf_status = "‚úÖ Treinado" if models.get('random_forest', False) else "‚ùå Ausente"
            lr_status = "‚úÖ Treinado" if models.get('logistic_regression', False) else "‚ùå Ausente"
            
            st.markdown(f"""
            **Random Forest:** {rf_status}
            **Logistic Regression:** {lr_status}
            **Preprocessor:** {'‚úÖ Dispon√≠vel' if models.get('preprocessor', False) else '‚ùå Ausente'}
            """)
        
        with col2:
            st.markdown("#### üìã Regras de Associa√ß√£o")
            
            apriori_status = "‚úÖ Executado" if pipeline_status['algorithms'].get('apriori_rules', False) else "‚ùå Pendente"
            fp_status = "‚úÖ Executado" if pipeline_status['algorithms'].get('fp_growth_rules', False) else "‚ùå Pendente"
            eclat_status = "‚úÖ Executado" if pipeline_status['algorithms'].get('eclat_rules', False) else "‚ùå Pendente"
            
            apriori_records = pipeline_status['algorithms'].get('apriori_rules_records', 0)
            fp_records = pipeline_status['algorithms'].get('fp_growth_rules_records', 0)
            eclat_records = pipeline_status['algorithms'].get('eclat_rules_records', 0)
            
            st.markdown(f"""
            **APRIORI:** {apriori_status} ({apriori_records:,} regras)
            **FP-GROWTH:** {fp_status} ({fp_records:,} regras)
            **ECLAT:** {eclat_status} ({eclat_records:,} regras)
            
            *Objetivo: Descobrir padr√µes frequentes entre vari√°veis categ√≥ricas*
            """)
        
        # Executar pipeline se necess√°rio
        if not pipeline_status['executed']:
            st.warning("‚ö†Ô∏è Pipeline principal n√£o foi executado completamente")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.info("""
                üí° **Para obter resultados completos:**
                1. Execute `python main.py` no terminal
                2. Aguarde a conclus√£o (1-2 minutos)
                3. Recarregue esta p√°gina
                """)
            
            with col2:
                if st.button("üöÄ Executar Pipeline", type="primary"):
                    self._execute_main_pipeline()
        
        # Resumo do pipeline (se dispon√≠vel)
        if pipeline_status['summary']:
            st.subheader("üìÑ Resumo da Execu√ß√£o")
            
            with st.expander("Ver Resumo Completo", expanded=False):
                st.text(pipeline_status['summary'])
        
        # Visualiza√ß√µes de overview
        self._show_overview_visualizations(df)
    
    def show_clustering_page(self, df, pipeline_status):
        """P√°gina de an√°lise de clustering DBSCAN"""
        st.title("üéØ An√°lise de Clustering - DBSCAN")
        st.markdown("---")
        
        # Explica√ß√£o te√≥rica
        with st.expander("üìö Sobre o Algoritmo DBSCAN", expanded=False):
            st.markdown("""
            **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**
            
            - **Tipo:** Clustering baseado em densidade
            - **Vantagens:** Identifica clusters de formas arbitr√°rias, detecta outliers automaticamente
            - **Vari√°veis utilizadas:** age, fnlwgt, education-num, capital-gain, capital-loss, hours-per-week
            - **Par√¢metros:** eps (dist√¢ncia m√°xima), min_samples (pontos m√≠nimos por cluster)
            
            **Justificativa da Escolha das Vari√°veis:**
            1. **age** - Experi√™ncia profissional correlaciona com idade
            2. **education-num** - Anos de estudo = principal preditor salarial  
            3. **hours-per-week** - Carga hor√°ria reflete dedica√ß√£o/disponibilidade
            4. **capital-gain/loss** - Indicadores de classe socioecon√¥mica
            5. **fnlwgt** - Peso populacional para representatividade
            """)
        
        # Resultados do DBSCAN
        if pipeline_status['algorithms'].get('dbscan_results', False):
            dbscan_data = self.data_loader.load_algorithm_results('dbscan_results')
            
            if dbscan_data is not None and not dbscan_data.empty:
                st.success(f"‚úÖ Resultados DBSCAN carregados: {len(dbscan_data):,} pontos analisados")
                
                # M√©tricas de clustering
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    if 'cluster' in dbscan_data.columns:
                        n_clusters = len(dbscan_data['cluster'].unique()) - (1 if -1 in dbscan_data['cluster'].unique() else 0)
                        st.metric("üéØ Clusters Identificados", n_clusters)
                
                with col2:
                    if 'cluster' in dbscan_data.columns:
                        noise_points = (dbscan_data['cluster'] == -1).sum()
                        st.metric("üîä Pontos de Ru√≠do", noise_points)
                
                with col3:
                    if 'cluster' in dbscan_data.columns:
                        noise_percentage = (dbscan_data['cluster'] == -1).mean()
                        st.metric("üìä % Ru√≠do", f"{noise_percentage:.1%}")
                
                with col4:
                    # Tentar calcular silhouette score se dispon√≠vel
                    try:
                        from sklearn.metrics import silhouette_score
                        from sklearn.preprocessing import StandardScaler
                        
                        # Preparar dados para silhouette
                        numeric_cols = ['age', 'education-num', 'hours-per-week', 'capital-gain', 'capital-loss', 'fnlwgt']
                        available_cols = [col for col in numeric_cols if col in dbscan_data.columns]
                        
                        if len(available_cols) > 1 and 'cluster' in dbscan_data.columns:
                            X = dbscan_data[available_cols].fillna(0)
                            labels = dbscan_data['cluster']
                            
                            # Apenas calcular se h√° clusters v√°lidos (n√£o apenas ru√≠do)
                            if len(labels.unique()) > 1 and not all(labels == -1):
                                scaler = StandardScaler()
                                X_scaled = scaler.fit_transform(X)
                                silhouette = silhouette_score(X_scaled, labels)
                                st.metric("üìà Silhouette Score", f"{silhouette:.3f}")
                            else:
                                st.metric("üìà Silhouette Score", "N/A")
                        else:
                            st.metric("üìà Silhouette Score", "N/A")
                    except:
                        st.metric("üìà Silhouette Score", "N/A")
                
                # Visualiza√ß√µes dos clusters
                st.subheader("üìä Visualiza√ß√£o dos Clusters")
                
                self._plot_dbscan_results(dbscan_data)
                
                # An√°lise dos perfis dos clusters
                st.subheader("üë• Perfis dos Clusters")
                
                self._analyze_cluster_profiles(dbscan_data)
                
                # Dados tabulares
                st.subheader("üìã Dados dos Clusters")
                
                # Filtros
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'cluster' in dbscan_data.columns:
                        cluster_options = ['Todos'] + sorted(dbscan_data['cluster'].unique().tolist())
                        selected_cluster = st.selectbox("Filtrar por Cluster:", cluster_options)
                
                with col2:
                    show_noise = st.checkbox("Incluir Pontos de Ru√≠do", value=True)
                
                # Aplicar filtros
                filtered_data = dbscan_data.copy()
                
                if selected_cluster != 'Todos':
                    filtered_data = filtered_data[filtered_data['cluster'] == selected_cluster]
                
                if not show_noise and 'cluster' in filtered_data.columns:
                    filtered_data = filtered_data[filtered_data['cluster'] != -1]
                
                st.dataframe(
                    filtered_data,
                    use_container_width=True,
                    height=400
                )
                
            else:
                st.error("‚ùå Erro ao carregar dados do DBSCAN")
        else:
            st.info("‚ÑπÔ∏è Execute o pipeline principal (main.py) para gerar os resultados do DBSCAN")
            
            # Mostrar explica√ß√£o conceitual
            st.subheader("üéì Conceito Te√≥rico - DBSCAN")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **Processo do DBSCAN:**
                1. Define pontos core (‚â• min_samples vizinhos)
                2. Expande clusters a partir dos pontos core
                3. Marca pontos isolados como ru√≠do (-1)
                4. Agrupa pontos conectados por densidade
                """)
            
            with col2:
                st.markdown("""
                **Par√¢metros T√≠picos:**
                - **eps:** 0.5 (dist√¢ncia m√°xima entre pontos)
                - **min_samples:** 5 (pontos m√≠nimos por cluster)
                - **Normaliza√ß√£o:** StandardScaler aplicado
                """)
    
    def show_association_rules_page(self, df, pipeline_status):
        """P√°gina de regras de associa√ß√£o"""
        st.title("üìã Regras de Associa√ß√£o")
        st.markdown("---")
        
        # Sele√ß√£o do algoritmo
        col1, col2 = st.columns([1, 3])
        
        with col1:
            algorithm = st.selectbox(
                "üîç Algoritmo:",
                ["apriori", "fp_growth", "eclat"],
                help="Selecione o algoritmo de minera√ß√£o de regras"
            )
        
        with col2:
            # Explica√ß√£o do algoritmo selecionado
            algorithm_info = {
                "apriori": "**APRIORI**: Algoritmo cl√°ssico que gera candidatos iterativamente",
                "fp_growth": "**FP-GROWTH**: Usa √°rvore FP para minera√ß√£o eficiente sem candidatos",
                "eclat": "**ECLAT**: Baseado em intersec√ß√£o de conjuntos, eficiente para datasets densos"
            }
            st.info(algorithm_info[algorithm])
        
        # Carregar regras do algoritmo selecionado
        rules_key = f"{algorithm}_rules"
        
        if pipeline_status['algorithms'].get(rules_key, False):
            rules_data = self.data_loader.load_algorithm_results(rules_key)
            
            if rules_data is not None and not rules_data.empty:
                st.success(f"‚úÖ {len(rules_data):,} regras {algorithm.upper()} carregadas")
                
                # M√©tricas das regras
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    avg_support = rules_data['support'].mean() if 'support' in rules_data.columns else 0
                    st.metric("üìä Support M√©dio", f"{avg_support:.3f}")
                
                with col2:
                    avg_confidence = rules_data['confidence'].mean() if 'confidence' in rules_data.columns else 0
                    st.metric("üéØ Confidence M√©dio", f"{avg_confidence:.3f}")
                
                with col3:
                    if 'lift' in rules_data.columns:
                        avg_lift = rules_data['lift'].mean()
                        st.metric("üìà Lift M√©dio", f"{avg_lift:.3f}")
                    else:
                        st.metric("üìà Lift M√©dio", "N/A")
                
                with col4:
                    strong_rules = 0
                    if 'confidence' in rules_data.columns and 'lift' in rules_data.columns:
                        strong_rules = len(rules_data[(rules_data['confidence'] > 0.7) & (rules_data['lift'] > 1.2)])
                    st.metric("üí™ Regras Fortes", strong_rules)
                
                # Filtros interativos
                st.subheader("üîç Filtros de An√°lise")
                
                col1, col2, col3 = st.columns(3)
                
                filtered_rules = rules_data.copy()
                
                with col1:
                    if 'support' in rules_data.columns:
                        min_support = st.slider(
                            "Support m√≠nimo:", 
                            0.0, 
                            float(rules_data['support'].max()), 
                            0.01, 
                            0.01,
                            help="Frequ√™ncia m√≠nima do conjunto de itens"
                        )
                        filtered_rules = filtered_rules[filtered_rules['support'] >= min_support]
                
                with col2:
                    if 'confidence' in rules_data.columns:
                        min_confidence = st.slider(
                            "Confidence m√≠nimo:", 
                            0.0, 
                            1.0, 
                            0.5, 
                            0.01,
                            help="Probabilidade condicional da regra"
                        )
                        filtered_rules = filtered_rules[filtered_rules['confidence'] >= min_confidence]
                
                with col3:
                    if 'lift' in rules_data.columns:
                        min_lift = st.slider(
                            "Lift m√≠nimo:", 
                            1.0, 
                            float(rules_data['lift'].max()) if rules_data['lift'].max() > 1 else 2.0, 
                            1.0, 
                            0.1,
                            help="For√ßa da associa√ß√£o (>1 = positiva)"
                        )
                        filtered_rules = filtered_rules[filtered_rules['lift'] >= min_lift]
                
                # Resultados filtrados
                st.subheader(f"üìã Regras {algorithm.upper()} Filtradas ({len(filtered_rules)} de {len(rules_data)})")
                
                if not filtered_rules.empty:
                    # Preparar dados para exibi√ß√£o
                    display_rules = filtered_rules.copy()
                    
                    # Arredondar valores num√©ricos
                    numeric_cols = display_rules.select_dtypes(include=[np.number]).columns
                    display_rules[numeric_cols] = display_rules[numeric_cols].round(4)
                    
                    # Ordenar por lift decrescente
                    if 'lift' in display_rules.columns:
                        display_rules = display_rules.sort_values('lift', ascending=False)
                    
                    st.dataframe(
                        display_rules,
                        use_container_width=True,
                        height=400
                    )
                    
                    # Visualiza√ß√µes das regras
                    st.subheader("üìä Visualiza√ß√£o das Regras")
                    
                    self._plot_association_rules(filtered_rules, algorithm)
                    
                    # Top regras
                    st.subheader("üèÜ Top 10 Regras Mais Relevantes")
                    
                    if 'lift' in filtered_rules.columns:
                        top_rules = filtered_rules.nlargest(10, 'lift')
                        
                        for idx, rule in top_rules.iterrows():
                            with st.container():
                                col1, col2, col3 = st.columns([2, 1, 1])
                                
                                with col1:
                                    antecedents = rule.get('antecedents', 'N/A')
                                    consequents = rule.get('consequents', 'N/A')
                                    st.write(f"**Se** {antecedents} **‚Üí Ent√£o** {consequents}")
                                
                                with col2:
                                    confidence = rule.get('confidence', 0)
                                    st.write(f"Conf: {confidence:.3f}")
                                
                                with col3:
                                    lift = rule.get('lift', 0)
                                    st.write(f"Lift: {lift:.3f}")
                
                else:
                    st.info("‚ÑπÔ∏è Nenhuma regra atende aos crit√©rios selecionados. Ajuste os filtros.")
            else:
                st.error(f"‚ùå Erro ao carregar regras {algorithm.upper()}")
        else:
            st.info(f"‚ÑπÔ∏è Execute o pipeline principal para gerar regras {algorithm.upper()}")
            
            # Explica√ß√£o conceitual
            st.subheader(f"üéì Conceito - {algorithm.upper()}")
            
            concepts = {
                "apriori": {
                    "description": "Algoritmo cl√°ssico de minera√ß√£o de regras de associa√ß√£o",
                    "steps": [
                        "1. Gera conjuntos frequentes de tamanho 1",
                        "2. Combina conjuntos para gerar candidatos maiores", 
                        "3. Poda candidatos infrequentes",
                        "4. Repete at√© n√£o haver mais conjuntos frequentes",
                        "5. Gera regras a partir dos conjuntos frequentes"
                    ],
                    "complexity": "O(2^n) no pior caso"
                },
                "fp_growth": {
                    "description": "Algoritmo eficiente que usa estrutura de √°rvore FP",
                    "steps": [
                        "1. Constr√≥i √°rvore FP compacta",
                        "2. Minera padr√µes por proje√ß√£o condicional",
                        "3. N√£o gera candidatos explicitamente",
                        "4. Mais eficiente que APRIORI",
                        "5. Especialmente bom para datasets densos"
                    ],
                    "complexity": "Mais eficiente que APRIORI"
                },
                "eclat": {
                    "description": "Baseado em intersec√ß√£o de conjuntos (vertical)",
                    "steps": [
                        "1. Representa dados em formato vertical",
                        "2. Usa intersec√ß√£o de TID-sets",
                        "3. Breadth-first ou depth-first search",
                        "4. Eficiente para datasets densos",
                        "5. Menos uso de mem√≥ria"
                    ],
                    "complexity": "Eficiente para dados densos"
                }
            }
            
            concept = concepts[algorithm]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**{concept['description']}**")
                st.markdown("**Passos do Algoritmo:**")
                for step in concept['steps']:
                    st.markdown(f"- {step}")
            
            with col2:
                st.markdown(f"**Complexidade:** {concept['complexity']}")
                st.markdown("**M√©tricas Importantes:**")
                st.markdown("""
                - **Support**: Freq(A‚à™B) / N
                - **Confidence**: Freq(A‚à™B) / Freq(A)  
                - **Lift**: Confidence(A‚ÜíB) / Support(B)
                """)
    
    def show_ml_models_page(self, df, pipeline_status):
        """P√°gina de modelos de Machine Learning"""
        st.title("ü§ñ Modelos de Machine Learning")
        st.markdown("---")
        
        models_status = pipeline_status['models']
        
        # Header explicativo
        st.markdown("""
        <div style="background: #f0f2f6; padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem;">
            <h4>üéØ Objetivo: Predi√ß√£o de Faixa Salarial (>50K vs ‚â§50K)</h4>
            <p><strong>Problema:</strong> Classifica√ß√£o bin√°ria supervisionada</p>
            <p><strong>Features:</strong> age, education-num, hours-per-week, capital-gain, capital-loss, fnlwgt + vari√°veis categ√≥ricas</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Status dos modelos
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üå≥ Random Forest")
            
            if models_status.get('random_forest', False):
                st.success("‚úÖ Modelo treinado e dispon√≠vel")
                
                # M√©tricas baseadas no relat√≥rio acad√™mico
                st.markdown("""
                **Performance (baseada no relat√≥rio):**
                - **Acur√°cia:** ~84.08% - 86.32%
                - **Tipo:** Ensemble (m√∫ltiplas √°rvores)
                - **Vantagens:** Robustez, lida com overfitting
                - **Interpretabilidade:** Feature importance dispon√≠vel
                """)
                
                # M√©tricas em cards
                met_col1, met_col2 = st.columns(2)
                with met_col1:
                    st.metric("üéØ Acur√°cia", "84.08%", "Alta performance")
                with met_col2:
                    st.metric("üå≤ √Årvores", "100", "Ensemble robusto")
                
            else:
                st.error("‚ùå Modelo n√£o encontrado")
                st.info("Execute `python main.py` para treinar")
        
        with col2:
            st.subheader("üìà Logistic Regression")
            
            if models_status.get('logistic_regression', False):
                st.success("‚úÖ Modelo treinado e dispon√≠vel")
                
                st.markdown("""
                **Performance (baseada no relat√≥rio):**
                - **Acur√°cia:** ~81.85% - 85.87%
                - **Tipo:** Linear (baseline)
                - **Vantagens:** Interpretabilidade m√°xima
                - **Coeficientes:** Facilmente explic√°veis
                """)
                
                # M√©tricas em cards
                met_col1, met_col2 = st.columns(2)
                with met_col1:
                    st.metric("üéØ Acur√°cia", "81.85%", "Baseline s√≥lido")
                with met_col2:
                    st.metric("üîç Interpretabilidade", "M√°xima", "Linear")
                
            else:
                st.error("‚ùå Modelo n√£o encontrado")
                st.info("Execute `python main.py` para treinar")
        
        # Compara√ß√£o de modelos
        st.subheader("‚öñÔ∏è Compara√ß√£o de Performance")
        
        if models_status.get('random_forest', False) and models_status.get('logistic_regression', False):
            # Dados baseados no relat√≥rio acad√™mico
            comparison_data = {
                'Modelo': ['Random Forest', 'Logistic Regression'],
                'Acur√°cia': [0.8408, 0.8185],  # Valores do relat√≥rio
                'Precis√£o': [0.8592, 0.8531],
                'Recall': [0.8632, 0.8587],
                'F1-Score': [0.8532, 0.8539],
                'Interpretabilidade': ['Moderada', 'Alta'],
                'Tipo': ['Ensemble', 'Linear']
            }
            
            comparison_df = pd.DataFrame(comparison_data)
            
            # Gr√°fico de compara√ß√£o
            fig = px.bar(
                comparison_df, 
                x='Modelo', 
                y='Acur√°cia',
                title="üèÜ Compara√ß√£o de Acur√°cia dos Modelos",
                color='Modelo',
                text='Acur√°cia',
                color_discrete_sequence=['#1f77b4', '#ff7f0e']
            )
            fig.update_traces(texttemplate='%{text:.1%}', textposition='outside')
            fig.update_layout(showlegend=False, yaxis_tickformat='.0%')
            st.plotly_chart(fig, use_container_width=True)
            
            # Tabela detalhada
            st.subheader("üìä M√©tricas Detalhadas")
            
            # Preparar dados para exibi√ß√£o
            display_df = comparison_df.copy()
            
            # Formatar percentuais
            for col in ['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score']:
                display_df[col] = display_df[col].apply(lambda x: f"{x:.2%}")
            
            st.dataframe(display_df, use_container_width=True, hide_index=True)
            
            # Interpreta√ß√£o dos resultados
            st.subheader("üß† Interpreta√ß√£o dos Resultados")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **Random Forest (Vencedor):**
                - ‚úÖ Melhor acur√°cia geral (84.08%)
                - ‚úÖ Captura rela√ß√µes n√£o-lineares
                - ‚úÖ Resistente a overfitting
                - ‚ö†Ô∏è Menos interpret√°vel ("black box")
                - üéØ **Recomendado para predi√ß√£o**
                """)
            
            with col2:
                st.markdown("""
                **Logistic Regression (Baseline):**
                - ‚úÖ Altamente interpret√°vel
                - ‚úÖ R√°pido para treinar/prever
                - ‚úÖ Coeficientes explic√°veis
                - ‚ö†Ô∏è Assume rela√ß√µes lineares
                - üéØ **Recomendado para explica√ß√£o**
                """)
        
        else:
            st.info("‚ÑπÔ∏è Execute o pipeline principal para ver a compara√ß√£o completa")
            
            # Placeholder com dados te√≥ricos
            st.markdown("""
            **Compara√ß√£o Esperada (baseada na literatura):**
            - Random Forest geralmente supera modelos lineares
            - Diferen√ßa t√≠pica: 2-5% de acur√°cia
            - Trade-off: Performance vs Interpretabilidade
            """)
        
        # Simulador de predi√ß√£o
        st.subheader("üîÆ Simulador de Predi√ß√£o")
        
        st.markdown("*Simule uma predi√ß√£o com caracter√≠sticas de entrada:*")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            age = st.slider("Idade", 18, 80, 35, help="Idade da pessoa")
            education_num = st.slider("Anos de Educa√ß√£o", 1, 16, 10, help="Anos de escolaridade formal")
        
        with col2:
            hours_per_week = st.slider("Horas por Semana", 1, 100, 40, help="Horas trabalhadas por semana")
            capital_gain = st.number_input("Ganhos de Capital", 0, 100000, 0, help="Capital gains anuais")
        
        with col3:
            capital_loss = st.number_input("Perdas de Capital", 0, 10000, 0, help="Capital losses anuais")
            sex = st.selectbox("Sexo", ["Male", "Female"])
        
        if st.button("üîÆ Fazer Predi√ß√£o Simulada", type="primary"):
            # Simula√ß√£o baseada em heur√≠sticas do dataset
            
            # Calcular score baseado nas vari√°veis
            score = 0
            
            # Idade (experi√™ncia)
            if age > 40:
                score += 0.3
            elif age > 30:
                score += 0.1
            
            # Educa√ß√£o (principal fator)
            if education_num >= 13:  # Bachelor+
                score += 0.4
            elif education_num >= 10:  # Some college
                score += 0.2
            
            # Horas (dedica√ß√£o)
            if hours_per_week > 50:
                score += 0.2
            elif hours_per_week > 40:
                score += 0.1
            
            # Capital (riqueza)
            if capital_gain > 1000:
                score += 0.3
            
            # Adicionar ru√≠do para realismo
            import random
            score += random.uniform(-0.1, 0.1)
            
            # Normalizar
            probability = min(max(score, 0), 1)
            prediction = ">50K" if probability > 0.5 else "‚â§50K"
            
            # Mostrar resultado
            result_col1, result_col2 = st.columns(2)
            
            with result_col1:
                if prediction == ">50K":
                    st.success(f"**Predi√ß√£o: {prediction}** üí∞")
                else:
                    st.info(f"**Predi√ß√£o: {prediction}**")
            
            with result_col2:
                st.metric("Probabilidade >50K", f"{probability:.1%}")
            
            # Explica√ß√£o
            st.markdown("""
            **‚ö†Ô∏è Nota:** Esta √© uma simula√ß√£o baseada em heur√≠sticas.
            Para predi√ß√µes reais, execute o pipeline principal e use os modelos treinados.
            """)
    
    def show_academic_report_page(self, pipeline_status):
        """P√°gina do relat√≥rio acad√™mico"""
        st.title("üìö Relat√≥rio Acad√™mico")
        st.markdown("---")
        
        # Verificar se relat√≥rio existe
        if pipeline_status['algorithms'].get('academic_report', False):
            report_content = self.data_loader.load_algorithm_results('academic_report')
            
            if report_content:
                st.success("‚úÖ Relat√≥rio acad√™mico dispon√≠vel")
                
                # Mostrar conte√∫do do relat√≥rio
                st.markdown(report_content)
                
                # Download do relat√≥rio
                st.download_button(
                    "üì• Download Relat√≥rio Completo",
                    report_content,
                    "relatorio_academico_v2.md",
                    "text/markdown",
                    help="Baixar relat√≥rio em formato Markdown"
                )
            else:
                st.error("‚ùå Erro ao carregar o relat√≥rio")
        else:
            st.info("‚ÑπÔ∏è Execute o pipeline principal (main.py) para gerar o relat√≥rio acad√™mico")
            
            # Mostrar estrutura esperada do relat√≥rio
            st.subheader("üìã Estrutura do Relat√≥rio Acad√™mico")
            
            st.markdown("""
            O relat√≥rio acad√™mico completo incluir√°:
            
            ## üìñ **1. Introdu√ß√£o e Objetivos**
            - Contextualiza√ß√£o do problema
            - Objetivos espec√≠ficos e gerais
            - Justificativa cient√≠fica
            
            ## üî¨ **2. Metodologia Cient√≠fica**
            - Descri√ß√£o dos algoritmos implementados
            - Fundamenta√ß√£o te√≥rica
            - Pipeline de an√°lise
            
            ## üìä **3. An√°lise Explorat√≥ria dos Dados**
            - Caracteriza√ß√£o do dataset (32.561 registros)
            - Distribui√ß√µes das vari√°veis
            - Correla√ß√µes e insights preliminares
            
            ## ü§ñ **4. Resultados dos Algoritmos**
            
            ### **4.1 DBSCAN Clustering**
            - Par√¢metros otimizados
            - Clusters identificados
            - Perfis socioecon√¥micos
            
            ### **4.2 Regras de Associa√ß√£o**
            - **APRIORI**: Regras cl√°ssicas
            - **FP-GROWTH**: Minera√ß√£o eficiente
            - **ECLAT**: Intersec√ß√£o de conjuntos
            
            ### **4.3 Modelos Supervisionados**
            - **Random Forest**: 84.08% acur√°cia
            - **Logistic Regression**: 81.85% acur√°cia
            - Compara√ß√£o e valida√ß√£o
            
            ## üí° **5. Discuss√£o e Interpreta√ß√£o**
            - Insights principais
            - Implica√ß√µes pr√°ticas
            - Limita√ß√µes identificadas
            
            ## üéØ **6. Conclus√µes e Trabalhos Futuros**
            - S√≠ntese dos resultados
            - Recomenda√ß√µes para organiza√ß√µes
            - Dire√ß√µes para pesquisas futuras
            
            ## üìö **7. Refer√™ncias Bibliogr√°ficas**
            - Literatura cient√≠fica consultada
            - Fundamenta√ß√£o te√≥rica
            """)
            
            # Bot√£o para executar pipeline
            if st.button("üöÄ Gerar Relat√≥rio (Executar Pipeline)", type="primary"):
                self._execute_main_pipeline()
    
    def _execute_main_pipeline(self):
        """Executar pipeline principal"""
        try:
            with st.spinner("üîÑ Executando pipeline principal... (pode demorar 1-2 minutos)"):
                result = subprocess.run(
                    [sys.executable, 'main.py'], 
                    capture_output=True, 
                    text=True, 
                    timeout=300
                )
                
                if result.returncode == 0:
                    st.success("‚úÖ Pipeline executado com sucesso!")
                    st.balloons()
                    
                    # Mostrar sa√≠da se houver
                    if result.stdout:
                        with st.expander("üìã Log de Execu√ß√£o"):
                            st.text(result.stdout)
                    
                    time.sleep(2)
                    st.rerun()
                else:
                    st.error(f"‚ùå Erro na execu√ß√£o do pipeline:")
                    if result.stderr:
                        st.code(result.stderr)
                    
        except subprocess.TimeoutExpired:
            st.warning("‚è∞ Timeout - Pipeline ainda em execu√ß√£o. Aguarde e recarregue a p√°gina.")
        except FileNotFoundError:
            st.error("‚ùå Arquivo main.py n√£o encontrado. Verifique se est√° no diret√≥rio correto.")
        except Exception as e:
            st.error(f"‚ùå Erro inesperado: {e}")
    
    def _show_overview_visualizations(self, df):
        """Visualiza√ß√µes da p√°gina de overview"""
        st.subheader("üìä An√°lise Explorat√≥ria do Dataset")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o de sal√°rios
            if 'salary' in df.columns:
                salary_counts = df['salary'].value_counts()
                
                fig = px.pie(
                    values=salary_counts.values,
                    names=salary_counts.index,
                    title="üí∞ Distribui√ß√£o de Faixas Salariais",
                    color_discrete_sequence=['#ff7f0e', '#1f77b4']
                )
                fig.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Distribui√ß√£o por sexo
            if 'sex' in df.columns:
                sex_counts = df['sex'].value_counts()
                
                fig = px.bar(
                    x=sex_counts.index,
                    y=sex_counts.values,
                    title="üë• Distribui√ß√£o por G√™nero",
                    color=sex_counts.index,
                    color_discrete_sequence=['#2ca02c', '#d62728']
                )
                fig.update_layout(showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
        
        # Distribui√ß√£o de idade e educa√ß√£o
        col1, col2 = st.columns(2)
        
        with col1:
            if 'age' in df.columns:
                fig = px.histogram(
                    df, 
                    x='age', 
                    title="üìà Distribui√ß√£o de Idades",
                    nbins=20,
                    color_discrete_sequence=['#9467bd']
                )
                fig.update_layout(yaxis_title="Frequ√™ncia")
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            if 'education-num' in df.columns:
                fig = px.histogram(
                    df, 
                    x='education-num', 
                    title="üéì Distribui√ß√£o de Anos de Educa√ß√£o",
                    nbins=16,
                    color_discrete_sequence=['#8c564b']
                )
                fig.update_layout(yaxis_title="Frequ√™ncia")
                st.plotly_chart(fig, use_container_width=True)
    
    def _plot_dbscan_results(self, dbscan_data):
        """Plotar resultados do DBSCAN"""
        if 'cluster' in dbscan_data.columns:
            # Preparar dados para visualiza√ß√£o
            plot_cols = []
            
            # Tentar usar as vari√°veis principais do clustering
            preferred_cols = ['age', 'education-num', 'hours-per-week', 'capital-gain']
            
            for col in preferred_cols:
                if col in dbscan_data.columns:
                    plot_cols.append(col)
                if len(plot_cols) >= 2:
                    break
            
            # Fallback para qualquer coluna num√©rica
            if len(plot_cols) < 2:
                numeric_cols = dbscan_data.select_dtypes(include=[np.number]).columns
                numeric_cols = [col for col in numeric_cols if col != 'cluster']
                plot_cols = list(numeric_cols[:2])
            
            if len(plot_cols) >= 2:
                # Scatter plot dos clusters
                fig = px.scatter(
                    dbscan_data,
                    x=plot_cols[0],
                    y=plot_cols[1],
                    color='cluster',
                    title=f"üéØ Clusters DBSCAN - {plot_cols[0]} vs {plot_cols[1]}",
                    labels={'cluster': 'Cluster ID'},
                    hover_data=['cluster']
                )
                
                # Destacar ru√≠do com cor especial
                fig.update_traces(
                    marker=dict(size=6, opacity=0.7)
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Distribui√ß√£o dos clusters
                if len(dbscan_data['cluster'].unique()) > 1:
                    cluster_counts = dbscan_data['cluster'].value_counts().sort_index()
                    
                    # Renomear cluster -1 para "Ru√≠do"
                    cluster_names = []
                    for cluster_id in cluster_counts.index:
                        if cluster_id == -1:
                            cluster_names.append("Ru√≠do")
                        else:
                            cluster_names.append(f"Cluster {cluster_id}")
                    
                    fig2 = px.bar(
                        x=cluster_names,
                        y=cluster_counts.values,
                        title="üìä Distribui√ß√£o dos Clusters",
                        color=cluster_names
                    )
                    fig2.update_layout(showlegend=False, xaxis_title="Cluster", yaxis_title="N√∫mero de Pontos")
                    st.plotly_chart(fig2, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Dados insuficientes para visualiza√ß√£o dos clusters")
    
    def _analyze_cluster_profiles(self, dbscan_data):
        """Analisar perfis dos clusters"""
        if 'cluster' in dbscan_data.columns:
            # An√°lise por cluster
            clusters = sorted(dbscan_data['cluster'].unique())
            
            # Estat√≠sticas por cluster
            numeric_cols = dbscan_data.select_dtypes(include=[np.number]).columns
            numeric_cols = [col for col in numeric_cols if col != 'cluster']
            
            if len(numeric_cols) > 0:
                st.subheader("üìà Estat√≠sticas por Cluster")
                
                profiles = []
                
                for cluster_id in clusters:
                    cluster_data = dbscan_data[dbscan_data['cluster'] == cluster_id]
                    
                    cluster_name = "Ru√≠do" if cluster_id == -1 else f"Cluster {cluster_id}"
                    
                    profile = {
                        'Cluster': cluster_name,
                        'Tamanho': len(cluster_data),
                        'Percentual': f"{len(cluster_data)/len(dbscan_data)*100:.1f}%"
                    }
                    
                    # Adicionar m√©dias das vari√°veis num√©ricas principais
                    for col in numeric_cols[:4]:  # Limitar para n√£o ficar muito largo
                        if col in cluster_data.columns:
                            profile[f'{col}_m√©dia'] = f"{cluster_data[col].mean():.1f}"
                    
                    profiles.append(profile)
                
                profiles_df = pd.DataFrame(profiles)
                st.dataframe(profiles_df, use_container_width=True, hide_index=True)
                
                # Interpreta√ß√£o dos clusters
                st.subheader("üß† Interpreta√ß√£o dos Perfis")
                
                if len(clusters) > 1:
                    for cluster_id in clusters:
                        if cluster_id != -1:  # Ignorar ru√≠do na interpreta√ß√£o
                            cluster_data = dbscan_data[dbscan_data['cluster'] == cluster_id]
                            
                            with st.container():
                                st.markdown(f"**Cluster {cluster_id}** ({len(cluster_data)} pessoas)")
                                
                                # Caracter√≠sticas principais
                                characteristics = []
                                
                                if 'age' in cluster_data.columns:
                                    avg_age = cluster_data['age'].mean()
                                    if avg_age < 30:
                                        characteristics.append("üë∂ Jovens")
                                    elif avg_age > 50:
                                        characteristics.append("üë¥ Experientes")
                                    else:
                                        characteristics.append("üë® Adultos")
                                
                                if 'education-num' in cluster_data.columns:
                                    avg_edu = cluster_data['education-num'].mean()
                                    if avg_edu >= 13:
                                        characteristics.append("üéì Alta escolaridade")
                                    elif avg_edu <= 9:
                                        characteristics.append("üìö Baixa escolaridade")
                                    else:
                                        characteristics.append("üè´ Escolaridade m√©dia")
                                
                                if 'hours-per-week' in cluster_data.columns:
                                    avg_hours = cluster_data['hours-per-week'].mean()
                                    if avg_hours > 50:
                                        characteristics.append("‚è∞ Carga hor√°ria alta")
                                    elif avg_hours < 35:
                                        characteristics.append("üïê Meio per√≠odo")
                                
                                st.markdown(f"- {' ‚Ä¢ '.join(characteristics)}")
                                st.markdown("---")
    
    def _plot_association_rules(self, rules_data, algorithm):
        """Plotar visualiza√ß√µes das regras de associa√ß√£o"""
        if not rules_data.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                # Scatter plot Support vs Confidence
                if 'support' in rules_data.columns and 'confidence' in rules_data.columns:
                    size_col = 'lift' if 'lift' in rules_data.columns else None
                    
                    fig = px.scatter(
                        rules_data,
                        x='support',
                        y='confidence',
                        size=size_col,
                        title=f"üìä {algorithm.upper()}: Support vs Confidence",
                        hover_data=['lift'] if 'lift' in rules_data.columns else None,
                        labels={
                            'support': 'Support (Frequ√™ncia)',
                            'confidence': 'Confidence (Confian√ßa)',
                            'lift': 'Lift (For√ßa da Associa√ß√£o)'
                        }
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Histograma das m√©tricas
                if 'lift' in rules_data.columns:
                    fig = px.histogram(
                        rules_data,
                        x='lift',
                        title=f"üìà {algorithm.upper()}: Distribui√ß√£o do Lift",
                        nbins=20,
                        labels={'lift': 'Lift (For√ßa da Associa√ß√£o)'}
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)

# =============================================================================
# APLICA√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """Aplica√ß√£o principal do dashboard cient√≠fico"""
    
    # Configurar logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # Inicializar sistemas
    auth_system = AcademicAuthSystem()
    
    # Verificar autentica√ß√£o
    if not st.session_state.get('authenticated', False):
        auth_system.show_login_page()
        return
    
    # Header do usu√°rio autenticado
    user_data = st.session_state.get('user', {})
    st.sidebar.markdown(f"""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
        <h4>üë§ {user_data.get('name', 'Usu√°rio')}</h4>
        <p><strong>Perfil:</strong> {user_data.get('role', 'N/A').title()}</p>
        <p><strong>Acesso:</strong> {user_data.get('access', 'N/A').title()}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Bot√£o de logout
    if st.sidebar.button("üö™ Sair do Sistema", use_container_width=True):
        st.session_state.clear()
        st.rerun()
    
    st.sidebar.markdown("---")
    
    # Menu de navega√ß√£o
    st.sidebar.markdown("### üìö Navega√ß√£o Acad√™mica")
    
    page = st.sidebar.selectbox(
        "Selecione a p√°gina:",
        [
            "üìä Vis√£o Geral",
            "üéØ Clustering (DBSCAN)", 
            "üìã Regras de Associa√ß√£o",
            "ü§ñ Modelos ML",
            "üìö Relat√≥rio Acad√™mico"
        ],
        help="Navegue pelas diferentes an√°lises cient√≠ficas"
    )
    
    # Informa√ß√µes do projeto na sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### üéì Sobre o Projeto
    
    **Algoritmos Implementados:**
    - üéØ DBSCAN (Clustering)
    - üìã APRIORI (Regras)
    - üå≤ FP-GROWTH (Regras)
    - üîç ECLAT (Regras)
    - ü§ñ Random Forest
    - üìà Logistic Regression
    
    **Dataset:** Adult Income (UCI)
    **Objetivo:** An√°lise Salarial
    """)
    
    # Carregar dados e status
    data_loader = ScientificDataLoader()
    
    with st.spinner("üîÑ Carregando dados..."):
        df, load_message = data_loader.load_main_dataset()
        pipeline_status = data_loader.check_pipeline_execution()
    
    # Mostrar status de carregamento na sidebar
    if "demonstra√ß√£o" in load_message:
        st.sidebar.warning(load_message)
    else:
        st.sidebar.success(load_message)
    
    # Status do pipeline na sidebar
    execution_score = pipeline_status.get('execution_score', 0)
    
    if execution_score >= 0.8:
        st.sidebar.success(f"‚úÖ Pipeline: {execution_score:.0%} completo")
    elif execution_score >= 0.5:
        st.sidebar.warning(f"‚ö†Ô∏è Pipeline: {execution_score:.0%} completo")
    else:
        st.sidebar.error(f"‚ùå Pipeline: {execution_score:.0%} completo")
    
    # Inicializar p√°ginas
    pages = ScientificDashboardPages(data_loader)
    
    # Roteamento de p√°ginas baseado na sele√ß√£o
    try:
        if page == "üìä Vis√£o Geral":
            pages.show_overview_page(df, pipeline_status)
        elif page == "üéØ Clustering (DBSCAN)":
            pages.show_clustering_page(df, pipeline_status)
        elif page == "üìã Regras de Associa√ß√£o":
            pages.show_association_rules_page(df, pipeline_status)
        elif page == "ü§ñ Modelos ML":
            pages.show_ml_models_page(df, pipeline_status)
        elif page == "üìö Relat√≥rio Acad√™mico":
            pages.show_academic_report_page(pipeline_status)
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar p√°gina: {e}")
        st.info("üîÑ Tente recarregar a p√°gina ou contate o administrador")
        
        # Debug info para desenvolvimento
        if user_data.get('role') == 'admin':
            with st.expander("üêõ Debug Info (Admin)"):
                st.code(str(e))
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; margin-top: 2rem;">
        <p>üéì <strong>Dashboard Cient√≠fico Acad√™mico</strong> | 
        Desenvolvido para An√°lise Salarial | 
        <i>Vers√£o 3.0 - Totalmente Integrado</i></p>
    </div>
    """, unsafe_allow_html=True)

# =============================================================================
# CSS PERSONALIZADO PARA TEMA ACAD√äMICO
# =============================================================================

def apply_academic_theme():
    """Aplicar tema visual acad√™mico"""
    st.markdown("""
    <style>
    /* Tema acad√™mico */
    .main > div {
        padding-top: 2rem;
    }
    
    /* Cards de m√©tricas */
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Header acad√™mico */
    .academic-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.15);
    }
    
    /* Status cards */
    .status-card {
        border: 2px solid #e0e0e0;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    
    .status-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }
    
    .status-success {
        border-color: #4caf50;
        background: linear-gradient(135deg, #f1f8e9 0%, #e8f5e8 100%);
    }
    
    .status-warning {
        border-color: #ff9800;
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
    }
    
    .status-error {
        border-color: #f44336;
        background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
    }
    
    /* Bot√µes personalizados */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    
    /* Sidebar personalizada */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* Tabelas */
    .dataframe {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    
    /* M√©tricas do Streamlit */
    [data-testid="metric-container"] {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 1px solid #e9ecef;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }
    
    /* Expanders */
    .streamlit-expanderHeader {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        font-weight: 600;
    }
    
    /* Alerts personalizados */
    .stAlert {
        border-radius: 10px;
        border: none;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    
    /* T√≠tulos */
    h1 {
        color: #1e3c72;
        font-weight: 700;
        margin-bottom: 1rem;
    }
    
    h2 {
        color: #2a5298;
        font-weight: 600;
    }
    
    h3 {
        color: #667eea;
        font-weight: 600;
    }
    
    /* Loading spinner */
    .stSpinner {
        text-align: center;
    }
    
    /* Plotly charts */
    .js-plotly-plot {
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    
    /* Footer */
    .footer {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin-top: 2rem;
    }
    
    /* Anima√ß√µes */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .fadeIn {
        animation: fadeIn 0.6s ease-out;
    }
    
    /* Responsive design */
    @media (max-width: 768px) {
        .metric-card {
            padding: 1rem;
        }
        
        .academic-header {
            padding: 1.5rem;
        }
    }
    </style>
    """, unsafe_allow_html=True)

# =============================================================================
# PONTO DE ENTRADA
# =============================================================================

if __name__ == "__main__":
    # Aplicar tema visual
    apply_academic_theme()
    
    # Executar aplica√ß√£o principal
    main()